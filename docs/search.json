[
  {
    "objectID": "index.html#papers-slides-etc.",
    "href": "index.html#papers-slides-etc.",
    "title": "",
    "section": "Papers üìö, Slides üìä etc.",
    "text": "Papers üìö, Slides üìä etc.\n\nüìä Slides (07/31/2023 @ Lattice 2023)\nüìï Notebooks / Reports:\n\nüìì 2D U(1) Example\n\nüìô 2D U(1) Model (w/ fp16 or fp32 for training)\nüìí 4D SU(3) Model (w/ complex128 + fp64 for training)\n\nalt link (if github won‚Äôt load)\n\n\n\nüìù Papers:\n\nLeapfrogLayers: A Trainable Framework for Effective Topological Sampling, 2022\n\nAccelerated Sampling Techniques for Lattice Gauge Theory @ BNL & RBRC: DWQ @ 25 (12/2021)\nTraining Topological Samplers for Lattice Gauge Theory from the ML for HEP, on and off the Lattice @ \\mathrm{ECT}^{*} Trento (09/2021) (+ üìä slides)\nDeep Learning Hamiltonian Monte Carlo @ Deep Learning for Simulation (SimDL) Workshop ICLR 2021\n\nüìö : arXiv:2105.03418\n\nüìä : poster"
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "",
    "section": "Background",
    "text": "Background\nThe L2HMC algorithm aims to improve upon HMC by optimizing a carefully chosen loss function which is designed to minimize autocorrelations within the Markov Chain, thereby improving the efficiency of the sampler.\nA detailed description of the original L2HMC algorithm can be found in the paper:\nGeneralizing Hamiltonian Monte Carlo with Neural Network\nwith implementation available at brain-research/l2hmc/ by Daniel Levy, Matt D. Hoffman and Jascha Sohl-Dickstein.\nBroadly, given an analytically described target distribution, œÄ(x), L2HMC provides a statistically exact sampler that:\n\nQuickly converges to the target distribution (fast burn-in).\nQuickly produces uncorrelated samples (fast mixing).\nIs able to efficiently mix between energy levels.\nIs capable of traversing low-density zones to mix between modes (often difficult for generic HMC)."
  },
  {
    "objectID": "index.html#configuration-management",
    "href": "index.html#configuration-management",
    "title": "",
    "section": "Configuration Management",
    "text": "Configuration Management\nThis project uses hydra for configuration management and supports distributed training for both PyTorch and TensorFlow.\nIn particular, we support the following combinations of framework + backend for distributed training:\n\nTensorFlow (+ Horovod for distributed training)\nPyTorch +\n\nDDP\nHorovod\nDeepSpeed\n\n\nThe main entry point is src/l2hmc/main.py, which contains the logic for running an end-to-end Experiment.\nAn Experiment consists of the following sub-tasks:\n\nTraining\nEvaluation\nHMC (for comparison and to measure model improvement)\n\nAll configuration options can be dynamically overridden via the CLI at runtime, and we can specify our desired framework and backend combination via:\npython3 main.py mode=debug framework=pytorch backend=deepspeed precision=fp16\nto run a (non-distributed) Experiment with pytorch + deepspeed with fp16 precision.\nThe l2hmc/conf/config.yaml contains a brief explanation of each of the various parameter options, and values can be overriden either by modifying the config.yaml file, or directly through the command line, e.g.\ncd src/l2hmc\n./train.sh mode=debug framework=pytorch &gt; train.log 2&gt;&1 &\ntail -f train.log $(tail -1 logs/latest)\nAdditional information about various configuration options can be found in:\n\nsrc/l2hmc/configs.py: Contains implementations of the (concrete python objects) that are adjustable for our experiment.\nsrc/l2hmc/conf/config.yaml: Starting point with default configuration options for a generic Experiment.\n\nfor more information on how this works I encourage you to read Hydra‚Äôs Documentation Page."
  },
  {
    "objectID": "index.html#running-at-alcf",
    "href": "index.html#running-at-alcf",
    "title": "",
    "section": "Running at ALCF",
    "text": "Running at ALCF\nFor running with distributed training on ALCF systems, we provide a complete src/l2hmc/train.sh script which should run without issues on either Polaris or ThetaGPU @ ALCF.\n\nALCF:\n# Polaris --------------------------------\nif [[ \"$(hostname)==x3*\" ]]; then\n  MACHINE=\"Polaris\"\n  CONDA_DATE=\"2023-10-02\"\n# thetaGPU -------------------------------\nelif  [[ \"$(hostname)==thetagpu*\" ]]; then\n  MACHINE=\"thetaGPU\"\n  CONDA_DATE=\"2023-01-11\"\nelse\n  echo \"Unknown machine\"\n  exit 1\nfi\n# Setup conda + build virtual env -----------------------------------------\nmodule load \"conda/${CONDA_DATE}\"\nconda activate base\ngit clone https://github.com/saforem2/l2hmc-qcd\ncd l2hmc-qcd\nmkdir -p \"venvs/${MACHINE}/${CONDA_DATE}\"\npython3 -m venv \"venvs/${MACHINE}/${CONDA_DATE}\" --system-site-packages\nsource \"venvs/${MACHINE}/${CONDA_DATE}/bin/activate\"\npython3 -m pip install --upgrade pip setuptools wheel\n# Install `l2hmc` ----------\npython3 -m pip install -e .\n# Train ----------------------------------------------------------------------\ncd src/l2hmc\n./bin/train.sh mode=test framework=pytorch backend=deepspeed seed=\"${RANDOM}\""
  },
  {
    "objectID": "index.html#organization",
    "href": "index.html#organization",
    "title": "",
    "section": "Organization",
    "text": "Organization\n\n\n\nLattice Dynamics\n\n\n\nFigure¬†1: A 2D view of the lattice, with an elementary plaquette, U_{\\mu\\nu}(x) illustrated.\n\n\nFor a given target distribution, \\pi(U) the Dynamics object (src/l2hmc/dynamics/) implements methods for generating proposal configurations\nU_{0} \\rightarrow U_{1} \\rightarrow \\cdots \\rightarrow U_{n} \\sim \\pi(U)\nusing the generalized leapfrog update, as shown to the right in Figure¬†2.\nThis generalized leapfrog update takes as input a buffer of lattice configurations U1 and generates a proposal configuration:\n\nU^{\\prime}= Dynamics(U)\n\nby evolving the generalized L2HMC dynamics.\n\n\n\nNetwork Architecture\nWe use networks with identical architectures, \\Gamma^{\\pm}2, \\Lambda^{\\pm}3 to update our momenta P and links U, respectively.\n\n\n\nFigure¬†2: An illustration of the leapfrog layer updating (P, U) \\rightarrow (P', U')."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "",
    "section": "Contact",
    "text": "Contact\nCode author: Sam Foreman\nPull requests and issues should be directed to: saforem2"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "",
    "section": "Citation",
    "text": "Citation\nIf you use this code or found this work interesting, please cite our work along with the original paper:\n@misc{foreman2021deep,\n      title={Deep Learning Hamiltonian Monte Carlo}, \n      author={Sam Foreman and Xiao-Yong Jin and James C. Osborn},\n      year={2021},\n      eprint={2105.03418},\n      archivePrefix={arXiv},\n      primaryClass={hep-lat}\n}\n@article{levy2017generalizing,\n  title={Generalizing Hamiltonian Monte Carlo with Neural Networks},\n  author={Levy, Daniel and Hoffman, Matthew D. and Sohl-Dickstein, Jascha},\n  journal={arXiv preprint arXiv:1711.09268},\n  year={2017}\n}"
  },
  {
    "objectID": "index.html#acknowledgement",
    "href": "index.html#acknowledgement",
    "title": "",
    "section": "Acknowledgement",
    "text": "Acknowledgement\n\nNote This research used resources of the Argonne Leadership Computing Facility, which is a DOE Office of Science User Facility supported under contract DE_AC02-06CH11357. This work describes objective technical results and analysis. Any subjective views or opinions that might be expressed in the work do not necessarily represent the views of the U.S. DOE or the United States Government."
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "",
    "section": "Posts",
    "text": "Posts\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 4, 2023\n\n\nundefined\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nPosts\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nundefined\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nMCMC + Diffusion Sampling\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nDenoising Diffusion Probabilistic Models\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nundefined\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nRecent Talks\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nundefined\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\n2D U(1) Example\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nundefined\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\n4D SU(3) Model\n\n\nSam Foreman \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "qmd/l2hmc-4DSU3.html",
    "href": "qmd/l2hmc-4DSU3.html",
    "title": "4D SU(3) Model",
    "section": "",
    "text": "Slides\n\n\nimport os\nfrom pathlib import Path\nfrom typing import Optional\n\nimport lovely_tensors as lt\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport yaml\n\nimport l2hmc.group.su3.pytorch.group as g\nfrom l2hmc import get_logger\nfrom l2hmc.common import grab_tensor, print_dict\nfrom l2hmc.configs import dict_to_list_of_overrides, get_experiment\nfrom l2hmc.experiment.pytorch.experiment import Experiment, evaluate  # noqa  # noqa\nfrom l2hmc.utils.dist import setup_torch\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nlt.monkey_patch()\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '6'\nos.environ['COLORTERM'] = 'truecolor;'\nos.environ['MASTER_PORT'] = '5433'\n# os.environ['MPLBACKEND'] = 'module://matplotlib-backend-kitty'\n# plt.switch_backend('module://matplotlib-backend-kitty')\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom enrich.console import Console\n\nlog = get_logger(__name__)\ntheme = Theme(STYLES)\n# log = get_logger('ClimRR')\nconsole = Console(theme=theme, log_path=False, markup=True)\nif console.is_jupyter:\n    console.is_jupyter = False\n\n_ = setup_torch(precision='float64', backend='DDP', seed=4351)\n\nset_plot_style()\n\nfrom l2hmc.utils.plot_helpers import (  # noqa\n    set_plot_style,\n    plot_scalar,\n    plot_chains,\n    plot_leapfrogs\n)\n\nUsing device: cpu\n\n\n\nFailed to download font: Source Sans Pro, skipping!\nFailed to download font: Titillium WebRoboto Condensed, skipping!\n[10/04/23 08:06:53][INFO][dist.py:226] - Caught MASTER_PORT:5433 from environment!\n[10/04/23 08:06:53][WARNING][dist.py:332] - Setting default dtype: float64\n[10/04/23 08:06:53][INFO][dist.py:338] - Global Rank: 0 / 0\n\n\n\ndef savefig(fig: plt.Figure, fname: str, outdir: os.PathLike):\n    pngfile = Path(outdir).joinpath(f\"pngs/{fname}.png\")\n    svgfile = Path(outdir).joinpath(f\"svgs/{fname}.svg\")\n    pngfile.parent.mkdir(exist_ok=True, parents=True)\n    svgfile.parent.mkdir(exist_ok=True, parents=True)\n    fig.savefig(svgfile, transparent=True, bbox_inches='tight')\n    fig.savefig(pngfile, transparent=True, bbox_inches='tight', dpi=300)\n\n\ndef plot_metrics(metrics: dict, title: Optional[str] = None, **kwargs):\n    from l2hmc.utils.rich import is_interactive\n    from l2hmc.configs import QUARTO_OUTPUTS_DIR\n    outdir = Path(f\"{QUARTO_OUTPUTS_DIR}/plots-4dSU3/{title}\")\n    outdir.mkdir(exist_ok=True, parents=True)\n    for key, val in metrics.items():\n        fig, ax = plot_metric(val, name=key, **kwargs)\n        if title is not None:\n            ax.set_title(title)\n        log.info(f\"Saving {key} to {outdir}\")\n        savefig(fig, f\"{key}\", outdir=outdir)\n        # fpath = outdir.joinpath(f\"{key}\")\n        # plt.savefig(f\"{fpath}.svg\", bbox_inches='tight')\n        # plt.savefig(f\"{fpath}.png\", bbox_inches='tight', dpi=300)\n        # log.info(f\"Saving {title} {key} plot to {fpath}\")\n        if not is_interactive():\n            plt.show()\n\n\ndef plot_metric(\n        metric: torch.Tensor,\n        name: Optional[str] = None,\n        **kwargs,\n):\n    assert len(metric) &gt; 0\n    if isinstance(metric[0], (int, float, bool, np.floating)):\n        y = np.stack(metric)\n        return plot_scalar(y, ylabel=name, **kwargs)\n    element_shape = metric[0].shape\n    if len(element_shape) == 2:\n        if isinstance(metric, torch.Tensor):\n            y = grab_tensor(torch.stack(metric))\n        else:\n            y = np.stack(metric)\n        return plot_leapfrogs(y, ylabel=name)\n    if len(element_shape) == 1:\n        if isinstance(metric, torch.Tensor):\n            y = grab_tensor(torch.stack(metric))\n        else:\n            y = np.stack(metric)\n        return plot_chains(y, ylabel=name, **kwargs)\n    if len(element_shape) == 0:\n        if isinstance(metric, torch.Tensor):\n            y = grab_tensor(torch.stack(metric))\n        else:\n            y = np.stack(metric)\n        return plot_scalar(y, ylabel=name, **kwargs)\n    raise ValueError\n\n\ndef main():\n    from l2hmc.experiment.pytorch.experiment import train_step\n    set_plot_style()\n\n    from l2hmc.configs import CONF_DIR\n    su3conf = Path(CONF_DIR).joinpath('su3-min-cpu.yaml')\n    assert su3conf.is_file()\n    # su3conf = Path('su3-min-cpu.yaml')\n    with su3conf.open('r') as stream:\n        conf = dict(yaml.safe_load(stream))\n\n    log.info(conf)\n    overrides = dict_to_list_of_overrides(conf)\n    ptExpSU3 = get_experiment(overrides=[*overrides], build_networks=True)\n    state = ptExpSU3.trainer.dynamics.random_state(6.0)\n    assert isinstance(state.x, torch.Tensor)\n    assert isinstance(state.beta, torch.Tensor)\n    assert isinstance(ptExpSU3, Experiment)\n    xhmc, history_hmc = evaluate(\n        nsteps=10,\n        exp=ptExpSU3,\n        beta=state.beta,\n        x=state.x,\n        eps=0.1,\n        nleapfrog=1,\n        job_type='hmc',\n        nlog=1,\n        nprint=2,\n        grab=True\n    )\n    xhmc = ptExpSU3.trainer.dynamics.unflatten(xhmc)\n    log.info(f\"checkSU(x_hmc): {g.checkSU(xhmc)}\")\n    plot_metrics(history_hmc.history, title='HMC', marker='.')\n    # ptExpSU3.trainer.dynamics.init_weights(\n    #     method='uniform',\n    #     min=-1e-16,\n    #     max=1e-16,\n    #     bias=True,\n    #     # xeps=0.001,\n    #     # veps=0.001,\n    # )\n    xeval, history_eval = evaluate(\n        nsteps=10,\n        exp=ptExpSU3,\n        beta=6.0,\n        x=state.x,\n        job_type='eval',\n        nlog=1,\n        nprint=2,\n        grab=True,\n    )\n    xeval = ptExpSU3.trainer.dynamics.unflatten(xeval)\n    log.info(f\"checkSU(x_eval): {g.checkSU(xeval)}\")\n    plot_metrics(history_eval.history, title='Evaluate', marker='.')\n\n    history = {}\n    x = state.x\n    for step in range(20):\n        log.info(f'TRAIN STEP: {step}')\n        x, metrics = ptExpSU3.trainer.train_step((x, state.beta))\n        if (step &gt; 0 and step % 2 == 0):\n            print_dict(metrics, grab=True)\n        if (step &gt; 0 and step % 1 == 0):\n            for key, val in metrics.items():\n                try:\n                    history[key].append(val)\n                except KeyError:\n                    history[key] = [val]\n\n    x = ptExpSU3.trainer.dynamics.unflatten(x)\n    log.info(f\"checkSU(x_train): {g.checkSU(x)}\")\n    plot_metrics(history, title='train', marker='.')\n    #\n    # for step in range(20):\n    #     log.info(f\"train step: {step}\")\n    #     x, metrics = ptExpSU3.trainer.train_step((x, state.beta))\n    #     if step % 5 == 0:\n    #         print_dict(metrics, grab=True)\n\n    return x, history\n\n\n# main()\nfrom l2hmc.experiment.pytorch.experiment import train_step\nset_plot_style()\n\nfrom l2hmc.configs import CONF_DIR\nsu3conf = Path(CONF_DIR).joinpath('su3-min-cpu.yaml')\nassert su3conf.is_file()\n# su3conf = Path('./conf/su3-min-cpu.yaml')\nwith su3conf.open('r') as stream:\n    conf = dict(yaml.safe_load(stream))\n\nlog.info(conf)\noverrides = dict_to_list_of_overrides(conf)\nptExpSU3 = get_experiment(overrides=[*overrides], build_networks=True)\n\n[10/04/23 08:06:54][INFO][2091541093.py:12] - {'annealing_schedule': {'beta_final': 6.0, 'beta_init': 6.0}, 'backend': 'DDP', 'conv': 'none', 'dynamics': {'eps': 0.1, 'eps_fixed': True, 'group': 'SU3', 'latvolume': [1, 1, 1, 1], 'nchains': 4, 'nleapfrog': 1, 'use_separate_networks': False, 'use_split_xnets': False, 'verbose': True}, 'framework': 'pytorch', 'init_aim': False, 'init_wandb': False, 'learning_rate': {'clip_norm': 1.0, 'lr_init': 1e-05}, 'loss': {'charge_weight': 0.0, 'plaq_weight': 0.0, 'rmse_weight': 1.0, 'use_mixed_loss': False}, 'net_weights': {'v': {'q': 1.0, 's': 1.0, 't': 1.0}, 'x': {'q': 0.0, 's': 0.0, 't': 0.0}}, 'network': {'activation_fn': 'tanh', 'dropout_prob': 0.0, 'units': [1], 'use_batch_norm': False}, 'restore': False, 'save': False, 'steps': {'log': 1, 'nepoch': 10, 'nera': 1, 'print': 1, 'test': 50}, 'use_tb': False, 'use_wandb': False}\n[10/04/23 08:06:54][INFO][experiment.py:251] - Creating outputs/2023-10-04-080654/pytorch/train\n[10/04/23 08:06:54][INFO][experiment.py:251] - Creating outputs/2023-10-04-080654/pytorch/eval\n[10/04/23 08:06:54][INFO][experiment.py:251] - Creating outputs/2023-10-04-080654/pytorch/hmc\n[10/04/23 08:06:54][INFO][dist.py:226] - Caught MASTER_PORT:5433 from environment!\n[10/04/23 08:06:54][INFO][dist.py:226] - Caught MASTER_PORT:5433 from environment!\n[10/04/23 08:06:54][WARNING][trainer.py:437] - Using `torch.optim.Adam` optimizer\n[10/04/23 08:06:54][INFO][trainer.py:284] - num_params in model: 788\n[10/04/23 08:06:54][WARNING][trainer.py:250] - logging with freq 1 for wandb.watch\n\n\n\nstate = ptExpSU3.trainer.dynamics.random_state(6.0)\nassert isinstance(state.x, torch.Tensor)\nassert isinstance(state.beta, torch.Tensor)\nassert isinstance(ptExpSU3, Experiment)\n\n\nxhmc, history_hmc = evaluate(\n    nsteps=10,\n    exp=ptExpSU3,\n    beta=state.beta,\n    x=state.x,\n    eps=0.1,\n    nleapfrog=1,\n    job_type='hmc',\n    nlog=1,\n    nprint=2,\n    grab=True\n)\nxhmc = ptExpSU3.trainer.dynamics.unflatten(xhmc)\nlog.info(f\"checkSU(x_hmc): {g.checkSU(xhmc)}\")\nplot_metrics(history_hmc.history, title='HMC', marker='.')\n\n[10/04/23 08:06:54][INFO][experiment.py:117] - Running 10 steps of hmc at beta=6.0000\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 0\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 1\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 2\n[10/04/23 08:06:54][INFO][common.py:97] - energy: torch.Size([2, 4]) torch.float64 \n[[-10.75791732 -12.34937625  -0.41675933  -1.53564322]\n [-10.75124452 -12.3522306   -0.41267615  -1.54108594]]\nlogprob: torch.Size([2, 4]) torch.float64 \n[[-10.75791732 -12.34937625  -0.41675933  -1.53564322]\n [-10.75124452 -12.3522306   -0.41267615  -1.54108594]]\nlogdet: torch.Size([2, 4]) torch.float64 \n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]]\nacc: torch.Size([4]) torch.float64 \n[0.99334941 1.         0.99592515 1.        ]\nsumlogdet: torch.Size([4]) torch.float64 \n[0. 0. 0. 0.]\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.16450298 0.30335925 0.08750178 0.11000818]\nsinQ: torch.Size([4]) torch.float64 \n[0.06377054 0.02936343 0.0290893  0.0471427 ]\nintQ: torch.Size([4]) torch.float64 \n[0.00363448 0.00167351 0.00165789 0.00268681]\ndQint: torch.Size([4]) torch.float64 \n[0.00063734 0.00026722 0.00153373 0.00079181]\ndQsin: torch.Size([4]) torch.float64 \n[0.01118282 0.00468872 0.02691084 0.01389309]\nloss: None None \n-0.008486187067784774\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 3\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 4\n[10/04/23 08:06:54][INFO][common.py:97] - energy: torch.Size([2, 4]) torch.float64 \n[[-11.11456032 -17.6499957   -3.95552998  -6.53463898]\n [-11.13603858 -17.671668    -3.9389084   -6.51679905]]\nlogprob: torch.Size([2, 4]) torch.float64 \n[[-11.11456032 -17.6499957   -3.95552998  -6.53463898]\n [-11.13603858 -17.671668    -3.9389084   -6.51679905]]\nlogdet: torch.Size([2, 4]) torch.float64 \n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]]\nacc: torch.Size([4]) torch.float64 \n[1.         1.         0.9835158  0.98231826]\nsumlogdet: torch.Size([4]) torch.float64 \n[0. 0. 0. 0.]\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.25275746 0.399866   0.08094436 0.14319661]\nsinQ: torch.Size([4]) torch.float64 \n[0.06062536 0.00580304 0.05690804 0.03510997]\nintQ: torch.Size([4]) torch.float64 \n[0.00345523 0.00033073 0.00324337 0.00200103]\ndQint: torch.Size([4]) torch.float64 \n[6.94769306e-04 1.54302575e-05 1.45796993e-03 7.05322708e-06]\ndQsin: torch.Size([4]) torch.float64 \n[0.0121904  0.00027074 0.02558149 0.00012376]\nloss: None None \n-0.007962121892379256\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 5\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 6\n[10/04/23 08:06:54][INFO][common.py:97] - energy: torch.Size([2, 4]) torch.float64 \n[[ -7.92357836 -18.88468089  -3.00365154  -4.94505522]\n [ -7.96783894 -18.86501731  -2.98482073  -4.97272838]]\nlogprob: torch.Size([2, 4]) torch.float64 \n[[ -7.92357836 -18.88468089  -3.00365154  -4.94505522]\n [ -7.96783894 -18.86501731  -2.98482073  -4.97272838]]\nlogdet: torch.Size([2, 4]) torch.float64 \n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]]\nacc: torch.Size([4]) torch.float64 \n[1.         0.98052848 0.98134538 1.        ]\nsumlogdet: torch.Size([4]) torch.float64 \n[0. 0. 0. 0.]\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.40639896 0.38496604 0.09990116 0.24746026]\nsinQ: torch.Size([4]) torch.float64 \n[ 0.04504223  0.00155452 -0.00443203  0.02472714]\nintQ: torch.Size([4]) torch.float64 \n[ 2.56709954e-03  8.85969084e-05 -2.52595510e-04  1.40927794e-03]\ndQint: torch.Size([4]) torch.float64 \n[7.55078122e-04 4.03034083e-04 2.18911031e-03 8.63609620e-05]\ndQsin: torch.Size([4]) torch.float64 \n[0.01324857 0.00707162 0.03841005 0.00151529]\nloss: None None \n-0.009571223668505026\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 7\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 8\n[10/04/23 08:06:54][INFO][common.py:97] - energy: torch.Size([2, 4]) torch.float64 \n[[-13.98883304  -7.11601894  -9.48035637  -3.92143691]\n [-13.99184124  -7.1014651   -9.49438875  -4.11672224]]\nlogprob: torch.Size([2, 4]) torch.float64 \n[[-13.98883304  -7.11601894  -9.48035637  -3.92143691]\n [-13.99184124  -7.1014651   -9.49438875  -4.11672224]]\nlogdet: torch.Size([2, 4]) torch.float64 \n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]]\nacc: torch.Size([4]) torch.float64 \n[1.         0.98555155 1.         1.        ]\nsumlogdet: torch.Size([4]) torch.float64 \n[0. 0. 0. 0.]\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.4385061  0.34539504 0.04537868 0.37245688]\nsinQ: torch.Size([4]) torch.float64 \n[0.0153556  0.00315862 0.11135176 0.00892928]\nintQ: torch.Size([4]) torch.float64 \n[0.00087516 0.00018002 0.00634629 0.00050891]\ndQint: torch.Size([4]) torch.float64 \n[0.00082473 0.00022505 0.00010956 0.00055608]\ndQsin: torch.Size([4]) torch.float64 \n[0.01447065 0.00394877 0.00192226 0.00975699]\nloss: None None \n-0.010424735653495517\n[10/04/23 08:06:54][INFO][experiment.py:121] - STEP: 9\n[10/04/23 08:06:54][INFO][2419635544.py:14] - checkSU(x_hmc): (tensor[4] f64 x‚àà[2.562e-16, 4.133e-16] Œº=3.159e-16 œÉ=7.356e-17 [2.562e-16, 2.620e-16, 3.323e-16, 4.133e-16], tensor[4] f64 x‚àà[3.601e-16, 7.415e-16] Œº=5.139e-16 œÉ=1.696e-16 [3.601e-16, 4.134e-16, 5.404e-16, 7.415e-16])\n[10/04/23 08:06:54][INFO][2088423886.py:19] - Saving energy to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:54][INFO][2088423886.py:19] - Saving logprob to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:55][INFO][2088423886.py:19] - Saving logdet to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:55][INFO][2088423886.py:19] - Saving acc to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:55][INFO][2088423886.py:19] - Saving sumlogdet to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:55][INFO][2088423886.py:19] - Saving acc_mask to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:56][INFO][2088423886.py:19] - Saving plaqs to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:56][INFO][2088423886.py:19] - Saving sinQ to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:56][INFO][2088423886.py:19] - Saving intQ to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:56][INFO][2088423886.py:19] - Saving dQint to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:57][INFO][2088423886.py:19] - Saving dQsin to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n[10/04/23 08:06:57][INFO][2088423886.py:19] - Saving loss to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/HMC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# ptExpSU3.trainer.dynamics.init_weights(\n#     method='uniform',\n#     min=-1e-16,\n#     max=1e-16,\n#     bias=True,\n#     # xeps=0.001,\n#     # veps=0.001,\n# )\nxeval, history_eval = evaluate(\n    nsteps=10,\n    exp=ptExpSU3,\n    beta=6.0,\n    x=state.x,\n    job_type='eval',\n    nlog=1,\n    nprint=2,\n    grab=True,\n)\nxeval = ptExpSU3.trainer.dynamics.unflatten(xeval)\nlog.info(f\"checkSU(x_eval): {g.checkSU(xeval)}\")\nplot_metrics(history_eval.history, title='Evaluate', marker='.')\n\n[10/04/23 08:06:58][INFO][experiment.py:117] - Running 10 steps of eval at beta=6.0000\n[10/04/23 08:06:58][INFO][experiment.py:121] - STEP: 0\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 1\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 2\n[10/04/23 08:06:59][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[ -9.93909722 -11.71406924 -13.98390472  -6.91867768]\n [ -9.64725014 -11.76741361 -13.84813463  -6.57255943]\n [ -9.24332693 -11.64892261 -13.56752346  -6.14914933]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[ -9.93909722 -11.71406924 -13.98390472  -6.91867768]\n [ -9.57527769 -11.61717321 -13.6004816   -6.52241563]\n [ -9.17429537 -11.68892811 -13.56843895  -6.15131339]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.07197245 -0.1502404  -0.24765303 -0.0501438 ]\n [-0.06903157  0.0400055   0.00091548  0.00216406]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.07197245 -0.1502404  -0.24765303 -0.0501438 ]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[0.         0.         0.         0.        ]\n [0.         0.         0.         0.        ]\n [0.00294088 0.1902459  0.24856851 0.05230786]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.07197245 -0.1502404  -0.24765303 -0.0501438 ]\n [-0.06903157  0.0400055   0.00091548  0.00216406]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.46542615 0.97517227 0.66003278 0.46423505]\nsumlogdet: torch.Size([4]) torch.float64 \n[-0.06903157  0.0400055   0.00091548  0.00216406]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.16767915 0.37381953 0.37383779 0.20119684]\nsinQ: torch.Size([4]) torch.float64 \n[ 0.04301257  0.01916423  0.01386744 -0.01006018]\nintQ: torch.Size([4]) torch.float64 \n[ 0.00245142  0.00109223  0.00079035 -0.00057336]\ndQint: torch.Size([4]) torch.float64 \n[0.00119233 0.00094291 0.00155372 0.00095932]\ndQsin: torch.Size([4]) torch.float64 \n[0.0209205  0.01654419 0.02726158 0.01683214]\nloss: None None \n-0.020710585677662853\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 3\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 4\n[10/04/23 08:06:59][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-12.85390515 -19.69124648 -23.34418961 -11.83338904]\n [-12.61930827 -19.83006702 -23.39287265 -12.32972948]\n [-12.22362162 -18.93555772 -22.24709415 -12.09553454]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-12.85390515 -19.69124648 -23.34418961 -11.83338904]\n [-12.65387143 -19.71055885 -23.17380781 -12.2815458 ]\n [-12.22896701 -18.91997701 -22.23396345 -12.07717473]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.03456316 -0.11950817 -0.21906484 -0.04818368]\n [ 0.00534539 -0.01558072 -0.01313071 -0.01835981]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.03456316 -0.11950817 -0.21906484 -0.04818368]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [-0.02921778  0.10392745  0.20593414  0.02982387]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.03456316 -0.11950817 -0.21906484 -0.04818368]\n [ 0.00534539 -0.01558072 -0.01313071 -0.01835981]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.53529454 0.46242566 0.32948444 1.        ]\nsumlogdet: torch.Size([4]) torch.float64 \n[ 0.00534539 -0.         -0.         -0.01835981]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 0. 0. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.30234966 0.55960731 0.69219294 0.31462515]\nsinQ: torch.Size([4]) torch.float64 \n[0.02246026 0.01034247 0.01407288 0.00475271]\nintQ: torch.Size([4]) torch.float64 \n[0.00128008 0.00058945 0.00080206 0.00027087]\ndQint: torch.Size([4]) torch.float64 \n[0.0017964  0.         0.         0.00236045]\ndQsin: torch.Size([4]) torch.float64 \n[0.03151961 0.         0.         0.04141642]\nloss: None None \n-0.015773998192892276\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 5\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 6\n[10/04/23 08:06:59][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-19.55645935 -20.86462233 -20.90289315 -11.80938497]\n [-19.27554945 -20.60377855 -20.79816694 -11.77715066]\n [-18.96590202 -20.34010565 -20.641842   -11.43213333]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-19.55645935 -20.86462233 -20.90289315 -11.80938497]\n [-19.31960696 -20.45738215 -20.56264778 -11.72755736]\n [-18.97671809 -20.35406438 -20.61748015 -11.4626642 ]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.04405751 -0.14639641 -0.23551916 -0.0495933 ]\n [ 0.01081607  0.01395873 -0.02436185  0.03053087]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.04405751 -0.14639641 -0.23551916 -0.0495933 ]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [-0.03324145  0.16035514  0.21115731  0.08012417]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.04405751 -0.14639641 -0.23551916 -0.0495933 ]\n [ 0.01081607  0.01395873 -0.02436185  0.03053087]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.56004325 0.60016062 0.75170374 0.70700272]\nsumlogdet: torch.Size([4]) torch.float64 \n[ 0.01081607  0.01395873 -0.02436185  0.03053087]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.50284475 0.55960731 0.58704547 0.23919369]\nsinQ: torch.Size([4]) torch.float64 \n[-0.01053072  0.01034247  0.01918416 -0.03898123]\nintQ: torch.Size([4]) torch.float64 \n[-0.00060018  0.00058945  0.00109337 -0.00222166]\ndQint: torch.Size([4]) torch.float64 \n[0.00135638 0.00120177 0.00227558 0.00031006]\ndQsin: torch.Size([4]) torch.float64 \n[0.02379895 0.02108615 0.03992728 0.00544025]\nloss: None None \n-0.016508422822688693\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 7\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 8\n[10/04/23 08:06:59][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-18.07899101 -28.71248658 -13.48019371 -14.59335827]\n [-17.76685303 -28.30437183 -12.76586787 -14.82013678]\n [-17.05030815 -28.78619363 -11.86821313 -14.6282822 ]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-18.07899101 -28.71248658 -13.48019371 -14.59335827]\n [-17.86336929 -28.37337191 -12.58082071 -14.75738913]\n [-17.21060337 -28.90503573 -11.8680323  -14.61315147]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n [ 9.65162556e-02  6.90000737e-02 -1.85047158e-01 -6.27476486e-02]\n [ 1.60295223e-01  1.18842098e-01 -1.80827316e-04 -1.51307243e-02]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.09651626  0.06900007 -0.18504716 -0.06274765]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[0.         0.         0.         0.        ]\n [0.         0.         0.         0.        ]\n [0.06377897 0.04984202 0.18486633 0.04761692]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n [ 9.65162556e-02  6.90000737e-02 -1.85047158e-01 -6.27476486e-02]\n [ 1.60295223e-01  1.18842098e-01 -1.80827316e-04 -1.51307243e-02]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.41962759 1.         0.19945604 1.        ]\nsumlogdet: torch.Size([4]) torch.float64 \n[ 0.16029522  0.1188421  -0.         -0.01513072]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 0. 1.]\nplaqs: torch.Size([4]) torch.float64 \n[0.62270466 0.74549143 0.53797573 0.24602781]\nsinQ: torch.Size([4]) torch.float64 \n[ 0.01834668  0.00603678 -0.01653119 -0.05096747]\nintQ: torch.Size([4]) torch.float64 \n[ 0.00104564  0.00034406 -0.00094216 -0.0029048 ]\ndQint: torch.Size([4]) torch.float64 \n[0.00191687 0.00024381 0.         0.00046954]\ndQsin: torch.Size([4]) torch.float64 \n[0.03363338 0.0042779  0.         0.00823858]\nloss: None None \n-0.01735800592796972\n[10/04/23 08:06:59][INFO][experiment.py:121] - STEP: 9\n[10/04/23 08:06:59][INFO][1629827420.py:20] - checkSU(x_eval): (tensor[4] f64 x‚àà[9.577e-14, 0.024] Œº=0.009 œÉ=0.012 [0.024, 2.063e-13, 0.014, 9.577e-14], tensor[4] f64 x‚àà[1.790e-13, 0.034] Œº=0.013 œÉ=0.016 [0.034, 3.935e-13, 0.016, 1.790e-13])\n[10/04/23 08:06:59][INFO][2088423886.py:19] - Saving energy to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:06:59][INFO][2088423886.py:19] - Saving logprob to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:06:59][INFO][2088423886.py:19] - Saving logdet to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:06:59][INFO][2088423886.py:19] - Saving sldf to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:00][INFO][2088423886.py:19] - Saving sldb to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:00][INFO][2088423886.py:19] - Saving sld to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:00][INFO][2088423886.py:19] - Saving xeps to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:01][INFO][2088423886.py:19] - Saving veps to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:01][INFO][2088423886.py:19] - Saving acc to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:01][INFO][2088423886.py:19] - Saving sumlogdet to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:01][INFO][2088423886.py:19] - Saving beta to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:01][INFO][2088423886.py:19] - Saving acc_mask to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:02][INFO][2088423886.py:19] - Saving plaqs to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:02][INFO][2088423886.py:19] - Saving sinQ to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:02][INFO][2088423886.py:19] - Saving intQ to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:02][INFO][2088423886.py:19] - Saving dQint to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:03][INFO][2088423886.py:19] - Saving dQsin to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n[10/04/23 08:07:03][INFO][2088423886.py:19] - Saving loss to /Users/samforeman/projects/saforem2/l2hmc-qcd/qmd/outputs/plots-4dSU3/Evaluate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhistory = {}\nx = state.x\nfor step in range(20):\n    log.info(f'TRAIN STEP: {step}')\n    x, metrics = ptExpSU3.trainer.train_step((x, state.beta))\n    if (step &gt; 0 and step % 2 == 0):\n        print_dict(metrics, grab=True)\n    if (step &gt; 0 and step % 1 == 0):\n        for key, val in metrics.items():\n            try:\n                history[key].append(val)\n            except KeyError:\n                history[key] = [val]\n\n[10/04/23 08:07:05][INFO][2642635469.py:4] - TRAIN STEP: 0\n[10/04/23 08:07:05][INFO][2642635469.py:4] - TRAIN STEP: 1\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 2\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-20.11355156 -13.83759796  -4.51987377 -11.45297864]\n [-19.63407248 -12.82094906  -3.89140218 -11.38944608]\n [-18.91054695 -12.57901193  -3.60837652 -10.80563673]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-20.11355156 -13.83759796  -4.51987377 -11.45297864]\n [-19.5349711  -12.66848527  -3.6937792  -11.31223158]\n [-18.98136385 -12.5501776   -3.58081924 -10.80513544]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.09910138 -0.15246379 -0.19762298 -0.0772145 ]\n [ 0.07081689 -0.02883433 -0.02755728 -0.00050128]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.09910138 -0.15246379 -0.19762298 -0.0772145 ]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[0.         0.         0.         0.        ]\n [0.         0.         0.         0.        ]\n [0.16991827 0.12362946 0.17006571 0.07671321]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.09910138 -0.15246379 -0.19762298 -0.0772145 ]\n [ 0.07081689 -0.02883433 -0.02755728 -0.00050128]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.32232732 0.2759818  0.39099734 0.52317294]\nsumlogdet: torch.Size([4]) torch.float64 \n[ 0.07081689 -0.         -0.02755728 -0.00050128]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 0. 1. 1.]\nloss: None None \n-0.009001684302756496\nplaqs: torch.Size([4]) torch.float64 \n[0.36183972 0.43746352 0.02919545 0.2244051 ]\nsinQ: torch.Size([4]) torch.float64 \n[ 0.01845919 -0.00937014  0.00653818  0.03579483]\nintQ: torch.Size([4]) torch.float64 \n[ 0.00105205 -0.00053403  0.00037263  0.00204006]\ndQint: torch.Size([4]) torch.float64 \n[0.00068181 0.         0.00033711 0.001986  ]\ndQsin: torch.Size([4]) torch.float64 \n[0.01196306 0.         0.00591496 0.0348463 ]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 3\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 4\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-16.99217625 -18.05099071 -10.04985909  -7.1340411 ]\n [-16.61047626 -17.84035555  -9.68866118  -7.14912011]\n [-16.28336399 -18.36191548  -9.14330041  -5.86613539]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-16.99217625 -18.05099071 -10.04985909  -7.1340411 ]\n [-16.4708106  -17.6654387   -9.64363079  -7.10061592]\n [-16.17915148 -18.35588077  -9.12314899  -5.81814653]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.13966566 -0.17491685 -0.04503039 -0.04850419]\n [-0.10421251 -0.0060347  -0.02015142 -0.04798886]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.13966566 -0.17491685 -0.04503039 -0.04850419]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[0.         0.         0.         0.        ]\n [0.         0.         0.         0.        ]\n [0.03545315 0.16888215 0.02487897 0.00051533]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.13966566 -0.17491685 -0.04503039 -0.04850419]\n [-0.10421251 -0.0060347  -0.02015142 -0.04798886]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.44351451 1.         0.39585389 0.26823426]\nsumlogdet: torch.Size([4]) torch.float64 \n[-0.10421251 -0.0060347  -0.         -0.        ]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 0. 0.]\nloss: None None \n-0.014134476436103167\nplaqs: torch.Size([4]) torch.float64 \n[0.46996628 0.45118214 0.18011337 0.30434348]\nsinQ: torch.Size([4]) torch.float64 \n[ 0.03170589 -0.01147666  0.05118318 -0.00268528]\nintQ: torch.Size([4]) torch.float64 \n[ 0.00180702 -0.00065409  0.00291709 -0.00015304]\ndQint: torch.Size([4]) torch.float64 \n[0.00065855 0.00207145 0.         0.        ]\ndQsin: torch.Size([4]) torch.float64 \n[0.01155495 0.03634551 0.         0.        ]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 5\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 6\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-22.17358114 -18.47427308  -2.95308721 -11.62559496]\n [-21.83570903 -18.22818944  -2.4429929  -11.20037746]\n [-21.81748065 -18.37604145  -2.70650275 -10.07465326]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-22.17358114 -18.47427308  -2.95308721 -11.62559496]\n [-21.84417608 -18.06424191  -2.60692839 -11.12021881]\n [-21.89172921 -18.39051785  -2.62673381 -10.08631078]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.00846706 -0.16394753  0.16393549 -0.08015865]\n [ 0.07424856  0.0144764  -0.07976894  0.01165751]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.00846706 -0.16394753  0.16393549 -0.08015865]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [ 0.0657815   0.17842393 -0.24370443  0.09181616]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.00846706 -0.16394753  0.16393549 -0.08015865]\n [ 0.07424856  0.0144764  -0.07976894  0.01165751]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.75438538 0.91965634 0.72155015 0.21453462]\nsumlogdet: torch.Size([4]) torch.float64 \n[ 0.07424856  0.0144764  -0.07976894  0.01165751]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nloss: None None \n-0.019461443124629982\nplaqs: torch.Size([4]) torch.float64 \n[0.43455592 0.53410535 0.15486684 0.30434348]\nsinQ: torch.Size([4]) torch.float64 \n[-0.01746029  0.01216864  0.01077427 -0.00268528]\nintQ: torch.Size([4]) torch.float64 \n[-0.00099512  0.00069353  0.00061406 -0.00015304]\ndQint: torch.Size([4]) torch.float64 \n[0.0016496  0.00074394 0.00087095 0.0014133 ]\ndQsin: torch.Size([4]) torch.float64 \n[0.02894377 0.01305311 0.01528163 0.02479769]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 7\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 8\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-28.94977982 -23.93414904  -5.02251262 -20.14381224]\n [-28.26856486 -24.03288661  -4.19892196 -20.37397293]\n [-27.78459946 -23.56989642  -3.56347647 -20.06837893]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-28.94977982 -23.93414904  -5.02251262 -20.14381224]\n [-28.25995613 -23.85544268  -4.41858446 -20.21769226]\n [-27.77851779 -23.59675098  -3.59362754 -20.09340966]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.00860873 -0.17744392  0.2196625  -0.15628067]\n [-0.00608167  0.02685456  0.03015107  0.02503073]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.00860873 -0.17744392  0.2196625  -0.15628067]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [ 0.00252705  0.20429848 -0.18951143  0.1813114 ]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.00860873 -0.17744392  0.2196625  -0.15628067]\n [-0.00608167  0.02685456  0.03015107  0.02503073]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.3099755  0.71362471 0.23957588 0.95084655]\nsumlogdet: torch.Size([4]) torch.float64 \n[-0.          0.          0.          0.02503073]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[0. 0. 0. 1.]\nloss: None None \n-0.015584381253787876\nplaqs: torch.Size([4]) torch.float64 \n[0.7403035  0.65171197 0.31634181 0.47457693]\nsinQ: torch.Size([4]) torch.float64 \n[-0.00859781 -0.00165773 -0.00396142  0.00092218]\nintQ: torch.Size([4]) torch.float64 \n[-4.90016318e-04 -9.44793472e-05 -2.25773828e-04  5.25577319e-05]\ndQint: torch.Size([4]) torch.float64 \n[0.         0.         0.         0.00032025]\ndQsin: torch.Size([4]) torch.float64 \n[0.         0.         0.         0.00561914]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 9\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 10\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-31.39076793 -27.31985011 -19.54217484 -21.1104468 ]\n [-31.0614939  -27.06503105 -19.07066872 -21.3910664 ]\n [-30.84961158 -26.95602155 -18.69349894 -20.00516103]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-31.39076793 -27.31985011 -19.54217484 -21.1104468 ]\n [-31.06645234 -26.87717262 -19.24520362 -21.21648217]\n [-30.82929486 -26.99061806 -18.65210819 -20.00045772]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.00495844 -0.18785843  0.1745349  -0.17458422]\n [-0.02031672  0.03459652 -0.04139075 -0.00470331]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.00495844 -0.18785843  0.1745349  -0.17458422]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [-0.02527516  0.22245494 -0.21592565  0.16988091]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.00495844 -0.18785843  0.1745349  -0.17458422]\n [-0.02031672  0.03459652 -0.04139075 -0.00470331]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.57036826 0.71947605 0.41062839 0.32956256]\nsumlogdet: torch.Size([4]) torch.float64 \n[-0.02031672  0.03459652 -0.04139075 -0.        ]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 0.]\nloss: None None \n-0.011982253415392767\nplaqs: torch.Size([4]) torch.float64 \n[0.7403035  0.65171197 0.45503328 0.62236101]\nsinQ: torch.Size([4]) torch.float64 \n[-0.00859781 -0.00165773 -0.00088107  0.01924983]\nintQ: torch.Size([4]) torch.float64 \n[-4.90016318e-04 -9.44793472e-05 -5.02151834e-05  1.09710862e-03]\ndQint: torch.Size([4]) torch.float64 \n[0.00043531 0.00061571 0.00043569 0.        ]\ndQsin: torch.Size([4]) torch.float64 \n[0.00763793 0.01080326 0.00764459 0.        ]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 11\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 12\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-31.42781825 -21.38032064 -19.16557544 -24.26085164]\n [-30.89428362 -21.22321069 -18.90945902 -23.55378881]\n [-30.46921912 -20.86892045 -18.93287679 -23.36450964]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-31.42781825 -21.38032064 -19.16557544 -24.26085164]\n [-30.88117485 -21.00988585 -19.11822465 -23.54366138]\n [-30.55010401 -20.84704698 -19.01058406 -23.31072478]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.01310877 -0.21332485  0.20876563 -0.01012743]\n [ 0.08088489 -0.02187348  0.07770727 -0.05378486]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.01310877 -0.21332485  0.20876563 -0.01012743]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [ 0.09399365  0.19145137 -0.13105835 -0.04365743]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.01310877 -0.21332485  0.20876563 -0.01012743]\n [ 0.08088489 -0.02187348  0.07770727 -0.05378486]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.41573209 0.58668123 0.85642256 0.38669196]\nsumlogdet: torch.Size([4]) torch.float64 \n[ 0.08088489 -0.          0.07770727 -0.        ]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 0. 1. 0.]\nloss: None None \n-0.016004372395409854\nplaqs: torch.Size([4]) torch.float64 \n[0.84037172 0.65154716 0.42313337 0.73863172]\nsinQ: torch.Size([4]) torch.float64 \n[ 1.47285038e-03 -1.56397921e-03 -6.09823914e-03 -6.72724198e-05]\nintQ: torch.Size([4]) torch.float64 \n[ 8.39424059e-05 -8.91361261e-05 -3.47557954e-04 -3.83406818e-06]\ndQint: torch.Size([4]) torch.float64 \n[1.23274406e-05 0.00000000e+00 5.10271910e-04 0.00000000e+00]\ndQsin: torch.Size([4]) torch.float64 \n[0.0002163  0.         0.00895321 0.        ]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 13\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 14\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-29.59240183 -21.94551736 -28.47707495 -20.59708329]\n [-29.48303373 -21.10556806 -28.05877271 -20.58985545]\n [-29.39854899 -20.73632654 -27.22089443 -19.77844503]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-29.59240183 -21.94551736 -28.47707495 -20.59708329]\n [-29.40940421 -20.98154179 -28.17860182 -20.541757  ]\n [-29.31460821 -20.72420952 -27.17276265 -19.77710774]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.07362952 -0.12402627  0.11982911 -0.04809845]\n [-0.08394078 -0.01211702 -0.04813178 -0.00133729]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.07362952 -0.12402627  0.11982911 -0.04809845]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [-0.01031126  0.11190925 -0.16796089  0.04676117]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.07362952 -0.12402627  0.11982911 -0.04809845]\n [-0.08394078 -0.01211702 -0.04813178 -0.00133729]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.75745313 0.2948443  0.27135909 0.44044242]\nsumlogdet: torch.Size([4]) torch.float64 \n[-0.08394078 -0.01211702 -0.04813178 -0.00133729]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 1. 1. 1.]\nloss: None None \n-0.012984717158635528\nplaqs: torch.Size([4]) torch.float64 \n[0.75491793 0.6547223  0.63304782 0.73863172]\nsinQ: torch.Size([4]) torch.float64 \n[ 3.85535809e-03 -1.41124889e-02 -1.46423245e-02 -6.72724198e-05]\nintQ: torch.Size([4]) torch.float64 \n[ 2.19729063e-04 -8.04315419e-04 -8.34512428e-04 -3.83406817e-06]\ndQint: torch.Size([4]) torch.float64 \n[0.00065824 0.00058615 0.00017334 0.00014198]\ndQsin: torch.Size([4]) torch.float64 \n[0.01154945 0.01028462 0.00304149 0.00249122]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 15\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 16\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-27.90336074 -24.58447835 -27.70507628 -25.1095963 ]\n [-27.4557147  -23.38939397 -26.86035304 -24.74188789]\n [-26.76730611 -23.12311187 -26.13507215 -24.81611966]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-27.90336074 -24.58447835 -27.70507628 -25.1095963 ]\n [-27.42721443 -23.25741435 -27.03208626 -24.69073936]\n [-26.83629231 -23.14150881 -26.14979085 -24.84522864]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.02850027 -0.13197962  0.17173322 -0.05114852]\n [ 0.0689862   0.01839694  0.0147187   0.02910898]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.02850027 -0.13197962  0.17173322 -0.05114852]\n [ 0.          0.          0.          0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [ 0.09748647  0.15037655 -0.15701452  0.0802575 ]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [-0.02850027 -0.13197962  0.17173322 -0.05114852]\n [ 0.0689862   0.01839694  0.0147187   0.02910898]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.34401554 0.23622524 0.21112911 0.76769124]\nsumlogdet: torch.Size([4]) torch.float64 \n[0.0689862  0.         0.0147187  0.02910898]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[1. 0. 1. 1.]\nloss: None None \n-0.011869373548195221\nplaqs: torch.Size([4]) torch.float64 \n[0.82255532 0.72111137 0.69612456 0.72896623]\nsinQ: torch.Size([4]) torch.float64 \n[-0.00564947 -0.00444414 -0.01693866  0.00255894]\nintQ: torch.Size([4]) torch.float64 \n[-0.00032198 -0.00025329 -0.00096539  0.00014584]\ndQint: torch.Size([4]) torch.float64 \n[8.49293564e-05 0.00000000e+00 3.84992539e-04 3.15784764e-04]\ndQsin: torch.Size([4]) torch.float64 \n[0.00149017 0.         0.00675506 0.00554075]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 17\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 18\n[10/04/23 08:07:06][INFO][common.py:97] - energy: torch.Size([3, 4]) torch.float64 \n[[-28.74207541 -24.8965513  -32.81235279 -22.59228204]\n [-27.98828099 -23.91465789 -32.28912627 -22.61626646]\n [-27.23785728 -24.01606216 -31.51716178 -21.73978358]]\nlogprob: torch.Size([3, 4]) torch.float64 \n[[-28.74207541 -24.8965513  -32.81235279 -22.59228204]\n [-28.07501629 -23.97865766 -32.35996206 -22.61968433]\n [-27.18635944 -23.93497767 -31.62224319 -21.75485085]]\nlogdet: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.0867353   0.06399977  0.07083579  0.00341787]\n [-0.05149783 -0.08108449  0.10508142  0.01506727]]\nsldf: torch.Size([3, 4]) torch.float64 \n[[0.         0.         0.         0.        ]\n [0.0867353  0.06399977 0.07083579 0.00341787]\n [0.         0.         0.         0.        ]]\nsldb: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.          0.          0.          0.        ]\n [-0.13823313 -0.14508427  0.03424563  0.0116494 ]]\nsld: torch.Size([3, 4]) torch.float64 \n[[ 0.          0.          0.          0.        ]\n [ 0.0867353   0.06399977  0.07083579  0.00341787]\n [-0.05149783 -0.08108449  0.10508142  0.01506727]]\nxeps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nveps: torch.Size([3]) torch.float64 \n[0.1 0.1 0.1]\nacc: torch.Size([4]) torch.float64 \n[0.21103823 0.38229083 0.30418792 0.43282093]\nsumlogdet: torch.Size([4]) torch.float64 \n[-0.         -0.08108449  0.          0.01506727]\nbeta: torch.Size([]) torch.float64 \n6.0\nacc_mask: torch.Size([4]) torch.float32 \n[0. 1. 0. 1.]\nloss: None None \n-0.00985098143962743\nplaqs: torch.Size([4]) torch.float64 \n[0.85381281 0.70579842 0.80681173 0.75974167]\nsinQ: torch.Size([4]) torch.float64 \n[-0.00332841 -0.00489329 -0.01271997  0.00506889]\nintQ: torch.Size([4]) torch.float64 \n[-0.0001897  -0.00027888 -0.00072495  0.00028889]\ndQint: torch.Size([4]) torch.float64 \n[0.         0.00045467 0.         0.00140838]\ndQsin: torch.Size([4]) torch.float64 \n[0.         0.00797764 0.         0.02471136]\n[10/04/23 08:07:06][INFO][2642635469.py:4] - TRAIN STEP: 19\n\n\n\nx = ptExpSU3.trainer.dynamics.unflatten(x)\nlog.info(f\"checkSU(x_train): {g.checkSU(x)}\")\n# plot_metrics(history, title='train', marker='.')\n\n[10/04/23 08:07:06][INFO][1630590238.py:2] - checkSU(x_train): (tensor[4] f64 x‚àà[3.838e-16, 0.018] Œº=0.008 œÉ=0.009 [0.018, 0.014, 3.838e-16, 9.135e-13], tensor[4] f64 x‚àà[6.307e-16, 0.026] Œº=0.011 œÉ=0.013 [0.026, 0.017, 6.307e-16, 1.818e-12])\n\n\n\nprint(history.keys())\n\ndict_keys(['energy', 'logprob', 'logdet', 'sldf', 'sldb', 'sld', 'xeps', 'veps', 'acc', 'sumlogdet', 'beta', 'acc_mask', 'loss', 'plaqs', 'sinQ', 'intQ', 'dQint', 'dQsin'])\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2023,\n  author = {Foreman, Sam},\n  title = {4D {\\$SU(3)\\$} {Model}},\n  date = {2023-10-04},\n  url = {https://saforem2.github.io/l2hmc-qcd/qmd/l2hmc-4DSU3.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. ‚Äú4D $SU(3)$ Model.‚Äù October 4, 2023. https://saforem2.github.io/l2hmc-qcd/qmd/l2hmc-4DSU3.html."
  },
  {
    "objectID": "qmd/slides.html",
    "href": "qmd/slides.html",
    "title": "Recent Talks",
    "section": "",
    "text": "\\hspace{2pt} MLMC: Machine Learning Monte Carlo @ Lattice 2023 (07/2023)\n\n\n\n\n\n\n\n&lt;p&gt;\nYour browser does not support iframes.\n&lt;/p&gt;\n\n\n\n\n\n\n\n\n\n\n \\hspace{2pt} Generative Modeling and Efficient Sampling @ PASC23 (07/2023)\n\n\n\n\n\n\n\n\n&lt;p&gt;\nYour browser does not support iframes.\n&lt;/p&gt;\n\n\n\n\n\n\n\n\n\n\n \\hspace{2pt} Efficient Sampling for Lattice Gauge Theory @ Deep Fridays @ U. Bologna (04/2023)\n\n\n\n\n\n\n\n&lt;p&gt;\nYour browser does not support iframes.\n&lt;/p&gt;\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{foreman2023,\n  author = {Foreman, Sam},\n  title = {Slides},\n  date = {2023-10-04},\n  url = {https://saforem2.github.io/l2hmc-qcd/qmd/slides.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. ‚ÄúSlides.‚Äù October 4, 2023. https://saforem2.github.io/l2hmc-qcd/qmd/slides.html."
  },
  {
    "objectID": "qmd/posts.html",
    "href": "qmd/posts.html",
    "title": "Posts",
    "section": "",
    "text": "U(1) Model in 2D\nSU(3) Model in 4D\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 4, 2023\n\n\nMCMC + Diffusion Sampling\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nDenoising Diffusion Probabilistic Models\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nRecent Talks\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\n2D U(1) Example\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\n4D SU(3) Model\n\n\nSam Foreman \n\n\n\n\n\n\nNo matching items\n\n\nLearn more about Quarto here."
  },
  {
    "objectID": "qmd/posts.html#external-links",
    "href": "qmd/posts.html#external-links",
    "title": "Posts",
    "section": "",
    "text": "U(1) Model in 2D\nSU(3) Model in 4D\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 4, 2023\n\n\nMCMC + Diffusion Sampling\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nDenoising Diffusion Probabilistic Models\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\nRecent Talks\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\n2D U(1) Example\n\n\nSam Foreman \n\n\n\n\nOct 4, 2023\n\n\n4D SU(3) Model\n\n\nSam Foreman \n\n\n\n\n\n\nNo matching items\n\n\nLearn more about Quarto here."
  },
  {
    "objectID": "qmd/diffusion/diffusion.html",
    "href": "qmd/diffusion/diffusion.html",
    "title": "MCMC + Diffusion Sampling",
    "section": "",
    "text": "2D U(1)\nfrom l2hmc.configs import dict_to_list_of_overrides\n\nseed = np.random.randint(0, 2**32)\nconsole.print(f\"seed = {seed}\")\n\noverrides = {\n    \"seed\": f\"{seed}\",\n    \"precision\": \"float32\",\n    \"init_wandb\": False,\n    \"init_aim\": False,\n    \"use_wandb\": False,\n    \"dynamics\": {\n        \"latvolume\": [32, 32],\n        \"nleapfrog\": 10,\n        \"nchains\": 16,\n        \"eps\": 0.05,\n    },\n    \"network\": {\n        \"use_batch_norm\": False,\n    },\n    'annealing_schedule': {\n        'beta_init': 6.0,\n        'beta_final': 6.0,\n    },\n\n}\nOVERRIDES = dict_to_list_of_overrides(overrides)\n\nseed = 1675333995\nfrom pathlib import Path\nfrom l2hmc.common import get_timestamp\nfrom enrich.console import get_theme, Console\nconsole = Console(theme=get_theme())\n\nOUTDIR = Path(\n    'l2hmc-diffusion-2dU1'\n).joinpath(get_timestamp(\"%Y-%m-%d\"))\nOUTDIR.mkdir(exist_ok=True, parents=True)\nconsole.print(f\"OUTDIR: {OUTDIR}\")\n\ndate = get_timestamp('%Y-%m-%d')\nPLOTS_DIR = OUTDIR.joinpath('plots')\nPLOTS_DIR.mkdir(exist_ok=True, parents=True)\nconsole.print(f\"Saving figures to: {PLOTS_DIR}\")\n\nOUTDIR: l2hmc-diffusion-2dU1/2023-09-21\n\n\n\nSaving figures to: l2hmc-diffusion-2dU1/2023-09-21/plots\n#os.environ['MASTER_PORT'] = '5436'\n\nexp = build_experiment(\n    overrides=[\n        *OVERRIDES,\n        'framework=pytorch',\n        'backend=DDP'\n    ]\n)\n\n[09/21/23 12:23:55][INFO][dist.py:226] - Caught MASTER_PORT:5561 from environment!\n[09/21/23 12:23:55][INFO][dist.py:338] - Global Rank: 0 / 0\n[09/21/23 12:23:58][INFO][experiment.py:251] - Creating outputs/2023-09-21-122358/pytorch/train\n[09/21/23 12:23:58][INFO][experiment.py:251] - Creating outputs/2023-09-21-122358/pytorch/eval\n[09/21/23 12:23:58][INFO][experiment.py:251] - Creating outputs/2023-09-21-122358/pytorch/hmc\n[09/21/23 12:23:58][INFO][dist.py:226] - Caught MASTER_PORT:5561 from environment!\n[09/21/23 12:23:58][INFO][dist.py:226] - Caught MASTER_PORT:5561 from environment!\n[09/21/23 12:24:06][INFO][trainer.py:441] - Looking for checkpoints in:\n /Users/samforeman/projects/saforem2/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-32-32/nlf-10/xsplit-True/sepnets-True/merge-True/conv-8-16-32-64-128_5-3-3-3-2_2-2-2-2-2/net-16-16-16-16_dp-0.2_bn-False/pytorch\n[09/21/23 12:24:06][WARNING][trainer.py:437] - No checkpoints found to load from\n[09/21/23 12:24:06][WARNING][trainer.py:437] - Restoring global step from ckpt! self._gstep: 0\n[09/21/23 12:24:06][WARNING][trainer.py:437] - Using `torch.optim.Adam` optimizer\n[09/21/23 12:24:06][INFO][trainer.py:284] - num_params in model: 958628260\n[09/21/23 12:24:09][WARNING][trainer.py:250] - logging with freq 50 for wandb.watch\nstate = exp.trainer.dynamics.random_state(6.0)\nxdim = state.x.flatten().shape[0]\n\ndim = xdim\nlow_bound = (-np.pi) * np.ones(dim)\nhigh_bound = (np.pi) * np.ones(dim)\nsigma = 0.15\nretrains = 10\nsamples_per_retrain = 100\ndiffusion_prob = 0.1\nsns.set_context('notebook')\n\noutputs = {}\noutputs['hmc'] = exp.trainer.eval(\n    job_type='hmc',\n    beta=6.0,\n    nprint=100,\n    nchains=16,\n    eval_steps=1000\n)\n#hdset = exp.save_dataset(job_type='hmc', nchains=1)\n\n[09/21/23 12:24:21][WARNING][trainer.py:437] - Step size `eps` not specified for HMC! Using default: 0.1000 for generic HMC\n[09/21/23 12:24:21][WARNING][trainer.py:437] - x.shape (original): torch.Size([16, 2, 32, 32])\n[09/21/23 12:24:21][WARNING][trainer.py:437] - x[:nchains].shape: torch.Size([16, 2, 32, 32])\n[09/21/23 12:24:21][INFO][trainer.py:1058] - eps=0.1\nbeta=6.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x2e1b98520&gt;\nnprint=100\neval_steps=1000\nnleapfrog=20\n\n\n\n\n\n[09/21/23 12:24:24][INFO][trainer.py:1188] - hstep=0 dt=0.024 beta=6.000 loss=3.410 dQsin=0.125 dQint=0.000 energy=1586.502 logprob=1586.502 logdet=0.000 acc=0.472 sumlogdet=0.000 acc_mask=0.500 plaqs=0.909 intQ=0.000 sinQ=0.051\n[09/21/23 12:24:27][INFO][trainer.py:1188] - hstep=100 dt=0.026 beta=6.000 loss=2.876 dQsin=0.163 dQint=0.000 energy=1555.800 logprob=1555.800 logdet=0.000 acc=0.593 sumlogdet=0.000 acc_mask=0.688 plaqs=0.912 intQ=-0.125 sinQ=-0.159\n[09/21/23 12:24:31][INFO][trainer.py:1188] - hstep=200 dt=0.025 beta=6.000 loss=4.678 dQsin=0.088 dQint=0.063 energy=1569.994 logprob=1569.994 logdet=0.000 acc=0.451 sumlogdet=0.000 acc_mask=0.250 plaqs=0.912 intQ=-0.187 sinQ=-0.149\n[09/21/23 12:24:34][INFO][trainer.py:1188] - hstep=300 dt=0.024 beta=6.000 loss=14.041 dQsin=0.094 dQint=0.000 energy=1554.118 logprob=1554.118 logdet=0.000 acc=0.438 sumlogdet=0.000 acc_mask=0.438 plaqs=0.914 intQ=-0.125 sinQ=-0.114\n[09/21/23 12:24:38][INFO][trainer.py:1188] - hstep=400 dt=0.024 beta=6.000 loss=-0.739 dQsin=0.199 dQint=0.000 energy=1566.516 logprob=1566.516 logdet=0.000 acc=0.509 sumlogdet=0.000 acc_mask=0.562 plaqs=0.912 intQ=-0.437 sinQ=-0.452\n[09/21/23 12:24:41][INFO][trainer.py:1188] - hstep=500 dt=0.045 beta=6.000 loss=1.545 dQsin=0.100 dQint=0.000 energy=1570.837 logprob=1570.837 logdet=0.000 acc=0.448 sumlogdet=0.000 acc_mask=0.562 plaqs=0.911 intQ=0.125 sinQ=0.189\n[09/21/23 12:24:45][INFO][trainer.py:1188] - hstep=600 dt=0.025 beta=6.000 loss=3.780 dQsin=0.094 dQint=0.000 energy=1568.012 logprob=1568.012 logdet=0.000 acc=0.463 sumlogdet=0.000 acc_mask=0.500 plaqs=0.913 intQ=0.438 sinQ=0.466\n[09/21/23 12:24:50][INFO][trainer.py:1188] - hstep=700 dt=0.023 beta=6.000 loss=-0.902 dQsin=0.113 dQint=0.000 energy=1563.778 logprob=1563.778 logdet=0.000 acc=0.475 sumlogdet=0.000 acc_mask=0.375 plaqs=0.913 intQ=0.688 sinQ=0.628\n[09/21/23 12:24:53][INFO][trainer.py:1188] - hstep=800 dt=0.024 beta=6.000 loss=11.416 dQsin=0.061 dQint=0.000 energy=1561.427 logprob=1561.427 logdet=0.000 acc=0.339 sumlogdet=0.000 acc_mask=0.438 plaqs=0.913 intQ=0.813 sinQ=0.755\n[09/21/23 12:24:57][INFO][trainer.py:1188] - hstep=900 dt=0.028 beta=6.000 loss=1.114 dQsin=0.127 dQint=0.000 energy=1564.465 logprob=1564.465 logdet=0.000 acc=0.699 sumlogdet=0.000 acc_mask=0.625 plaqs=0.913 intQ=0.938 sinQ=0.893\n# %matplotlib inline\nfrom l2hmc.common import plot_dataset\nsns.set_context('notebook')\nhdataset = outputs['hmc']['history'].get_dataset()\nplot_dataset(hdataset, outdir=PLOTS_DIR, job_type='HMC')\n\n[09/21/23 12:25:06][INFO][plot_helpers.py:1049] - Saving figure to: l2hmc-diffusion-2dU1/2023-09-21/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[09/21/23 12:25:09][INFO][plot_helpers.py:1049] - Saving figure to: l2hmc-diffusion-2dU1/2023-09-21/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[09/21/23 12:25:11][INFO][plot_helpers.py:1049] - Saving figure to: l2hmc-diffusion-2dU1/2023-09-21/plots/ridgeplots/svgs/logdet_ridgeplot.svg\nimport torch\n\ninitial_states = []\nstate_init = exp.trainer.dynamics.random_state(6.0)\nx = state_init.x\nbeta = state_init.beta\n\nNSAMPLES = 1000\nfor idx in range(NSAMPLES + int(0.1 * NSAMPLES)):\n    if idx % 100 == 0:\n        console.print(f\"step: {idx}\")\n        \n    x, metrics = exp.trainer.hmc_step((x, beta))\n    if idx &gt; int((0.1 * NSAMPLES)):\n        initial_states.append(x)\n\ninitial_states = torch.stack(initial_states).squeeze()\ninitial_states_np = initial_states.detach().cpu().numpy()\n\nstep: 0\n\n\n\nstep: 100\n\n\n\nstep: 200\n\n\n\nstep: 300\n\n\n\nstep: 400\n\n\n\nstep: 500\n\n\n\nstep: 600\n\n\n\nstep: 700\n\n\n\nstep: 800\n\n\n\nstep: 900\n\n\n\nstep: 1000\ninitial_states_np.shape\n\n(999, 16, 2048)\nx_ = initial_states_np.reshape(-1, 16, 2, 32, 32)\ntmp_ = x_[:, 0, ...]\nconsole.print(f'{x_.shape}')\nconsole.print(f'{tmp_.shape}')\n\n(999, 16, 2, 32, 32)\n\n\n\n(999, 2, 32, 32)\nfrom l2hmc.common import savefig\n\n#x_ = initial_states_np[:100].reshape(-1, 2, 32, 32)\ntmp_ = x_[:, 0, ...]\nfig, ax = plt.subplots()\nsns.kdeplot(\n    x=tmp_[-100:, 0].flatten(),\n    y=tmp_[-100:, 1].flatten(),\n    # ax=ax,\n    cmap='viridis',\n    # ax=axes[0],\n    # cmap=\"Blues\",\n    shade=False,\n    # bw_adjust=0.5,\n    thresh=0\n)\nax.set_xlim((-4, 4))\nax.set_ylim((-4, 4))\nsavefig(\n    f'hmc_samples-{NSAMPLES}',\n    Path(PLOTS_DIR),\n    tstamp=True,\n)\n\nSaving hmc_samples-1000-2023-09-21-122840 to l2hmc-diffusion-2dU1/2023-09-21/plots\nclass Diffusion:\n    def __init__(\n            self,\n            noise_steps: int = 1000,\n            beta_start: float = 1e-4,\n            beta_end: float = 0.02,\n            nchannels: int = 2,\n            img_size: int = 256,\n            device: str = \"cuda\"\n    ):\n        self.noise_steps = noise_steps\n        self.beta_start = beta_start\n        self.beta_end = beta_end\n        self.img_size = img_size\n        self.device = device\n        self.nchannels = nchannels\n\n        self.beta = self.prepare_noise_schedule().to(device)\n        self.alpha = 1. - self.beta\n        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n\n    def prepare_noise_schedule(self):\n        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n\n    def noise_images(self, x, t):\n        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n        sqrt_one_minus_alpha_hat = torch.sqrt(\n            1 - self.alpha_hat[t]\n        )[:, None, None, None]\n        eps = torch.randn_like(x)\n        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * eps, eps\n\n    def sample_timesteps(self, n):\n        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n\n    def sample(self, model, n):\n        # console.print(f\"Sampling {n} new images....\")\n        model.eval()\n        with torch.no_grad():\n            x = torch.randn(\n                (n, self.nchannels, self.img_size, self.img_size)\n            ).to(self.device)\n            sample_bar = tqdm(\n                reversed(range(1, self.noise_steps)),\n                position=0,\n                total=self.noise_steps - 1,\n                dynamic_ncols=True,\n            )\n            for i in sample_bar:\n                t = (torch.ones(n) * i).long().to(self.device)\n                predicted_noise = model(x, t)\n                alpha = self.alpha[t][:, None, None, None]\n                alpha_hat = self.alpha_hat[t][:, None, None, None]\n                beta = self.beta[t][:, None, None, None]\n                if i &gt; 1:\n                    noise = torch.randn_like(x)\n                else:\n                    noise = torch.zeros_like(x)\n                x = (\n                    (1 / torch.sqrt(alpha))\n                    * (\n                        x \n                        - ((1 - alpha) / (torch.sqrt(1 - alpha_hat)))\n                        * predicted_noise\n                    ) \n                    + (torch.sqrt(beta) * noise)\n                )\n        model.train()\n        x = (x + np.pi) % (2 * np.pi) - np.pi\n        return x\ninitial_states.shape\n\ntorch.Size([999, 16, 2048])\nTrain Diffusion Model\nimport torchvision\nimport os\nimport random\nfrom pathlib import Path\nimport torch\nimport torchvision\nimport torchvision.transforms as T\nimport numpy as np\nfrom PIL import Image\n#from fastdownload import FastDownload\nfrom torch.utils.data import DataLoader\n\ndef save_images(images, path, **kwargs):\n    grid = torchvision.utils.make_grid(images, **kwargs)\n    ndarr = grid.permute(1, 2, 0).to('cpu').numpy()\n    im = Image.fromarray(ndarr)\n    im.save(path)\nBuild Diffusion Model with UNet Architecure\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\nfrom l2hmc.common import savefig\nfrom l2hmc.diffusion.modules import NoiseScheduler, UNet\nfrom l2hmc.diffusion import ddpm\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nconfig = {\n    'channels_in': 2,\n    'channels_out': 2,\n    'train_batch_size': 5,\n    'learning_rate': 0.001,\n    'num_epochs': 1,\n    'noise_steps': 100,\n    'beta': 6.0,\n    'img_size': 32,\n    'retrains': 10,\n    'samples_per_retrain': 500,\n    'diffusion_prob': 0.1,\n}\n\nmodel = UNet(c_in=2, c_out=2)\n\ndataset = TensorDataset(initial_states.reshape(-1, 2, 32, 32))\ndataloader = DataLoader(\n    dataset,\n    batch_size=config[\"train_batch_size\"],\n    shuffle=False,\n    drop_last=True\n)\n\n\noptimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\nmse = nn.MSELoss()\ndiffusion = Diffusion(\n    noise_steps=100,\n    img_size=32,\n    device=DEVICE,\n    nchannels=2,\n)\n#logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\nl = len(dataloader)\n\nrun_name = 'diffusion2dU1'\nPerform initial training on HMC samples\nfrom torch import optim\ndevice = 'cpu'\n#dataloader = get_data(args)\n#model = UNet().to(device)\n\nsampled_images_history = []\n\nfor epoch in range(config['num_epochs']):\n    console.print(f\"Starting epoch {epoch}:\")\n    pbar = tqdm(dataloader)\n    for i, images in enumerate(pbar):\n        if isinstance(images, (tuple, list)) and len(images) == 1:\n            images = images[0]\n        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n        x_t, noise = diffusion.noise_images(images, t)\n        predicted_noise = model(x_t, t)\n        loss = mse(noise, predicted_noise)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        pbar.set_postfix({'epoch': epoch, 'batch': i, 'MSE': loss.item()})\n    console.print(f'epoch: {epoch}, loss: {loss.item()}')\n    sampled_images = diffusion.sample(model, n=images.shape[0])\n    sampled_images_history.append(sampled_images)\n    sns.set_context('notebook')\n    #tmp = initial_states.reshape(-1, 2, 32, 32)\n    fig, ax = plt.subplots(ncols=2)\n    _ = ax[0].imshow(sampled_images[0, 0, :, :])\n    _ = ax[1].imshow(sampled_images[0, 1, :, :])\n    _ = ax[0].set_xticklabels([])\n    _ = ax[1].set_xticklabels([])\n    _ = ax[0].set_yticklabels([])\n    _ = ax[1].set_yticklabels([])\n    _ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n    _ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n    _ = fig.suptitle('Diffusion Samples', y=0.8)\n    plt.show()\n    savefig(fname=f'sampled_image_epoch{epoch}', outdir=PLOTS_DIR, tstamp=True)\n    MODEL_FILE = OUTDIR.joinpath(\"models\", f\"unet-diffusion-epoch{epoch}.pt\")\n    MODEL_FILE.parent.mkdir(exist_ok=True, parents=True)\n    console.print(f\"Saving model checkpoint to: {MODEL_FILE}\")\n    torch.save(model.state_dict(), MODEL_FILE)\n\nStarting epoch 0:\n\n\n\n{\"model_id\":\"19b415c346b24bef8b60336d7f7bc355\",\"version_major\":2,\"version_minor\":0}\n\n\nepoch: 0, loss: 0.6023472547531128\n\n\n\n{\"model_id\":\"eea24504754f4cb9ab4d9925a6225c10\",\"version_major\":2,\"version_minor\":0}\n\n\n\n\n\nSaving sampled_image_epoch0-2023-09-21-124506 to l2hmc-diffusion-2dU1/2023-09-21/plots\n\n\nSaving model checkpoint to: l2hmc-diffusion-2dU1/2023-09-21/models/unet-diffusion-epoch0.pt\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\nsns.set_context('notebook')\ntmp = initial_states.reshape(-1, 2, 32, 32)\nfig, ax = plt.subplots(ncols=2)\n_ = ax[0].imshow(tmp[0, 0, :, :])\n_ = ax[1].imshow(tmp[0, 1, :, :])\n_ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n_ = ax[0].set_xticklabels([])\n_ = ax[1].set_xticklabels([])\n_ = ax[0].set_yticklabels([])\n_ = ax[1].set_yticklabels([])\n_ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n_ = fig.suptitle('HMC Samples', y=0.8)\nsampled_images_history_ = torch.stack(sampled_images_history)\nsampled_images_history_.shape\n\ntorch.Size([1, 5, 2, 32, 32])\nsns.set_context('notebook')\nfig, ax = plt.subplots(ncols=2)\n_ = ax[0].imshow(sampled_images_history_[0][0][0])\n_ = ax[1].imshow(sampled_images_history_[0][0][1])\n_ = ax[0].set_xticklabels([])\n_ = ax[1].set_xticklabels([])\n_ = ax[0].set_yticklabels([])\n_ = ax[1].set_yticklabels([])\n_ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n_ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n_ = fig.suptitle('Diffusion Samples', y=0.85)\nfor idx in range(sampled_images_history_.shape[0]):\n    q = exp.trainer.lattice.charges(x=sampled_images_history_[idx])\n    console.print(f'{idx}: {q}')\n\n0: Charges(intQ=tensor([ 5.0000e+00, -4.0000e+00, -6.0000e+00, -4.5535e-07,  1.0000e+00]), sinQ=tensor([ 1.6426, -1.7244, -4.4651,  0.5680,  0.7046]))\nHMC Sampling with Diffusion\n#for retrain_iter in range(config['retrains']):\nstate = exp.trainer.dynamics.random_state(config['beta'])\nx = state.x\n\nhistories = {}\nsamples = []\nhmc_samples = []\ndiffusion_samples = []\n\nglobal_step = 0\nwatcher = {}\nupdate_types = []\ncombined_samples = {}\nglobal_step\n\n0\nfor retrain_iter in range(2):\n    console.print(f'retrain_iter: {retrain_iter}')\n    ndiff_acc = 0\n    ndiff_proposed = 0\n    histories[retrain_iter] = {\n        'diffusion': [],\n        'hmc': [],\n    }\n    #for idx in range(config['samples_per_retrain']):\n    sbar = tqdm(range(10))\n    for idx in sbar:\n        t0_ = time.perf_counter()\n        if idx % 100 == 0:\n            console.print(f'sample idx: {idx}')\n        rand = np.random.uniform()\n        if (retrain_iter &gt;= 1) and rand &lt; diffusion_prob:\n            console.print(f'rand: {rand} &lt; {diffusion_prob}')\n            # Sample from diffusion model\n            x_ = diffusion.sample(model, n=x.shape[0])\n            ll_ = exp.trainer.dynamics.potential_energy(x_, config['beta'])\n            ll = exp.trainer.dynamics.potential_energy(x, config['beta'])\n            ratio = ll_ / ll\n            a = torch.min(torch.ones_like(ratio), ratio)\n            u = torch.rand(a.shape)\n            #u = np.random.uniform()\n            #for jdx in range(u.shape[0]):\n            #    if u[jdx] &lt; a[jdx]:\n            #        samples.append(x_[jdx])\n            #        diffusion_samples.append(x_[jdx])\n            #x = torch.where((u &lt; a), x_, x.reshape_as(x_)).reshape_as(x)\n            x = torch.where((u &lt; a)[:, None, None, None], x_, x.reshape_as(x_))\n            samples.append(x)\n            diffusion_samples.append(x)\n            combined_samples[global_step] = x\n            watcher[global_step] = 'diffusion'\n            #diffusion_samples.extend(x)\n            #samples.extend(x)\n            #ndiff_acc += \n            #if u &lt; a:\n            #    console.print('Accepted diffusion sample!')\n            #    console.print(f'{ndiff_acc} / {ndiff_proposed}')\n            #    ndiff_acc += 1\n            #    x = x_\n            #    diffusion_samples.append(x)\n            #    samples.append(x)\n        else:\n            # Oherwise, HMC\n            x, metrics = exp.trainer.hmc_step((x, config['beta']))\n            hmc_samples.append(x)\n            samples.append(x)\n            combined_samples[global_step] = x\n            watcher[global_step] = 'HMC'\n        smetrics = {\n            'idx': idx,\n            'global_step': global_step,\n            'dt': time.perf_counter() - t0_,\n        }\n        global_step += 1\n        #smetrics |= {\n        #    f'{k}': {torch.tensor(v).mean().item()} for k, v in metrics.items()\n        #}\n        sbar.set_postfix(smetrics)\n    # Train loop\n    dataset = TensorDataset(\n        torch.stack(hmc_samples).reshape(-1, 2, 32, 32)\n    )\n    dataloader = DataLoader(\n        dataset,\n        shuffle=False,\n        drop_last=True,\n        batch_size=config[\"train_batch_size\"],\n    )\n    pbar = tqdm(dataloader)\n    for i, batch in enumerate(pbar):\n        if i == 0:\n            console.print('Retraining...')\n        if isinstance(batch, (tuple, list)) and len(batch) == 1:\n            batch, = batch\n        batch = batch.reshape(-1, 2, 32, 32)\n        t0 = time.time()\n        t = diffusion.sample_timesteps(batch.shape[0]).to(device)\n        x_t, noise = diffusion.noise_images(batch, t)\n        predicted_noise = model(x_t, t)\n        loss = mse(noise, predicted_noise)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        t1 = time.time()\n        pbar.set_postfix(\n            {\n                'global_step': global_step,\n                'retrain_iter': retrain_iter,\n                'batch': i,\n                'dt': t1 - t0,\n                'MSE': loss.item()\n            }\n        )\n\nretrain_iter: 0\n\n\n\n{\"model_id\":\"17132d7ca8624fa387ee9467e4f1fa4d\",\"version_major\":2,\"version_minor\":0}\n\n\nsample idx: 0\n\n\n\n{\"model_id\":\"0ed1080fdebd4f7b9aae80db0d36b96b\",\"version_major\":2,\"version_minor\":0}\n\n\nRetraining...\n\n\n\nretrain_iter: 1\n\n\n\n{\"model_id\":\"d0346019e21b4d2a9b624dc59e84015b\",\"version_major\":2,\"version_minor\":0}\n\n\nsample idx: 0\n\n\n\nrand: 0.05506106760134255 &lt; 0.1\n\n\n\n{\"model_id\":\"c02b09d53ada46a194a47921f0ab3cba\",\"version_major\":2,\"version_minor\":0}\n\n\nrand: 0.07860283644524213 &lt; 0.1\n\n\n\n{\"model_id\":\"184df3f1c9714ece9756866b2617ed02\",\"version_major\":2,\"version_minor\":0}\n\n\n{\"model_id\":\"eaa0d84229c04618b7a2bffe2a4b1739\",\"version_major\":2,\"version_minor\":0}\n\n\nRetraining...\nconsole.print('\\n'.join([f\"{i.shape}\" for i in samples[:100]]))\n\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2, 32, 32])\ntorch.Size([16, 2048])\ntorch.Size([16, 2, 32, 32])\nsamples_ = torch.stack([i.reshape(-1, 2, 32, 32) for i in samples])\nsamples_.shape\n\ntorch.Size([30, 16, 2, 32, 32])\nlen(hmc_samples)\n\n28\nlen(diffusion_samples)\n\n2\nhmc_samples_ = torch.stack([i.reshape(-1, 2, 32, 32) for i in hmc_samples])\ndiffusion_samples_ = torch.stack(\n    [i.reshape(-1, 2, 32, 32) for i in diffusion_samples]\n)\nhmc_samples_.shape\n\ntorch.Size([28, 16, 2, 32, 32])\ndiffusion_samples_.shape\n\ntorch.Size([2, 16, 2, 32, 32])\nsamples_.shape\n\ntorch.Size([30, 16, 2, 32, 32])\ndef calc_plaqs(x):\n    return torch.stack([\n        exp.trainer.lattice.plaqs(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\n\ndef calc_intQ(x):\n    return torch.stack([\n        exp.trainer.lattice.int_charges(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\n    \ndef calc_sinQ(x):\n    return torch.stack([\n        exp.trainer.lattice.sin_charges(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\nsamples_init_ = initial_states.reshape(-1, initial_states.shape[1], 2, 32, 32)\nsamples_init_.shape\n\ntorch.Size([999, 16, 2, 32, 32])\nmetrics_init_ = {\n    'plaqs': calc_plaqs(samples_init_),\n    'intQ': calc_intQ(samples_init_),\n    'sinQ': calc_sinQ(samples_init_)\n}\n    \nmetrics_ = {\n    'plaqs': calc_plaqs(samples_),\n    'intQ': calc_intQ(samples_),\n    'sinQ': calc_sinQ(samples_)\n}\n\nmetrics_hmc_ = {\n    'plaqs': calc_plaqs(hmc_samples_),\n    'intQ': calc_intQ(hmc_samples_),\n    'sinQ': calc_sinQ(hmc_samples_)\n}\n\nmetrics_diffusion_ = {\n    'plaqs': calc_plaqs(diffusion_samples_),\n    'intQ': calc_intQ(diffusion_samples_),\n    'sinQ': calc_sinQ(diffusion_samples_)\n}\nmetrics_['plaqs'].shape\n\ntorch.Size([30, 16])\nconsole.print('\\n'.join([f\"{k}: {v}\" for k, v in watcher.items()]))\n\n0: HMC\n1: HMC\n2: HMC\n3: HMC\n4: HMC\n5: HMC\n6: HMC\n7: HMC\n8: HMC\n9: HMC\n10: HMC\n11: HMC\n12: HMC\n13: HMC\n14: HMC\n15: HMC\n16: HMC\n17: HMC\n18: HMC\n19: HMC\n20: HMC\n21: HMC\n22: HMC\n23: HMC\n24: HMC\n25: HMC\n26: HMC\n27: diffusion\n28: HMC\n29: diffusion\nfig, ax = plt.subplots()\n\n_ = ax.plot(metrics_['plaqs'][:, 0], label='Combined')\n_ = ax.plot(metrics_hmc_['plaqs'][:, 0], label='HMC')\n_ = ax.plot(metrics_diffusion_['plaqs'][:, 0], label='Diffusion')\n#_ = ax.plot(metrics_hmc1['plaqs'], label='HMC 1')\n#_ = ax.plot(metrics_diff_['plaqs'], label='Diffusion')\n_ = ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1.00))\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_init_.items()):\n    _ = ax[idx].plot(val[:, 0], label='HMC (Initial Samples)')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n    #_ = ax[idx].legend(loc='best', frameon=True, edgecolor=\"#838383\")\n\n_ = fig.suptitle(f\"Initial HMC States\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_.items()):\n    _ = ax[idx].plot(val[:, 0], label='Combined')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n    #_ = ax[idx].legend(loc='best', frameon=True, edgecolor=\"#838383\")\n\n_ = fig.suptitle(f\"Combined Samples\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_hmc_.items()):\n    _ = ax[idx].plot(val[:, 0], label='HMC')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n_ = fig.suptitle(f\"Generated HMC States\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_diffusion_.items()):\n    _ = ax[idx].plot(val[:, 0], label='Diffusion')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n_ = fig.suptitle(f\"Generated Diffusion States\", y=0.92)\nfrom l2hmc.lattice.u1.pytorch.lattice import plaq_exact\nplaq_exact(torch.tensor(6.0))\n\ntensor(0.9124)\nfig, ax = plt.subplots()\n#_ = plt.hist(metrics_['intQ'].flatten(), color='C0', alpha=0.6, label='Combined', edgecolor='none')\n_ = ax.hist(\n    metrics_diffusion_['intQ'].flatten(),\n    color='C0',\n    alpha=0.6,\n    edgecolor='none',\n    label='Diffusion',\n    density=True,\n)\n_ = ax.hist(\n    metrics_hmc_['intQ'].flatten(),\n    color='C1',\n    alpha=0.6,\n    edgecolor='none',\n    label='HMC',\n    density=True,\n)\n_ = ax.legend(loc='best', frameon=True, edgecolor='#666666')\n_ = ax.set_xlabel(r\"$Q$\", loc='center')\n_ = ax.set_title('Topological Charge ($Q$) Distribution', loc='center')\nfig, ax = plt.subplots()\n_ = plt.plot(metrics_['plaqs'][:, 0], color='C0', label='Diffusion')\n_ = plt.plot(metrics_hmc_['plaqs'][:, 0], color='C1', label='HMC')\n_ = ax.legend(loc='best', frameon=True, edgecolor='#666666', ncols=2)\n_ = ax.set_ylabel(r\"$\\left\\langle U_{\\mu\\nu}\\right\\rangle $\", loc='center')\n_ = ax.set_xlabel(f\"Draw\", loc='center')\nwloops = {\n    'hmc': [\n        exp.trainer.lattice.wilson_loops(i) for i in hmc_samples_\n    ],\n    'diffusion': [\n        exp.trainer.lattice.wilson_loops(i) for i in diffusion_samples_\n    ],\n}\n\nplaqs = {\n    'hmc': [\n        exp.trainer.lattice.plaqs(i) for i in hmc_samples_\n    ],\n    'diffusion': [\n        exp.trainer.lattice.plaqs(i) for i in diffusion_samples_\n    ],\n}\nwlhmc = torch.stack(wloops['hmc']).squeeze()\nwldiff = torch.stack(wloops['diffusion']).squeeze()\nwlhmc.shape\n\ntorch.Size([28, 16, 32, 32])\n_ = plt.tight_layout()\nfor idx in range(2):\n    fig, ax = plt.subplots(ncols=2)\n    _ = ax[0].imshow(wlhmc[idx, 0])\n    _ = ax[0].set_title(\"HMC\", loc='center')\n    _ = ax[1].imshow(wldiff[idx, 0])\n    _ = ax[1].set_title(\"Diffusion\", loc='center')\n    _ = fig.suptitle(r\"$U_{\\mu\\nu}$\", y=0.8)\n    for ax_ in ax:\n        _ = ax_.set_xticklabels([])\n        _ = ax_.set_yticklabels([])\n\n&lt;Figure size 640x480 with 0 Axes&gt;\nqhmc = metrics_hmc_['intQ']\nqdiff = metrics_diffusion_['intQ']\nqhmc.shape\n\ntorch.Size([28, 16])\nphmc = torch.stack(plaqs['hmc']).squeeze()\npdiff = torch.stack(plaqs['diffusion']).squeeze()\nphmc.shape\n\ntorch.Size([28, 16])\npdiff.shape\n\ntorch.Size([2, 16])\nfig, ax = plt.subplots()\n\n_ = ax.hist(\n    metrics_['plaqs'].flatten(),\n    color='C1',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='HMC',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_diffusion_['plaqs'].flatten(),\n    color='C0',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Diffusion',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_hmc_['plaqs'].flatten(),\n    color='C2',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Combined',\n    linewidth=1.5\n)\n_ = ax.set_xlabel(r\"$U_{\\mu\\nu}$\", loc='center')\n_ = ax.legend(\n    loc='upper left',\n    frameon=True,\n    #ncols=2,\n    bbox_to_anchor=(0.55, 1.00),\n    edgecolor=\"#838383\",\n)\n_ = ax.set_title('Plaquette Distribution', loc='center')\nfig, ax = plt.subplots()\n\n_ = ax.hist(\n    metrics_['intQ'].flatten(),\n    color='C1',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='HMC',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_diffusion_['intQ'].flatten(),\n    color='C0',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Diffusion',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_hmc_['intQ'].flatten(),\n    color='C2',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Combined',\n    linewidth=1.5\n)\n_ = ax.set_xlabel('$Q_{\\mathbb{Z}}$', loc='center')\n_ = ax.legend(\n    loc='upper left',\n    frameon=True,\n    #ncols=2,\n    bbox_to_anchor=(0.55, 1.00),\n    edgecolor=\"#838383\",\n)\n_ = ax.set_title('Charge Distribution', loc='center')\nglobal_step = 0\nframes = []\nlosses = []\nprint(\"Training model...\")\nfor epoch in range(config[\"num_epochs\"]):\n    model.train()\n    progress_bar = tqdm(total=len(dataloader))\n    progress_bar.set_description(f\"Epoch {epoch}\")\n    for step, batch in enumerate(dataloader):\n        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n\n        noise = torch.randn(batch.shape)\n        timesteps = torch.randint(\n            0, noise_scheduler.num_timesteps, (batch.shape[0],)\n        ).long()\n\n        #noisy = noise_scheduler.add_noise(batch, noise, timesteps)\n        noisy = noise_scheduler.noise_images(batch, timesteps)\n        noise_pred = model(noisy, timesteps)\n        loss = F.mse_loss(noise_pred, noise)\n        loss.backward(loss)\n\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n\n        progress_bar.update(1)\n        logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n        losses.append(loss.detach().item())\n        progress_bar.set_postfix(**logs)\n        global_step += 1\n    progress_bar.close()\n\n    if epoch % config[\"save_images_step\"] == 0 or epoch == config[\"num_epochs\"] - 1:\n        # generate data with the model to later visualize the learning process\n        model.eval()\n        sample = torch.randn(config[\"eval_batch_size\"], 2)\n        timesteps = list(range(len(noise_scheduler)))[::-1]\n        for i, t in enumerate(tqdm(timesteps)):\n            t = torch.from_numpy(np.repeat(t, config[\"eval_batch_size\"])).long()\n            with torch.no_grad():\n                residual = model(sample, t)\n            sample = noise_scheduler.step(residual, t[0], sample)\n        frames.append(sample.numpy())\ndataset[6]\nlen(dataloader)\neval_batch_size = 10\nnum_timesteps = 50\nplot_step = 5\nnoise_scheduler = ddpm.NoiseScheduler(num_timesteps=num_timesteps)\nsample = torch.randn(eval_batch_size, 2)\ntimesteps = list(range(num_timesteps))[::-1]\nsamples = []\nsteps = []\n\nretrains = 10\ndiffusion_prob = 0.3\nsamples_per_retrain = 100\neval_batch_size = 10\nt = torch.from_numpy(np.repeat(timesteps[0], eval_batch_size)).long()\nwith torch.no_grad():\n    residual = model(sample, t)\nsample_ = noise_scheduler.step(residual, t[0], sample)\nsample.shape\nresidual.shape\nsample_.shape\ndiffusion_samples = []\nhmc_samples = []\nbeta = 1.\nfor retrain_iter in range(retrains):\n    console.print(f'retrain_iter: {retrain_iter}')\n    ndiff_acc = 0\n    ndiff_proposed = 0\n    for idx in range(samples_per_retrain):\n        console.print(f'sample idx: {idx}')\n        rand = np.random.uniform()\n        if rand &lt; diffusion_prob:\n            ndiff_proposed += 1\n            rand_pick = randrange(len(dataloader))\n            #theta_prime = dataset[rand_pick]\n            t = torch.from_numpy(np.repeat(t, eval_batch_size)).long()\n            with torch.no_grad():\n                residual = model(sample, t)\n            sample_ = noise_scheduler.step(residual, t[0], sample)\n            ratio = (\n                log_likelihood_2dU1(sample_, 2)\n                / log_likelihood_2dU1(sample, 2)\n            )\n            a = min(1, ratio)\n            u = np.random.uniform()\n            if u &lt; a:\n                ndiff_acc += 1\n                sample = sample_\n                diffusion_samples.append(sample)\n        else:\n            sample_, metrics = exp.trainer.hmc_step((sample_, beta))\n            hmc_samples.append(sample)\nfor i, t in enumerate(tqdm(timesteps)):\n    t = torch.from_numpy(np.repeat(t, eval_batch_size)).long()\n    with torch.no_grad():\n        residual = model(sample, t)\n    sample = noise_scheduler.step(residual, t[0], sample)\n    if (i + 1) % plot_step == 0:\n        samples.append(sample.numpy())\n        steps.append(i + 1)\nAlternate\ndiffusion_ = DiffusionAlt(img_size=64, device='cpu')\nunet\nimage = torch.rand(1, 2, 64, 64)\nt = diffusion_.sample_timesteps(image.shape[0]).to('cpu')\nunet(image, t)\ndiffusion_.sample("
  },
  {
    "objectID": "qmd/diffusion/diffusion.html#imports--setup",
    "href": "qmd/diffusion/diffusion.html#imports--setup",
    "title": "MCMC + Diffusion Sampling",
    "section": "Imports / Setup",
    "text": "Imports / Setup\n\nfrom __future__ import absolute_import, print_function, annotations, division\nfrom dataclasses import dataclass\n\nimport sys\nimport os\nimport math\nimport numpy as np\nimport scipy\nimport time\nfrom random import randrange\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n\nfrom ezpz.dist import setup_torch\n\nport = np.random.randint(5000, 6000)\nprint(f\"Using port: {port}\")\n\nRANK = setup_torch(\n    backend=\"DDP\",\n    port=f\"{port}\"\n)\n\n    Using port: 5561\n\n\nUsing DDP for distributed training\n\n\n\nGlobal Rank: 0 / 0\n\n\n\n\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom l2hmc.main import build_experiment\nfrom l2hmc.utils.rich import get_console\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nimport opinionated\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nfrom pandas.io.formats import style\nimport scipy\nimport time\nfrom random import randrange\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\n\nset_plot_style()\nconsole = get_console()\nprint(console.is_jupyter)\nif console.is_jupyter:\n    console.is_jupyter = False\nprint(console.is_jupyter)\n\nUsing device: cpu\n\n\n\nFailed to download font: Source Sans Pro, skipping! Failed to download font: Titillium WebRoboto Condensed, skipping!\n\n\nTrue\n\n\n\nFalse\n\n\n\nplt.style.use(opinionated.STYLES['opinionated_min'])\nsns.set_context('notebook')"
  },
  {
    "objectID": "qmd/diffusion/diffusion.html#2d-u1",
    "href": "qmd/diffusion/diffusion.html#2d-u1",
    "title": "MCMC + Diffusion Sampling",
    "section": "2D U(1)",
    "text": "2D U(1)"
  },
  {
    "objectID": "qmd/diffusion/diffusion.html#train-diffusion-model",
    "href": "qmd/diffusion/diffusion.html#train-diffusion-model",
    "title": "MCMC + Diffusion Sampling",
    "section": "Train Diffusion Model",
    "text": "Train Diffusion Model"
  },
  {
    "objectID": "qmd/diffusion/diffusion.html#build-diffusion-model-with-unet-architecure",
    "href": "qmd/diffusion/diffusion.html#build-diffusion-model-with-unet-architecure",
    "title": "MCMC + Diffusion Sampling",
    "section": "Build Diffusion Model with UNet Architecure",
    "text": "Build Diffusion Model with UNet Architecure"
  },
  {
    "objectID": "qmd/diffusion/diffusion.html#hmc-sampling-with-diffusion",
    "href": "qmd/diffusion/diffusion.html#hmc-sampling-with-diffusion",
    "title": "MCMC + Diffusion Sampling",
    "section": "HMC Sampling with Diffusion",
    "text": "HMC Sampling with Diffusion"
  },
  {
    "objectID": "qmd/diffusion/diffusion.html#alternate",
    "href": "qmd/diffusion/diffusion.html#alternate",
    "title": "MCMC + Diffusion Sampling",
    "section": "Alternate",
    "text": "Alternate"
  },
  {
    "objectID": "qmd/l2hmc-2DU1.html",
    "href": "qmd/l2hmc-2DU1.html",
    "title": "2D U(1) Example",
    "section": "",
    "text": "l2hmc: Example\nImports / Setup\nInitialize and Build Experiment objects:\nPyTorch\nTraining\nInference\nTensorFlow\nTrain\nInference\nModel Performance\nComparisons\nTensorFlow Results\nPyTorch Results\nComparisons\nl2hmc: Example\n \nThis notebook will (attempt) to walk through the steps needed to successfully instantiate and ‚Äúrun‚Äù an experiment.\nFor this example, we wish to train the L2HMC sampler for the 2D U(1) lattice gauge model with Wilson action:\n\\begin{equation*}\nS_{\\beta}(n) = \\beta \\sum_{n}\\sum_{\\mu&lt;\\nu}\\mathrm{Re}\\left[1 - U_{\\mu\\nu}(n) \\right]\n\\end{equation*}\nThis consists of the following steps:\n\nBuild an Experiment by parsing our configuration object\nTrain our model using the Experiment.train() method\nEvaluate our trained model Experiment.evaluate(job_type='eval')\nCompare our trained models‚Äô performance against generic HMC Experiment.evaluate(job_type='hmc')\n\n\nEvaluating Performance\nExplicitly, we measure the performance of our model by comparing the tunneling rate \\delta Q of our trained sampler to that of generic HMC.\nExplicitly, the tunneling rate is given by:\n\n\\delta Q = \\frac{1}{N_{\\mathrm{chains}}}\\sum_{\\mathrm{chains}} \\left|Q_{i+1} - Q_{i}\\right|\n\nwhere the difference is between subsequent states in a chain, and the sum is over all N chains (each being ran in parallel, independently).\nSince our goal is to generate independent configurations, the more our sampler tunnels between different topological sectors (tunneling rate), the more efficient our sampler.\nImports / Setup\n! nvidia-smi | tail --lines -7\n# automatically detect and reload local changes to modules\n%load_ext autoreload\n%autoreload 2\n%matplotlib widget\n\nimport os\nimport warnings\n\nos.environ['COLORTERM'] = 'truecolor'\n\nwarnings.filterwarnings('ignore')\n# --------------------------------------\n# BE SURE TO GRAB A FRESH GPU !\nos.environ['CUDA_VISIBLE_DEVICES'] = '2'\n!echo $CUDA_VISIBLE_DEVICES\n# --------------------------------------\n\n2\ndevices = os.environ.get('CUDA_VISIBLE_DEVICES', None)\nprint(devices)\n!getconf _NPROCESSORS_ONLN  # get number of availble CPUs\n\n2\n256\nos.environ['TORCH_CPP_LOG_LEVEL'] = 'ERROR'\nos.environ['AUTOGRAPH_VERBOSITY'] = '10'\n!echo $CUDA_VISIBLE_DEVICES\n\n2\nfrom __future__ import absolute_import, print_function, annotations, division\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.display import set_matplotlib_formats\n\nfrom l2hmc.main import build_experiment\nfrom l2hmc.utils.rich import get_console\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nset_plot_style()\nplt.rcParams['grid.alpha'] = 0.8\nplt.rcParams['grid.color'] = '#404040'\nsns.set(rc={\"figure.dpi\":100, 'savefig.dpi':300})\nsns.set_context('notebook')\nsns.set_style(\"ticks\")\nset_matplotlib_formats('retina')\nplt.rcParams['figure.figsize'] = [12.4, 4.8]\n\nconsole = get_console()\nprint(console.is_jupyter)\nif console.is_jupyter:\n    console.is_jupyter = False\nprint(console.is_jupyter)\n\n--------------------------------------------------------------------------\nWARNING: There was an error initializing an OpenFabrics device.\n\n  Local host:   thetagpu23\n  Local device: mlx5_0\n--------------------------------------------------------------------------\n\n\nTrue\n\n\nFalse\nimport l2hmc\nl2hmc.__file__\n\n'/lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/l2hmc-qcd/src/l2hmc/__init__.py'\nInitialize and Build Experiment objects:\n\nThe l2hmc.main module provides a function build_experiment:\n\ndef build_experiment(overrides: list[str]) -&gt; tfExperiment | ptExperiment:\n    ...\nwhich will:\n\nLoad the default options from conf/config.yaml\nOverride the default options with any values provided in overrides\nParse these options and build an ExperimentConfig which uniquely defines an experiment\nInstantiate / return an Experiment from the ExperimentConfig. Depending on framework=pytorch|tensorflow: a. framework=pytorch -&gt; l2hmc.experiment.pytorch.Experiment b. framework=tensorflow -&gt; l2hmc.experiment.tensorflow.Experiment\n\n&gt;&gt;&gt; train_output = experiment.train()\n&gt;&gt;&gt; eval_output = experiment.evaluate(job_type='eval')\n&gt;&gt;&gt; hmc_output = experiment.evaluate(job_type='hmc')\n\nOverriding Defaults\nSpecifics about the training / evaluation / hmc runs can be flexibly overridden by passing arguments to the training / evaluation / hmc runs, respectively\nimport numpy as np\n\n#seed = np.random.randint(100000)\nseed=76043\n\nDEFAULTS = {\n    'seed': f'{seed}',\n    'precision': 'fp16',\n    'init_aim': False,\n    'init_wandb': False,\n    'use_wandb': False,\n    'restore': False,\n    'save': False,\n    'use_tb': False,\n    'dynamics': {\n        'nleapfrog': 10,\n        'nchains': 4096,\n        'eps': 0.05,\n    },\n    'conv': 'none',\n    'steps': {\n        'log': 20,\n        'print': 250,\n        'nepoch': 5000,\n        'nera': 1,\n    },\n    'annealing_schedule': {\n        'beta_init': 4.0,\n        'beta_final': 4.0,\n    },\n    #'learning_rate': {\n    #    #'lr_init': 0.0005,\n    #    #'clip_norm': 10.0,\n    #},\n}\n\noutputs = {\n    'pytorch': {\n        'train': {},\n        'eval': {},\n        'hmc': {},\n    },\n    'tensorflow': {\n        'train': {},\n        'eval': {},\n        'hmc': {},\n    },\n}\nfrom l2hmc.configs import dict_to_list_of_overrides\nOVERRIDES = dict_to_list_of_overrides(DEFAULTS)\nOVERRIDES\n\n['seed=76043',\n 'precision=fp16',\n 'init_aim=False',\n 'init_wandb=False',\n 'use_wandb=False',\n 'restore=False',\n 'save=False',\n 'use_tb=False',\n 'dynamics.nleapfrog=10',\n 'dynamics.nchains=4096',\n 'dynamics.eps=0.05',\n 'conv=none',\n 'steps.log=20',\n 'steps.print=250',\n 'steps.nepoch=5000',\n 'steps.nera=1',\n 'annealing_schedule.beta_init=4.0',\n 'annealing_schedule.beta_final=4.0']\n# Build PyTorch Experiment\nptExpU1 = build_experiment(\n    overrides=[\n        *OVERRIDES,\n        'framework=pytorch',\n        'backend=DDP',\n    ]\n)\n\n[06/23/23 12:57:55][INFO][dist.py:338] - Global Rank: 0 / 0\n\n\n2023-06-23 12:57:58.015160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n\n\n[06/23/23 12:58:15][INFO][dist.py:226] - Caught MASTER_PORT:2345 from environment!\n[06/23/23 12:58:15][INFO][dist.py:226] - Caught MASTER_PORT:2345 from environment!\n[06/23/23 12:58:15][WARNING][trainer.py:435] - Using torch.float16 on cuda!\n[06/23/23 12:58:17][WARNING][trainer.py:435] - Using `torch.optim.Adam` optimizer\n[06/23/23 12:58:17][INFO][trainer.py:283] - num_params in model: 1486740\n[06/23/23 12:58:17][WARNING][trainer.py:250] - logging with freq 20 for wandb.watch\n# Build TensorFlow Experiment\nimport tensorflow as tf\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\ntfExpU1 = build_experiment(\n    overrides=[\n        *OVERRIDES,\n        'framework=tensorflow',\n        'backend=horovod',\n    ]\n)\n\nINFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\nYour GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100-SXM4-80GB, compute capability 8.0\n[06/23/23 12:58:18][INFO][dist.py:82] - 1, Physical GPUs and 1 Logical GPUs\n[06/23/23 12:58:18][WARNING][dist.py:108] - Using: float32 precision\n[06/23/23 12:58:18][INFO][dist.py:109] - RANK: 0, LOCAL_RANK: 0\nPyTorch\nTraining\noutputs['pytorch']['train'] = ptExpU1.trainer.train()\n    #nera=5,\n    #nepoch=2000,\n    #beta=[4.0, 4.25, 4.5, 4.75, 5.0],\n#)\n\n_ = ptExpU1.save_dataset(job_type='train', nchains=32)\n\n\n\n\n[06/23/23 12:58:19][INFO][trainer.py:439] - [TRAINING] x.dtype: torch.float32\n[06/23/23 12:58:19][INFO][trainer.py:439] - [TRAINING] self._dtype: torch.float16\n[06/23/23 12:58:19][INFO][trainer.py:107] - ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n[06/23/23 12:58:19][INFO][trainer.py:108] - ‚îÉ ERA: 0 / 1, BETA: 4.000 ‚îÉ\n[06/23/23 12:58:19][INFO][trainer.py:109] - ‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n[06/23/23 12:58:24][INFO][trainer.py:439] - Thermalizing configs @ 4.00 took 4.7326 s\n[06/23/23 12:58:25][INFO][trainer.py:1722] - era=0 epoch=0 tstep=1 dt=0.781 beta=4.000 loss=59.439 dQsin=0.016 dQint=0.005 energy=398.887 logprob=398.650 logdet=0.237 sldf=0.143 sldb=-0.117 sld=0.237 xeps=0.050 veps=0.050 acc=0.057 sumlogdet=0.003 acc_mask=0.057 plaqs=0.864 intQ=0.009 sinQ=0.006 lr=0.001\n[06/23/23 13:00:59][INFO][trainer.py:1722] - era=0 epoch=240 tstep=241 dt=0.600 beta=4.000 loss=-4.980 dQsin=0.212 dQint=0.069 energy=396.331 logprob=395.966 logdet=0.365 sldf=0.199 sldb=-0.146 sld=0.365 xeps=0.044 veps=0.043 acc=0.781 sumlogdet=-0.003 acc_mask=0.777 plaqs=0.864 intQ=-0.012 sinQ=-0.012 lr=0.001\n[06/23/23 13:03:34][INFO][trainer.py:1722] - era=0 epoch=500 tstep=501 dt=0.599 beta=4.000 loss=-7.162 dQsin=0.239 dQint=0.084 energy=396.375 logprob=395.945 logdet=0.431 sldf=0.234 sldb=-0.186 sld=0.431 xeps=0.051 veps=0.050 acc=0.846 sumlogdet=0.002 acc_mask=0.851 plaqs=0.864 intQ=0.053 sinQ=0.049 lr=0.001\n[06/23/23 13:06:07][INFO][trainer.py:1722] - era=0 epoch=740 tstep=741 dt=0.591 beta=4.000 loss=-8.272 dQsin=0.253 dQint=0.095 energy=396.330 logprob=395.886 logdet=0.444 sldf=0.243 sldb=-0.216 sld=0.444 xeps=0.052 veps=0.051 acc=0.872 sumlogdet=0.001 acc_mask=0.882 plaqs=0.864 intQ=0.013 sinQ=0.015 lr=0.001\n[06/23/23 13:08:39][INFO][trainer.py:1722] - era=0 epoch=1000 tstep=1001 dt=0.594 beta=4.000 loss=-8.689 dQsin=0.246 dQint=0.092 energy=396.763 logprob=396.257 logdet=0.505 sldf=0.277 sldb=-0.258 sld=0.505 xeps=0.058 veps=0.056 acc=0.865 sumlogdet=0.002 acc_mask=0.861 plaqs=0.863 intQ=-0.037 sinQ=-0.038 lr=0.001\n[06/23/23 13:11:12][INFO][trainer.py:1722] - era=0 epoch=1240 tstep=1241 dt=0.607 beta=4.000 loss=-8.190 dQsin=0.242 dQint=0.101 energy=396.304 logprob=395.726 logdet=0.578 sldf=0.316 sldb=-0.282 sld=0.578 xeps=0.065 veps=0.063 acc=0.840 sumlogdet=0.001 acc_mask=0.846 plaqs=0.864 intQ=-0.040 sinQ=-0.035 lr=0.001\n[06/23/23 13:13:44][INFO][trainer.py:1722] - era=0 epoch=1500 tstep=1501 dt=0.592 beta=4.000 loss=-9.732 dQsin=0.238 dQint=0.121 energy=397.387 logprob=396.435 logdet=0.952 sldf=0.519 sldb=-0.430 sld=0.952 xeps=0.083 veps=0.078 acc=0.752 sumlogdet=0.002 acc_mask=0.748 plaqs=0.863 intQ=0.039 sinQ=0.035 lr=0.001\n[06/23/23 13:16:17][INFO][trainer.py:1722] - era=0 epoch=1740 tstep=1741 dt=0.592 beta=4.000 loss=-10.209 dQsin=0.235 dQint=0.134 energy=397.590 logprob=396.320 logdet=1.271 sldf=0.692 sldb=-0.577 sld=1.271 xeps=0.094 veps=0.087 acc=0.725 sumlogdet=0.007 acc_mask=0.723 plaqs=0.864 intQ=0.005 sinQ=0.008 lr=0.001\n[06/23/23 13:18:52][INFO][trainer.py:1722] - era=0 epoch=2000 tstep=2001 dt=0.599 beta=4.000 loss=-12.075 dQsin=0.234 dQint=0.149 energy=399.553 logprob=397.752 logdet=1.800 sldf=0.980 sldb=-0.801 sld=1.800 xeps=0.106 veps=0.094 acc=0.638 sumlogdet=0.005 acc_mask=0.633 plaqs=0.863 intQ=0.013 sinQ=0.007 lr=0.001\n[06/23/23 13:21:25][INFO][trainer.py:1722] - era=0 epoch=2240 tstep=2241 dt=0.592 beta=4.000 loss=-13.515 dQsin=0.239 dQint=0.162 energy=399.697 logprob=397.477 logdet=2.220 sldf=1.209 sldb=-0.991 sld=2.220 xeps=0.114 veps=0.099 acc=0.616 sumlogdet=0.007 acc_mask=0.618 plaqs=0.863 intQ=0.005 sinQ=0.004 lr=0.001\n[06/23/23 13:23:58][INFO][trainer.py:1722] - era=0 epoch=2500 tstep=2501 dt=0.591 beta=4.000 loss=-11.498 dQsin=0.216 dQint=0.155 energy=400.518 logprob=397.818 logdet=2.700 sldf=1.470 sldb=-1.218 sld=2.700 xeps=0.125 veps=0.104 acc=0.538 sumlogdet=0.010 acc_mask=0.541 plaqs=0.863 intQ=-0.033 sinQ=-0.027 lr=0.001\n[06/23/23 13:26:30][INFO][trainer.py:1722] - era=0 epoch=2740 tstep=2741 dt=0.591 beta=4.000 loss=-13.669 dQsin=0.239 dQint=0.178 energy=400.852 logprob=397.768 logdet=3.084 sldf=1.679 sldb=-1.381 sld=3.084 xeps=0.132 veps=0.112 acc=0.586 sumlogdet=0.012 acc_mask=0.589 plaqs=0.864 intQ=0.052 sinQ=0.040 lr=0.001\n[06/23/23 13:29:03][INFO][trainer.py:1722] - era=0 epoch=3000 tstep=3001 dt=0.825 beta=4.000 loss=-13.659 dQsin=0.229 dQint=0.175 energy=402.199 logprob=398.541 logdet=3.658 sldf=1.994 sldb=-1.676 sld=3.658 xeps=0.142 veps=0.118 acc=0.541 sumlogdet=0.008 acc_mask=0.545 plaqs=0.863 intQ=-0.034 sinQ=-0.035 lr=0.001\n[06/23/23 13:31:36][INFO][trainer.py:1722] - era=0 epoch=3240 tstep=3241 dt=0.593 beta=4.000 loss=-14.593 dQsin=0.232 dQint=0.182 energy=403.727 logprob=399.641 logdet=4.087 sldf=2.232 sldb=-1.965 sld=4.087 xeps=0.151 veps=0.121 acc=0.489 sumlogdet=0.012 acc_mask=0.498 plaqs=0.863 intQ=-0.009 sinQ=-0.012 lr=0.001\n[06/23/23 13:34:09][INFO][trainer.py:1722] - era=0 epoch=3500 tstep=3501 dt=0.600 beta=4.000 loss=-10.267 dQsin=0.202 dQint=0.161 energy=404.429 logprob=399.713 logdet=4.716 sldf=2.575 sldb=-2.237 sld=4.716 xeps=0.152 veps=0.130 acc=0.432 sumlogdet=0.010 acc_mask=0.451 plaqs=0.863 intQ=-0.003 sinQ=-0.003 lr=0.001\n[06/23/23 13:36:44][INFO][trainer.py:1722] - era=0 epoch=3740 tstep=3741 dt=0.602 beta=4.000 loss=-16.740 dQsin=0.239 dQint=0.202 energy=404.274 logprob=399.215 logdet=5.059 sldf=2.765 sldb=-2.461 sld=5.059 xeps=0.163 veps=0.133 acc=0.503 sumlogdet=0.013 acc_mask=0.507 plaqs=0.863 intQ=-0.027 sinQ=-0.024 lr=0.001\n[06/23/23 13:39:19][INFO][trainer.py:1722] - era=0 epoch=4000 tstep=4001 dt=0.602 beta=4.000 loss=-17.072 dQsin=0.242 dQint=0.215 energy=405.285 logprob=399.736 logdet=5.549 sldf=3.037 sldb=-2.781 sld=5.549 xeps=0.171 veps=0.135 acc=0.460 sumlogdet=0.012 acc_mask=0.464 plaqs=0.864 intQ=0.013 sinQ=0.013 lr=0.001\n[06/23/23 13:41:53][INFO][trainer.py:1722] - era=0 epoch=4240 tstep=4241 dt=0.600 beta=4.000 loss=-18.798 dQsin=0.236 dQint=0.218 energy=406.449 logprob=400.293 logdet=6.156 sldf=3.370 sldb=-3.104 sld=6.156 xeps=0.179 veps=0.137 acc=0.455 sumlogdet=0.011 acc_mask=0.451 plaqs=0.864 intQ=0.009 sinQ=0.007 lr=0.001\n[06/23/23 13:44:28][INFO][trainer.py:1722] - era=0 epoch=4500 tstep=4501 dt=0.598 beta=4.000 loss=-18.046 dQsin=0.242 dQint=0.215 energy=406.391 logprob=400.047 logdet=6.343 sldf=3.476 sldb=-3.278 sld=6.343 xeps=0.183 veps=0.144 acc=0.463 sumlogdet=0.011 acc_mask=0.465 plaqs=0.864 intQ=-0.019 sinQ=-0.016 lr=0.001\n[06/23/23 13:47:02][INFO][trainer.py:1722] - era=0 epoch=4740 tstep=4741 dt=0.601 beta=4.000 loss=-16.357 dQsin=0.230 dQint=0.206 energy=407.460 logprob=400.501 logdet=6.958 sldf=3.815 sldb=-3.604 sld=6.958 xeps=0.188 veps=0.147 acc=0.423 sumlogdet=0.010 acc_mask=0.426 plaqs=0.864 intQ=0.023 sinQ=0.022 lr=0.001\n[06/23/23 13:49:51][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 13:49:56][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 13:50:00][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 13:50:05][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 13:50:09][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 13:50:13][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 13:50:56][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/data/train_data.h5\n[06/23/23 13:51:06][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 13:51:06][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nInference\nEvaluation\noutputs['pytorch']['eval'] = ptExpU1.trainer.eval(\n    job_type='eval',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = ptExpU1.save_dataset(job_type='eval', nchains=32)\n\n[06/23/23 13:52:42][WARNING][trainer.py:435] - x.shape (original): torch.Size([4096, 2, 16, 16])\n[06/23/23 13:52:42][WARNING][trainer.py:435] - x[:nchains].shape: torch.Size([128, 2, 16, 16])\n[06/23/23 13:52:42][INFO][trainer.py:1051] - eps=None\nbeta=4.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x7f2722bfbdf0&gt;\nnprint=500\neval_steps=2000\nnleapfrog=None\n\n\n\n\n\n[06/23/23 13:52:46][INFO][trainer.py:1181] - estep=0 dt=0.278 beta=4.000 loss=-26.568 dQsin=0.310 dQint=0.328 energy=412.448 logprob=405.216 logdet=7.232 sldf=3.974 sldb=-3.865 sld=7.232 xeps=0.193 veps=0.148 acc=0.484 sumlogdet=0.003 acc_mask=0.508 plaqs=0.863 intQ=-0.086 sinQ=-0.055\n[06/23/23 13:54:55][INFO][trainer.py:1181] - estep=500 dt=0.226 beta=4.000 loss=-23.825 dQsin=0.266 dQint=0.227 energy=407.989 logprob=400.742 logdet=7.247 sldf=3.976 sldb=-3.845 sld=7.247 xeps=0.193 veps=0.148 acc=0.470 sumlogdet=0.029 acc_mask=0.492 plaqs=0.862 intQ=-0.164 sinQ=-0.105\n[06/23/23 13:57:02][INFO][trainer.py:1181] - estep=1000 dt=0.228 beta=4.000 loss=-23.745 dQsin=0.270 dQint=0.250 energy=410.211 logprob=402.944 logdet=7.266 sldf=3.987 sldb=-3.842 sld=7.266 xeps=0.193 veps=0.148 acc=0.456 sumlogdet=0.011 acc_mask=0.461 plaqs=0.863 intQ=-0.023 sinQ=-0.042\n[06/23/23 13:59:11][INFO][trainer.py:1181] - estep=1500 dt=0.230 beta=4.000 loss=-18.855 dQsin=0.285 dQint=0.227 energy=408.605 logprob=401.337 logdet=7.267 sldf=3.984 sldb=-3.841 sld=7.267 xeps=0.193 veps=0.148 acc=0.432 sumlogdet=0.019 acc_mask=0.508 plaqs=0.863 intQ=0.125 sinQ=0.103\n[06/23/23 14:01:28][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:01:32][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:01:37][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:01:41][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 14:01:45][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 14:01:50][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 14:02:02][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/data/eval_data.h5\n[06/23/23 14:02:03][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:02:03][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nHMC\noutputs['pytorch']['hmc'] = ptExpU1.trainer.eval(\n    job_type='hmc',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = ptExpU1.save_dataset(job_type='hmc', nchains=32)\n\n[06/23/23 14:02:13][WARNING][trainer.py:435] - Step size `eps` not specified for HMC! Using default: 0.1000 for generic HMC\n[06/23/23 14:02:13][WARNING][trainer.py:435] - x.shape (original): torch.Size([4096, 2, 16, 16])\n[06/23/23 14:02:13][WARNING][trainer.py:435] - x[:nchains].shape: torch.Size([128, 2, 16, 16])\n[06/23/23 14:02:13][INFO][trainer.py:1051] - eps=0.1\nbeta=4.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x7f266407a500&gt;\nnprint=500\neval_steps=2000\nnleapfrog=20\n\n\n\n\n\n[06/23/23 14:02:17][INFO][trainer.py:1181] - hstep=0 dt=0.034 beta=4.000 loss=-11.965 dQsin=0.256 dQint=0.172 energy=395.464 logprob=395.464 logdet=0.000 acc=0.762 sumlogdet=0.000 acc_mask=0.734 plaqs=0.864 intQ=0.203 sinQ=0.148\n[06/23/23 14:02:47][INFO][trainer.py:1181] - hstep=500 dt=0.035 beta=4.000 loss=-15.159 dQsin=0.263 dQint=0.156 energy=395.520 logprob=395.520 logdet=0.000 acc=0.771 sumlogdet=0.000 acc_mask=0.734 plaqs=0.864 intQ=-0.078 sinQ=-0.086\n[06/23/23 14:03:20][INFO][trainer.py:1181] - hstep=1000 dt=0.035 beta=4.000 loss=-17.856 dQsin=0.307 dQint=0.156 energy=395.126 logprob=395.126 logdet=0.000 acc=0.832 sumlogdet=0.000 acc_mask=0.859 plaqs=0.864 intQ=0.125 sinQ=0.102\n[06/23/23 14:03:52][INFO][trainer.py:1181] - hstep=1500 dt=0.035 beta=4.000 loss=-9.512 dQsin=0.242 dQint=0.055 energy=397.486 logprob=397.486 logdet=0.000 acc=0.791 sumlogdet=0.000 acc_mask=0.812 plaqs=0.863 intQ=-0.148 sinQ=-0.106\n[06/23/23 14:04:26][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:04:32][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:04:36][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:04:46][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125815/pytorch/data/hmc_data.h5\n[06/23/23 14:04:46][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:04:46][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nTensorFlow\nTrain\noutputs['tensorflow']['train'] = tfExpU1.trainer.train()\n#    nera=5,\n#    nepoch=2000,\n#    beta=[4.0, 4.25, 4.5, 4.75, 5.0],\n#)\n_ = tfExpU1.save_dataset(job_type='train', nchains=32)\n\n[06/23/23 14:05:07][INFO][trainer.py:200] - Looking for checkpoints in: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-16-16/nlf-10/xsplit-True/sepnets-True/merge-True/net-16-16-16_dp-0.2_bn-False/tensorflow\n[06/23/23 14:05:07][INFO][trainer.py:200] - No checkpoints found to load from. Continuing\n\n\n\n\n\n[06/23/23 14:05:07][INFO][trainer.py:1266] - ERA: 0 / 1, BETA: 4.000\n[06/23/23 14:06:32][INFO][trainer.py:200] - Thermalizing configs @ 4.00 took 85.1316 s\n\n\n{\"model_id\":\"3ce8a6d5ef17444abb0644b54156bbcf\",\"version_major\":2,\"version_minor\":0}\n\n\nWARNING:tensorflow:From /lus/grand/projects/datascience/foremans/locations/thetaGPU/miniconda3/envs/2023-04-26/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\nInstructions for updating:\nLambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n[06/23/23 14:08:07][INFO][trainer.py:1089] - era=0 epoch=0 tstep=1.000 dt=93.926 beta=4.000 loss=97.795 dQsin=0.001 dQint=0.001 energy=1281.699 logprob=1281.654 logdet=0.046 sldf=0.060 sldb=0.094 sld=0.046 xeps=0.050 veps=0.050 acc=0.001 sumlogdet=-0.001 acc_mask=0.001 plaqs=0.021 intQ=-0.042 sinQ=0.020 lr=0.001\n[06/23/23 14:09:11][INFO][trainer.py:1089] - era=0 epoch=240 tstep=241.000 dt=0.239 beta=4.000 loss=-0.984 dQsin=0.153 dQint=0.055 energy=395.706 logprob=396.037 logdet=-0.332 sldf=-0.175 sldb=0.045 sld=-0.332 xeps=0.048 veps=0.044 acc=0.550 sumlogdet=0.004 acc_mask=0.555 plaqs=0.864 intQ=0.010 sinQ=0.003 lr=0.001\n[06/23/23 14:10:15][INFO][trainer.py:1089] - era=0 epoch=500 tstep=501.000 dt=0.241 beta=4.000 loss=-4.051 dQsin=0.190 dQint=0.064 energy=394.337 logprob=395.721 logdet=-1.383 sldf=-0.746 sldb=0.488 sld=-1.383 xeps=0.047 veps=0.043 acc=0.709 sumlogdet=-0.025 acc_mask=0.708 plaqs=0.864 intQ=-0.025 sinQ=-0.025 lr=0.001\n[06/23/23 14:11:22][INFO][trainer.py:1089] - era=0 epoch=740 tstep=741.000 dt=0.236 beta=4.000 loss=-6.052 dQsin=0.206 dQint=0.072 energy=394.177 logprob=395.854 logdet=-1.677 sldf=-0.908 sldb=0.629 sld=-1.677 xeps=0.048 veps=0.043 acc=0.759 sumlogdet=-0.001 acc_mask=0.754 plaqs=0.864 intQ=0.006 sinQ=0.003 lr=0.001\n[06/23/23 14:12:27][INFO][trainer.py:1089] - era=0 epoch=1000 tstep=1001.000 dt=0.244 beta=4.000 loss=-6.203 dQsin=0.221 dQint=0.075 energy=394.858 logprob=396.599 logdet=-1.742 sldf=-0.942 sldb=0.653 sld=-1.742 xeps=0.049 veps=0.045 acc=0.811 sumlogdet=-0.011 acc_mask=0.812 plaqs=0.863 intQ=0.029 sinQ=0.026 lr=0.001\n[06/23/23 14:13:32][INFO][trainer.py:1089] - era=0 epoch=1240 tstep=1241.000 dt=0.234 beta=4.000 loss=-7.401 dQsin=0.235 dQint=0.084 energy=394.913 logprob=396.405 logdet=-1.493 sldf=-0.809 sldb=0.544 sld=-1.493 xeps=0.050 veps=0.046 acc=0.833 sumlogdet=0.004 acc_mask=0.831 plaqs=0.863 intQ=0.023 sinQ=0.021 lr=0.001\n[06/23/23 14:14:40][INFO][trainer.py:1089] - era=0 epoch=1500 tstep=1501.000 dt=0.241 beta=4.000 loss=-7.387 dQsin=0.239 dQint=0.089 energy=394.786 logprob=395.871 logdet=-1.084 sldf=-0.586 sldb=0.393 sld=-1.084 xeps=0.051 veps=0.047 acc=0.854 sumlogdet=-0.001 acc_mask=0.854 plaqs=0.864 intQ=-0.008 sinQ=-0.012 lr=0.001\n[06/23/23 14:15:46][INFO][trainer.py:1089] - era=0 epoch=1740 tstep=1741.000 dt=0.276 beta=4.000 loss=-8.684 dQsin=0.250 dQint=0.086 energy=394.998 logprob=395.804 logdet=-0.806 sldf=-0.438 sldb=0.318 sld=-0.806 xeps=0.053 veps=0.049 acc=0.878 sumlogdet=0.001 acc_mask=0.873 plaqs=0.864 intQ=0.036 sinQ=0.023 lr=0.001\n[06/23/23 14:16:52][INFO][trainer.py:1089] - era=0 epoch=2000 tstep=2001.000 dt=0.280 beta=4.000 loss=-8.376 dQsin=0.255 dQint=0.095 energy=394.788 logprob=395.364 logdet=-0.576 sldf=-0.314 sldb=0.244 sld=-0.576 xeps=0.054 veps=0.050 acc=0.896 sumlogdet=0.002 acc_mask=0.897 plaqs=0.863 intQ=-0.023 sinQ=-0.021 lr=0.001\n[06/23/23 14:17:56][INFO][trainer.py:1089] - era=0 epoch=2240 tstep=2241.000 dt=0.238 beta=4.000 loss=-9.100 dQsin=0.258 dQint=0.106 energy=395.875 logprob=396.324 logdet=-0.449 sldf=-0.245 sldb=0.219 sld=-0.449 xeps=0.059 veps=0.054 acc=0.904 sumlogdet=-0.002 acc_mask=0.902 plaqs=0.863 intQ=0.029 sinQ=0.027 lr=0.001\n[06/23/23 14:19:00][INFO][trainer.py:1089] - era=0 epoch=2500 tstep=2501.000 dt=0.244 beta=4.000 loss=-9.489 dQsin=0.247 dQint=0.103 energy=395.602 logprob=395.899 logdet=-0.297 sldf=-0.165 sldb=0.195 sld=-0.297 xeps=0.064 veps=0.058 acc=0.876 sumlogdet=0.001 acc_mask=0.864 plaqs=0.864 intQ=0.028 sinQ=0.024 lr=0.001\n[06/23/23 14:20:04][INFO][trainer.py:1089] - era=0 epoch=2740 tstep=2741.000 dt=0.251 beta=4.000 loss=-9.468 dQsin=0.250 dQint=0.107 energy=395.899 logprob=396.116 logdet=-0.217 sldf=-0.122 sldb=0.183 sld=-0.217 xeps=0.072 veps=0.065 acc=0.857 sumlogdet=0.001 acc_mask=0.854 plaqs=0.863 intQ=-0.045 sinQ=-0.034 lr=0.001\n[06/23/23 14:21:08][INFO][trainer.py:1089] - era=0 epoch=3000 tstep=3001.000 dt=0.236 beta=4.000 loss=-10.554 dQsin=0.248 dQint=0.132 energy=395.727 logprob=395.661 logdet=0.065 sldf=0.030 sldb=0.088 sld=0.065 xeps=0.084 veps=0.071 acc=0.782 sumlogdet=0.002 acc_mask=0.781 plaqs=0.864 intQ=0.024 sinQ=0.015 lr=0.001\n[06/23/23 14:22:12][INFO][trainer.py:1089] - era=0 epoch=3240 tstep=3241.000 dt=0.253 beta=4.000 loss=-10.425 dQsin=0.252 dQint=0.141 energy=396.195 logprob=396.024 logdet=0.171 sldf=0.086 sldb=0.076 sld=0.171 xeps=0.094 veps=0.080 acc=0.790 sumlogdet=0.002 acc_mask=0.795 plaqs=0.864 intQ=-0.002 sinQ=-0.000 lr=0.001\n[06/23/23 14:23:17][INFO][trainer.py:1089] - era=0 epoch=3500 tstep=3501.000 dt=0.271 beta=4.000 loss=-13.095 dQsin=0.254 dQint=0.161 energy=396.836 logprob=396.210 logdet=0.627 sldf=0.335 sldb=-0.134 sld=0.627 xeps=0.109 veps=0.089 acc=0.709 sumlogdet=0.002 acc_mask=0.708 plaqs=0.864 intQ=0.045 sinQ=0.043 lr=0.001\n[06/23/23 14:24:22][INFO][trainer.py:1089] - era=0 epoch=3740 tstep=3741.000 dt=0.242 beta=4.000 loss=-13.164 dQsin=0.226 dQint=0.160 energy=399.160 logprob=397.731 logdet=1.429 sldf=0.772 sldb=-0.496 sld=1.429 xeps=0.123 veps=0.093 acc=0.585 sumlogdet=-0.003 acc_mask=0.574 plaqs=0.864 intQ=0.002 sinQ=-0.000 lr=0.001\n[06/23/23 14:25:27][INFO][trainer.py:1089] - era=0 epoch=4000 tstep=4001.000 dt=0.254 beta=4.000 loss=-15.590 dQsin=0.251 dQint=0.197 energy=399.077 logprob=397.221 logdet=1.856 sldf=1.005 sldb=-0.672 sld=1.856 xeps=0.138 veps=0.104 acc=0.600 sumlogdet=-0.006 acc_mask=0.601 plaqs=0.863 intQ=-0.021 sinQ=-0.013 lr=0.001\n[06/23/23 14:26:31][INFO][trainer.py:1089] - era=0 epoch=4240 tstep=4241.000 dt=0.244 beta=4.000 loss=-14.301 dQsin=0.232 dQint=0.177 energy=401.006 logprob=398.483 logdet=2.523 sldf=1.369 sldb=-1.005 sld=2.523 xeps=0.150 veps=0.109 acc=0.538 sumlogdet=0.006 acc_mask=0.539 plaqs=0.864 intQ=0.018 sinQ=0.008 lr=0.001\n[06/23/23 14:27:38][INFO][trainer.py:1089] - era=0 epoch=4500 tstep=4501.000 dt=0.245 beta=4.000 loss=-14.125 dQsin=0.209 dQint=0.183 energy=403.764 logprob=400.618 logdet=3.145 sldf=1.714 sldb=-1.357 sld=3.145 xeps=0.166 veps=0.109 acc=0.411 sumlogdet=-0.002 acc_mask=0.407 plaqs=0.863 intQ=0.014 sinQ=0.017 lr=0.001\n[06/23/23 14:28:43][INFO][trainer.py:1089] - era=0 epoch=4740 tstep=4741.000 dt=0.241 beta=4.000 loss=-21.004 dQsin=0.266 dQint=0.235 energy=402.266 logprob=399.061 logdet=3.205 sldf=1.750 sldb=-1.493 sld=3.205 xeps=0.172 veps=0.121 acc=0.536 sumlogdet=0.002 acc_mask=0.539 plaqs=0.863 intQ=-0.024 sinQ=-0.016 lr=0.001\n[06/23/23 14:29:47][INFO][trainer.py:1303] - Saving took: 3.12328e-05s\n[06/23/23 14:29:47][INFO][trainer.py:1304] - Checkpoint saved to: /lus/grand/projects/DLHMC/foremans/locations/thetaGPU/projects/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-16-16/nlf-10/xsplit-True/sepnets-True/merge-True/net-16-16-16_dp-0.2_bn-False/tensorflow\n[06/23/23 14:29:47][INFO][trainer.py:1305] - Era 0 took: 1480.06s\n[06/23/23 14:29:52][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:29:58][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:30:03][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:30:08][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 14:30:13][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 14:30:18][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 14:31:02][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/data/train_data.h5\n[06/23/23 14:31:12][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:31:12][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nInference\nEvaluate\noutputs['tensorflow']['eval'] = tfExpU1.trainer.eval(\n    job_type='eval',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = tfExpU1.save_dataset(job_type='eval', nchains=32)\n\n[06/23/23 14:31:23][WARNING][trainer.py:196] - x.shape (original): (4096, 2, 16, 16)\n[06/23/23 14:31:23][WARNING][trainer.py:196] - x[:nchains].shape: (128, 2, 16, 16)\n[06/23/23 14:31:23][INFO][trainer.py:200] - eps = None\nbeta = 4.0\nnlog = 10\ntable = &lt;rich.table.Table object at 0x7f26042c9e70&gt;\nnprint = 500\neval_steps = 2000\nnleapfrog = None\n\n\n\n\n\n{\"model_id\":\"42d6b6d371eb4dbca473bb047e79f408\",\"version_major\":2,\"version_minor\":0}\n\n\n[06/23/23 14:33:00][INFO][trainer.py:200] - estep=0 dt=13.921 beta=4.000 loss=-34.934 dQsin=0.296 dQint=0.242 energy=402.696 logprob=398.796 logdet=3.900 sldf=2.138 sldb=-1.896 sld=3.900 xeps=0.183 veps=0.124 acc=0.472 sumlogdet=0.008 acc_mask=0.469 plaqs=0.865 intQ=0.094 sinQ=0.060\n[06/23/23 14:33:49][INFO][trainer.py:200] - estep=500 dt=0.049 beta=4.000 loss=-14.736 dQsin=0.258 dQint=0.203 energy=404.299 logprob=400.366 logdet=3.932 sldf=2.151 sldb=-1.896 sld=3.932 xeps=0.183 veps=0.124 acc=0.456 sumlogdet=-0.009 acc_mask=0.500 plaqs=0.862 intQ=-0.211 sinQ=-0.169\n[06/23/23 14:34:27][INFO][trainer.py:200] - estep=1000 dt=0.048 beta=4.000 loss=-14.039 dQsin=0.233 dQint=0.211 energy=403.103 logprob=399.185 logdet=3.917 sldf=2.142 sldb=-1.890 sld=3.917 xeps=0.183 veps=0.124 acc=0.477 sumlogdet=0.034 acc_mask=0.477 plaqs=0.864 intQ=0.070 sinQ=0.055\n[06/23/23 14:35:05][INFO][trainer.py:200] - estep=1500 dt=0.048 beta=4.000 loss=-19.743 dQsin=0.225 dQint=0.203 energy=402.832 logprob=398.931 logdet=3.901 sldf=2.136 sldb=-1.895 sld=3.901 xeps=0.183 veps=0.124 acc=0.437 sumlogdet=-0.012 acc_mask=0.453 plaqs=0.864 intQ=-0.016 sinQ=-0.026\n[06/23/23 14:35:49][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:35:54][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:35:59][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:36:04][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldf_ridgeplot.svg\n[06/23/23 14:36:09][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sldb_ridgeplot.svg\n[06/23/23 14:36:14][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/sld_ridgeplot.svg\n[06/23/23 14:36:29][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/data/eval_data.h5\n[06/23/23 14:36:29][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:36:29][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nHMC\noutputs['tensorflow']['hmc'] = tfExpU1.trainer.eval(\n    job_type='hmc',\n    nprint=500,\n    nchains=128,\n    eval_steps=2000,\n)\n_ = tfExpU1.save_dataset(job_type='hmc', nchains=32)\n\n[06/23/23 14:36:40][WARNING][trainer.py:196] - Step size `eps` not specified for HMC! Using default: 0.1000 for generic HMC\n[06/23/23 14:36:40][WARNING][trainer.py:196] - x.shape (original): (4096, 2, 16, 16)\n[06/23/23 14:36:40][WARNING][trainer.py:196] - x[:nchains].shape: (128, 2, 16, 16)\n[06/23/23 14:36:40][INFO][trainer.py:200] - eps = 0.1\nbeta = 4.0\nnlog = 10\ntable = &lt;rich.table.Table object at 0x7f17f07da080&gt;\nnprint = 500\neval_steps = 2000\nnleapfrog = 20\n\n\n\n\n\n{\"model_id\":\"c9e14ead5fda4789a4a40038a941d064\",\"version_major\":2,\"version_minor\":0}\n\n\n[06/23/23 14:38:03][INFO][trainer.py:200] - hstep=0 dt=0.197 beta=4.000 loss=-14.990 dQsin=0.288 dQint=0.195 energy=397.008 logprob=397.008 logdet=0.000 acc=0.822 sumlogdet=0.000 acc_mask=0.828 plaqs=0.862 intQ=-0.148 sinQ=-0.153\n[06/23/23 14:39:55][INFO][trainer.py:200] - hstep=500 dt=0.193 beta=4.000 loss=-11.040 dQsin=0.261 dQint=0.141 energy=396.582 logprob=396.582 logdet=0.000 acc=0.815 sumlogdet=0.000 acc_mask=0.781 plaqs=0.862 intQ=0.055 sinQ=0.060\n[06/23/23 14:41:47][INFO][trainer.py:200] - hstep=1000 dt=0.193 beta=4.000 loss=-14.025 dQsin=0.287 dQint=0.180 energy=395.838 logprob=395.838 logdet=0.000 acc=0.818 sumlogdet=0.000 acc_mask=0.836 plaqs=0.863 intQ=-0.117 sinQ=-0.090\n[06/23/23 14:43:39][INFO][trainer.py:200] - hstep=1500 dt=0.193 beta=4.000 loss=-18.793 dQsin=0.300 dQint=0.195 energy=393.051 logprob=393.051 logdet=0.000 acc=0.813 sumlogdet=0.000 acc_mask=0.844 plaqs=0.862 intQ=0.047 sinQ=0.039\n[06/23/23 14:45:36][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[06/23/23 14:45:45][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[06/23/23 14:45:49][INFO][plot_helpers.py:1005] - Saving figure to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/plots/ridgeplots/svgs/logdet_ridgeplot.svg\n[06/23/23 14:46:01][INFO][common.py:271] - Saving dataset to: /lus/grand/projects/datascience/foremans/locations/thetaGPU/projects/saforem2/l2hmc-qcd/src/l2hmc/notebooks/outputs/2023-06-23-125818/tensorflow/data/hmc_data.h5\n[06/23/23 14:46:01][INFO][experiment.py:362] - Done saving and analyzing data.\n[06/23/23 14:46:01][INFO][experiment.py:363] - Creating summaries for WandB, Aim\nModel Performance\nOur goal is improving the efficiency of our MCMC sampler.\nIn particular, we are interested in generating independent save_datasetrations which we can then use to calculate expectation values of physical observables.\nFor our purposes, we are interested in obtaining lattice configurations from distinct topological charge sectors, as characterized by a configurations topological charge, Q.\nHMC is known to suffer from critical slowing down, a phenomenon in which our configurations remains stuck in some local topological charge sector and fails to produce distinct configurations.\nIn particular, it is known that the integrated autocorrelation time of the topological charge \\tau grows exponentially with decreasing lattice spacing (i.e.¬†continuum limit), making this theory especially problematic.\nBecause of this, we can assess our models‚Äô performance by looking at the tunneling rate, i.e.¬†the rate at which our sampler jumps between these different charge sectors.\nWe can write this quantity as:\n\n\\delta Q = |Q^{(i)} - Q^{(i-1)}|\n\nwhere we look at the difference in the topological charge between sequential configurations.\n\nNote: The efficiency of our sampler is directly proportional to the tunneling rate, which is inversely proportional to the integrated autocorrelation time \\tau, i.e.\n¬†\n\n\\text{Efficiency} \\propto \\delta Q \\propto \\frac{1}{\\tau}\n\nExplicitly, this means that the more efficient the model \\longrightarrow\n- the larger tunneling rate - the smaller integrated autocorrelation time for Q\nimport xarray as xr\n\ndef get_thermalized_configs(\n        x: np.ndarray | xr.DataArray,\n        drop: int = 5\n) -&gt; np.ndarray | xr.DataArray:\n    \"\"\"Drop the first `drop` states across all chains.\n\n    x.shape = [draws, chains]\n    \"\"\"\n    if isinstance(x, np.ndarray):\n        return np.sort(x)[..., :-drop]\n    if isinstance(x, xr.DataArray):\n        return x.sortby(\n            ['chain', 'draw'],\n            ascending=False\n        )[..., :-drop]\n    raise TypeError\nComparisons\nWe can measure our models‚Äô performance explicitly by looking at the average tunneling rate, \\delta Q_{\\mathbb{Z}}, for our trained model and comparing it against generic HMC.\nRecall,\n\\delta Q_{\\mathbb{Z}} := \\big|Q^{(i+1)}_{\\mathbb{Z}} - Q^{(i)}_{\\mathbb{Z}}\\big|\nwhere a higher value of \\delta Q_{\\mathbb{Z}} corresponds to better tunneling of the topological charge, Q_{\\mathbb{Z}}.\nNote that we can get a concise representation of the data from different parts of our run via:\nNote that the data from each of the different parts of our experiment (i.e.¬†train, eval, and hmc) are stored as a dict, e.g.\n&gt;&gt;&gt; list(ptExpU1.trainer.histories.keys())\n['train', 'eval', 'hmc']\n&gt;&gt;&gt; train_history = ptExpU1.trainer.histories['train']\n&gt;&gt;&gt; train_dset = train_history.get_dataset()\n&gt;&gt;&gt; assert isinstance(train_history, l2hmc.utils.history.BaseHistory)\n&gt;&gt;&gt; assert isinstance(train_dset, xarray.Dataset)\n(see below, for example)\nWe aggregate the data into the dsets dict below, grouped by:\n\nFramework (pytorch / tensorflow)\nJob type (train, eval, hmc)\nimport logging\nlog = logging.getLogger(__name__)\ndsets = {}\nfws = ['pt', 'tf']\nmodes = ['train', 'eval', 'hmc']\nfor fw in fws:\n    dsets[fw] = {}\n    for mode in modes:\n        hist = None\n        if fw == 'pt':\n            hist = ptExpU1.trainer.histories.get(mode, None)\n        elif fw == 'tf':\n            hist = tfExpU1.trainer.histories.get(mode, None)\n        if hist is not None:\n            console.print(f'Getting dataset for {fw}: {mode}')\n            dsets[fw][mode] = hist.get_dataset()\n\nGetting dataset for pt: train\nGetting dataset for pt: eval\nGetting dataset for pt: hmc\nGetting dataset for tf: train\nGetting dataset for tf: eval\nGetting dataset for tf: hmc\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['text.usetex'] = False\nimport matplotlib.pyplot as plt\nfrom l2hmc.utils.plot_helpers import COLORS, set_plot_style\n\nset_plot_style()\n\nfig, ax = plt.subplots(figsize=(16, 3), ncols=2)\n\n# ---------------------------------------------\n# ---- DROP FIRST 20% FOR THERMALIZATION ------\n# ---------------------------------------------\nKEEP = int(0.8 * len(dsets['tf']['eval'].draw))\ndqpte = get_thermalized_configs(dsets['pt']['eval']['dQint'].astype('int'))\ndqpth = get_thermalized_configs(dsets['pt']['hmc']['dQint'].astype('int'))\n\ndqtfe = get_thermalized_configs(dsets['tf']['eval']['dQint'].astype('int'))\ndqtfh = get_thermalized_configs(dsets['tf']['hmc']['dQint'].astype('int'))\n\n_ = sns.distplot(\n    dqpte.sum('chain'),\n    kde=False,\n    color=COLORS['blue'],\n    label='Eval',\n    ax=ax[0]\n)\n_ = sns.distplot(\n    dqpth.sum('chain'),\n    kde=False,\n    color=COLORS['red'],\n    label='HMC',\n    ax=ax[0]\n)\n\n_ = ax[0].set_title('PyTorch')\n_ = ax[0].set_xlabel(\n    f'# tunneling events / {dqpte.shape[-1]} configurations'\n)\n_ = ax[0].legend(loc='best', frameon=False)\nplt.legend()\n\n_ = sns.distplot(\n    dqtfe.sum('chain'),\n    kde=False,\n    color=COLORS['blue'],\n    label='Eval',\n    ax=ax[1]\n)\n_ = sns.distplot(\n    dqtfh.sum('chain'),\n    kde=False,\n    color=COLORS['red'],\n    label='HMC',\n    ax=ax[1]\n)\n\n_ = ax[1].set_title('TensorFlow')\n_ = ax[1].set_xlabel(\n    #r\"\"\"$\\sum_{i=0} \\left|\\delta Q_{i}\\right|$\"\"\",\n    #fontsize='large',\n    f'# tunneling events / {dqpte.shape[-1]} configurations'\n)\n_ = ax[1].legend(loc='best', frameon=False)\nTensorFlow Results\nimport rich\nsns.set_context('notebook')\nndraws = len(dsets['tf']['eval']['dQint'].draw)\ndrop = int(0.1 * ndraws)\nkeep = int(0.9 * ndraws)\n\ndqe = dsets['tf']['eval']['dQint'][:, -90:]\ndqh = dsets['tf']['hmc']['dQint'][:, -90:]\n\netot = dqe.astype(int).sum()\nhtot = dqh.astype(int).sum()\n\nfsize = plt.rcParams['figure.figsize']\nfigsize = (2.5 * fsize[0], fsize[1])\nfig, ax = plt.subplots(figsize=figsize, ncols=2)\n_ = dqe.astype(int).plot(ax=ax[0])\n_ = dqh.astype(int).plot(ax=ax[1])\n_ = ax[0].set_title(f'Eval, total: {etot.values}', fontsize='x-large');\n_ = ax[1].set_title(f'HMC, total: {htot.values}', fontsize='x-large');\n_ = fig.suptitle(fr'TensorFlow Improvement: {100*(etot / htot):3.0f}%', fontsize='x-large')\n\nconsole.print(f\"TensorFlow, EVAL\\n dQint.sum('chain'):\\n {dqe.astype(int).sum('chain').T}\")\nconsole.print(f\"dQint.sum(): {dqe.astype(int).sum().T}\")\nconsole.print(f\"TensorFlow, HMC\\n dQint.sum('chain'):\\n {dqh.astype(int).sum('chain').T}\")\nconsole.print(f\"dQint.sum(): {dqh.astype(int).sum().T}\")\n\nTensorFlow, EVAL\n dQint.sum('chain'):\n &lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([13, 22, 11, 25, 14, 19, 20, 25, 13, 19, 22, 18, 10, 10, 15, 12, 17,\n       10, 19, 23, 17, 16, 14, 24, 16, 29, 15, 18, 16, 16, 20, 14,  5,  8,\n        9, 13, 14, 20, 24, 12, 12, 15, 23, 20,  8, 14, 16, 12, 17, 28, 18,\n       19, 18, 12, 27, 16, 24, 14, 21, 20, 19, 14, 14, 21, 22, 11, 22, 17,\n       23, 20, 17, 15, 22, 11, 12, 13, 17, 12, 17, 24, 27, 16, 12, 13, 12,\n       17, 18, 18, 16, 24])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199\ndQint.sum(): &lt;xarray.DataArray 'dQint' ()&gt;\narray(1527)\nTensorFlow, HMC\n dQint.sum('chain'):\n &lt;xarray.DataArray 'dQint' (draw: 90)&gt;\narray([ 8,  5,  9,  7, 14, 16, 12, 12, 15, 12, 10, 13, 13, 12,  8, 13, 12,\n        3, 11, 12,  7, 12, 10,  6,  8, 16,  8, 17,  8,  9,  7,  1, 10, 12,\n       13, 11, 21, 15, 11, 11,  7, 10,  6,  6, 13,  7,  8,  9, 11,  5, 12,\n       15, 13, 10,  6, 10,  6,  8,  7,  6, 11, 12, 12, 13,  7, 16,  8, 10,\n       14, 17, 11, 11, 13,  9,  9, 11,  9, 11, 13,  9, 11,  9,  7,  4,  6,\n        7, 10, 12, 17, 14])\nCoordinates:\n  * draw     (draw) int64 110 111 112 113 114 115 ... 194 195 196 197 198 199\ndQint.sum(): &lt;xarray.DataArray 'dQint' ()&gt;\narray(928)\nPyTorch Results\nsns.set_context('notebook')\nndraws = len(dsets['pt']['eval']['dQint'].draw)\ndrop = int(0.1 * ndraws)\nkeep = int(0.9 * ndraws)\n\ndqe = dsets['pt']['eval']['dQint'][:, -90:]\ndqh = dsets['pt']['hmc']['dQint'][:, -90:]\n\netot = dqe.astype(int).sum()\nhtot = dqh.astype(int).sum()\n\nfsize = plt.rcParams['figure.figsize']\nfigsize = (2.5 * fsize[0], 0.8 * fsize[1])\nfig, ax = plt.subplots(figsize=figsize, ncols=2)\n_ = dqe.astype(int).plot(ax=ax[0])\n_ = dqh.astype(int).plot(ax=ax[1])\n_ = ax[0].set_title(f'Eval, total: {etot.values}', fontsize='x-large');\n_ = ax[1].set_title(f'HMC, total: {htot.values}', fontsize='x-large');\n_ = fig.suptitle(fr'PyTorch Improvement: {100*(etot / htot):3.0f}%', fontsize='x-large')\n\nconsole.print(60 * '-')\nconsole.print(f\"PyTorch, EVAL\\n dQint.sum('chain'):\\n {dqe.astype(int).sum('chain').T.values}\")\nconsole.print(f\"dQint.sum(): {dqe.astype(int).sum().T.values}\")\nconsole.print(60 * '-')\nconsole.print(f\"PyTorch, HMC\\n dQint.sum('chain'):\\n {dqh.astype(int).sum('chain').T.values}\")\nconsole.print(f\"dQint.sum(): {dqh.astype(int).sum().T.values}\")\n\n------------------------------------------------------------\nPyTorch, EVAL\n dQint.sum('chain'):\n [26 16 12 23 13 16 39 18 18 18 15 16 27 17 25 16 11 21 20 18 22 21 13 20\n 16 19 12 26 17 16 13 17 14 18 15 15 18 23 29 20 17 23 11 16 15 15 19 22\n 25 22 19 28 20 20 20 11 24 24 13 15 26 22 14 22 23 23 19 17 21 10 20 14\n 16 17 19 11 21 19 15 20 13 16  9 20 21 20 21 22 23 15]\ndQint.sum(): 1677\n------------------------------------------------------------\nPyTorch, HMC\n dQint.sum('chain'):\n [14  6 10  5  7  9 14  8 12 10 19  8  4  6  9  7  9 17  9  7 11 13  9 11\n  4  9  7 14 10  6 15  6 10  9 13  7 15 10  7  9  3 14  8  6 11  9  9  6\n  9  6 16  6  8 10 14 16  9 12 15 10  9  9  5  6 12 17  6  8  9 12  5 12\n 16  9  7  8 11 15 16 12 12  7  5 14  9  9 13  6 12 10]\ndQint.sum(): 883\nComparisons\nimport matplotlib.pyplot as plt\nfrom l2hmc.utils.plot_helpers import set_plot_style, COLORS\n\nimport seaborn as sns\nset_plot_style()\nplt.rcParams['axes.linewidth'] = 2.0\nsns.set_context('notebook')\nfigsize = plt.rcParamsDefault['figure.figsize']\nplt.rcParams['figure.dpi'] = plt.rcParamsDefault['figure.dpi']\n\nfor idx in range(4):\n    fig, (ax, ax1) = plt.subplots(\n        ncols=2,\n        #nrows=4,\n        figsize=(3. * figsize[0], figsize[1]),\n    )\n    _ = ax.plot(\n        dsets['pt']['eval'].intQ[idx] + 5,  # .dQint.mean('chain')[100:],\n        color=COLORS['red'],\n        ls=':',\n        label='Trained',\n        lw=1.5,\n    );\n\n    _ = ax.plot(\n        dsets['pt']['hmc'].intQ[idx] - 5,  # .dQint.mean('chain')[100:],\n        ls='-',\n        label='HMC',\n        color='#666666',\n        zorder=5,\n        lw=2.0,\n    );\n\n    _ = ax1.plot(\n        dsets['tf']['eval'].intQ[idx] + 5,  # .dQint.mean('chain')[-100:],\n        color=COLORS['blue'],\n        ls=':',\n        label='Trained',\n        lw=1.5,\n\n    );\n    _ = ax1.plot(\n        dsets['tf']['hmc'].intQ[idx] - 5,  # .dQint.mean('chain')[-100:],\n        color='#666666',\n        ls='-',\n        label='HMC',\n        zorder=5,\n        lw=2.0,\n    );\n    _ = ax.set_title('PyTorch', fontsize='x-large')\n    _ = ax1.set_title('TensorFlow', fontsize='x-large')\n    #_ = ax1.set_ylim(ax.get_ylim())\n    _ = ax.grid(True, alpha=0.2)\n    _ = ax1.grid(True, alpha=0.2)\n    _ = ax.set_xlabel('MD Step', fontsize='large')\n    _ = ax1.set_xlabel('MD Step', fontsize='large')\n    _ = ax.set_ylabel('dQint', fontsize='large')\n    _ = ax.legend(loc='best', ncol=2, labelcolor='#939393')\n    _ = ax1.legend(loc='best', ncol=2, labelcolor='#939393')"
  },
  {
    "objectID": "qmd/l2hmc-2DU1.html#contents",
    "href": "qmd/l2hmc-2DU1.html#contents",
    "title": "2D U(1) Example",
    "section": "",
    "text": "l2hmc: Example\nImports / Setup\nInitialize and Build Experiment objects:\nPyTorch\nTraining\nInference\nTensorFlow\nTrain\nInference\nModel Performance\nComparisons\nTensorFlow Results\nPyTorch Results\nComparisons"
  },
  {
    "objectID": "qmd/l2hmc-2DU1.html#imports-setup",
    "href": "qmd/l2hmc-2DU1.html#imports-setup",
    "title": "2D U(1) Example",
    "section": "Imports / Setup",
    "text": "Imports / Setup"
  },
  {
    "objectID": "qmd/l2hmc-2DU1.html#pytorch",
    "href": "qmd/l2hmc-2DU1.html#pytorch",
    "title": "2D U(1) Example",
    "section": "PyTorch",
    "text": "PyTorch"
  },
  {
    "objectID": "qmd/l2hmc-2DU1.html#tensorflow",
    "href": "qmd/l2hmc-2DU1.html#tensorflow",
    "title": "2D U(1) Example",
    "section": "TensorFlow",
    "text": "TensorFlow"
  },
  {
    "objectID": "qmd/l2hmc-2DU1.html#tensorflow-results",
    "href": "qmd/l2hmc-2DU1.html#tensorflow-results",
    "title": "2D U(1) Example",
    "section": "TensorFlow Results",
    "text": "TensorFlow Results"
  },
  {
    "objectID": "qmd/l2hmc-2DU1.html#comparisons-1",
    "href": "qmd/l2hmc-2DU1.html#comparisons-1",
    "title": "2D U(1) Example",
    "section": "Comparisons",
    "text": "Comparisons"
  },
  {
    "objectID": "qmd/diffusion/diffusion.html#imports-setup",
    "href": "qmd/diffusion/diffusion.html#imports-setup",
    "title": "MCMC + Diffusion Sampling",
    "section": "Imports / Setup",
    "text": "Imports / Setup\nfrom __future__ import absolute_import, print_function, annotations, division\nfrom dataclasses import dataclass\n\nimport sys\nimport os\nimport math\nimport numpy as np\nimport scipy\nimport time\nfrom random import randrange\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom ezpz.dist import setup_torch\n\nport = np.random.randint(5000, 6000)\nprint(f\"Using port: {port}\")\n\nRANK = setup_torch(\n    backend=\"DDP\",\n    port=f\"{port}\"\n)\n\n\nUsing port: 5561\nUsing DDP for distributed training\n\n&lt;pre style=\"white-space:pre;overflow-x:auto;line-height:normal;\"&gt;\nGlobal Rank: &lt;span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"&gt;0&lt;/span&gt; &lt;span style=\"color: #800080; text-decoration-color: #800080\"&gt;/&lt;/span&gt; &lt;span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"&gt;0&lt;/span&gt;\n&lt;/pre&gt;\n\n\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom l2hmc.main import build_experiment\nfrom l2hmc.utils.rich import get_console\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nimport opinionated\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nfrom pandas.io.formats import style\nimport scipy\nimport time\nfrom random import randrange\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\n\nset_plot_style()\nconsole = get_console()\nprint(console.is_jupyter)\nif console.is_jupyter:\n    console.is_jupyter = False\nprint(console.is_jupyter)\n\nUsing device: cpu\n\n\n\nFailed to download font: Source Sans Pro, skipping!\nFailed to download font: Titillium WebRoboto Condensed, skipping!\n\n\nTrue\n\n\n\nFalse\n\n\n\n#plt.style.use('opinionated_minimal')\nimport pandas as pd\nimport opinionated\nwith plt.style.context(opinionated.STYLES['opinionated_min']):\n    #plt.rcParams['image.cmap'] = 'viridis'\n    sns.set_context('notebook')\n    df = pd.DataFrame({'x': np.random.randn(100), 'y': np.random.randn(100)})\n    df.plot.hexbin(x='x', y='y', gridsize=20, cmap='viridis')\n\n\n\n\n\nplt.style.use(opinionated.STYLES['opinionated_min'])\nsns.set_context('notebook')"
  },
  {
    "objectID": "qmd/diffusion-alt/diffusion.html",
    "href": "qmd/diffusion-alt/diffusion.html",
    "title": "Denoising Diffusion Probabilistic Models",
    "section": "",
    "text": "Denoising Diffusion Probabilistic Models\nImports / Setup\n2D U(1)\nTrain Diffusion Model\nBuild Diffusion Model with UNet Architecure\nPerform initial training on HMC samples\nHMC Sampling with Diffusion\nAlternate\nImports / Setup\nfrom __future__ import absolute_import, print_function, annotations, division\nfrom dataclasses import dataclass\n\nimport sys\nimport os\nimport math\nimport numpy as np\nimport scipy\nimport time\nfrom random import randrange\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom ezpz.dist import setup_torch\n\nport = np.random.randint(5000, 6000)\nprint(f\"Using port: {port}\")\n\nRANK = setup_torch(\n    backend=\"DDP\",\n    port=f\"{port}\"\n)\n\nUsing port: 5561\n\n\nUsing DDP for distributed training\n\n\nGlobal Rank: 0 / 0\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom l2hmc.main import build_experiment\nfrom l2hmc.utils.rich import get_console\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nimport opinionated\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\nfrom l2hmc.utils.plot_helpers import set_plot_style\n\nfrom pandas.io.formats import style\nimport scipy\nimport time\nfrom random import randrange\nfrom l2hmc.diffusion.diffusion import PureMH, MH_Diffusion\n\nset_plot_style()\nconsole = get_console()\nprint(console.is_jupyter)\nif console.is_jupyter:\n    console.is_jupyter = False\nprint(console.is_jupyter)\n\nUsing device: cpu\n\n\nFailed to download font: Source Sans Pro, skipping!\nFailed to download font: Titillium WebRoboto Condensed, skipping!\n\n\nTrue\n\n\nFalse\n#plt.style.use('opinionated_minimal')\nimport pandas as pd\nimport opinionated\nwith plt.style.context(opinionated.STYLES['opinionated_min']):\n    #plt.rcParams['image.cmap'] = 'viridis'\n    sns.set_context('notebook')\n    df = pd.DataFrame({'x': np.random.randn(100), 'y': np.random.randn(100)})\n    df.plot.hexbin(x='x', y='y', gridsize=20, cmap='viridis')\nplt.style.use(opinionated.STYLES['opinionated_min'])\nsns.set_context('notebook')\n2D U(1)\nfrom l2hmc.configs import dict_to_list_of_overrides\n\nseed = np.random.randint(0, 2**32)\nconsole.print(f\"seed = {seed}\")\n\noverrides = {\n    \"seed\": f\"{seed}\",\n    \"precision\": \"float32\",\n    \"init_wandb\": False,\n    \"init_aim\": False,\n    \"use_wandb\": False,\n    \"dynamics\": {\n        \"latvolume\": [32, 32],\n        \"nleapfrog\": 10,\n        \"nchains\": 16,\n        \"eps\": 0.05,\n    },\n    \"network\": {\n        \"use_batch_norm\": False,\n    },\n    'annealing_schedule': {\n        'beta_init': 6.0,\n        'beta_final': 6.0,\n    },\n\n}\nOVERRIDES = dict_to_list_of_overrides(overrides)\n\nseed = 1675333995\nfrom pathlib import Path\nfrom l2hmc.common import get_timestamp\nfrom enrich.console import get_theme, Console\nconsole = Console(theme=get_theme())\n\nOUTDIR = Path(\n    'l2hmc-diffusion-2dU1'\n).joinpath(get_timestamp(\"%Y-%m-%d\"))\nOUTDIR.mkdir(exist_ok=True, parents=True)\nconsole.print(f\"OUTDIR: {OUTDIR}\")\n\ndate = get_timestamp('%Y-%m-%d')\nPLOTS_DIR = OUTDIR.joinpath('plots')\nPLOTS_DIR.mkdir(exist_ok=True, parents=True)\nconsole.print(f\"Saving figures to: {PLOTS_DIR}\")\n\nOUTDIR: l2hmc-diffusion-2dU1/2023-09-21\n\n\nSaving figures to: l2hmc-diffusion-2dU1/2023-09-21/plots\n#os.environ['MASTER_PORT'] = '5436'\n\nexp = build_experiment(\n    overrides=[\n        *OVERRIDES,\n        'framework=pytorch',\n        'backend=DDP'\n    ]\n)\n\n[09/21/23 12:23:55][INFO][dist.py:226] - Caught MASTER_PORT:5561 from environment!\n[09/21/23 12:23:55][INFO][dist.py:338] - Global Rank: 0 / 0\n[09/21/23 12:23:58][INFO][experiment.py:251] - Creating outputs/2023-09-21-122358/pytorch/train\n[09/21/23 12:23:58][INFO][experiment.py:251] - Creating outputs/2023-09-21-122358/pytorch/eval\n[09/21/23 12:23:58][INFO][experiment.py:251] - Creating outputs/2023-09-21-122358/pytorch/hmc\n[09/21/23 12:23:58][INFO][dist.py:226] - Caught MASTER_PORT:5561 from environment!\n[09/21/23 12:23:58][INFO][dist.py:226] - Caught MASTER_PORT:5561 from environment!\n[09/21/23 12:24:06][INFO][trainer.py:441] - Looking for checkpoints in:\n /Users/samforeman/projects/saforem2/l2hmc-qcd/src/l2hmc/checkpoints/U1/2-32-32/nlf-10/xsplit-True/sepnets-True/merge-True/conv-8-16-32-64-128_5-3-3-3-2_2-2-2-2-2/net-16-16-16-16_dp-0.2_bn-False/pytorch\n[09/21/23 12:24:06][WARNING][trainer.py:437] - No checkpoints found to load from\n[09/21/23 12:24:06][WARNING][trainer.py:437] - Restoring global step from ckpt! self._gstep: 0\n[09/21/23 12:24:06][WARNING][trainer.py:437] - Using `torch.optim.Adam` optimizer\n[09/21/23 12:24:06][INFO][trainer.py:284] - num_params in model: 958628260\n[09/21/23 12:24:09][WARNING][trainer.py:250] - logging with freq 50 for wandb.watch\nstate = exp.trainer.dynamics.random_state(6.0)\nxdim = state.x.flatten().shape[0]\n\ndim = xdim\nlow_bound = (-np.pi) * np.ones(dim)\nhigh_bound = (np.pi) * np.ones(dim)\nsigma = 0.15\nretrains = 10\nsamples_per_retrain = 100\ndiffusion_prob = 0.1\nsns.set_context('notebook')\n\noutputs = {}\noutputs['hmc'] = exp.trainer.eval(\n    job_type='hmc',\n    beta=6.0,\n    nprint=100,\n    nchains=16,\n    eval_steps=1000\n)\n#hdset = exp.save_dataset(job_type='hmc', nchains=1)\n\n[09/21/23 12:24:21][WARNING][trainer.py:437] - Step size `eps` not specified for HMC! Using default: 0.1000 for generic HMC\n[09/21/23 12:24:21][WARNING][trainer.py:437] - x.shape (original): torch.Size([16, 2, 32, 32])\n[09/21/23 12:24:21][WARNING][trainer.py:437] - x[:nchains].shape: torch.Size([16, 2, 32, 32])\n[09/21/23 12:24:21][INFO][trainer.py:1058] - eps=0.1\nbeta=6.0\nnlog=10\ntable=&lt;rich.table.Table object at 0x2e1b98520&gt;\nnprint=100\neval_steps=1000\nnleapfrog=20\n\n\n\n\n\n[09/21/23 12:24:24][INFO][trainer.py:1188] - hstep=0 dt=0.024 beta=6.000 loss=3.410 dQsin=0.125 dQint=0.000 energy=1586.502 logprob=1586.502 logdet=0.000 acc=0.472 sumlogdet=0.000 acc_mask=0.500 plaqs=0.909 intQ=0.000 sinQ=0.051\n[09/21/23 12:24:27][INFO][trainer.py:1188] - hstep=100 dt=0.026 beta=6.000 loss=2.876 dQsin=0.163 dQint=0.000 energy=1555.800 logprob=1555.800 logdet=0.000 acc=0.593 sumlogdet=0.000 acc_mask=0.688 plaqs=0.912 intQ=-0.125 sinQ=-0.159\n[09/21/23 12:24:31][INFO][trainer.py:1188] - hstep=200 dt=0.025 beta=6.000 loss=4.678 dQsin=0.088 dQint=0.063 energy=1569.994 logprob=1569.994 logdet=0.000 acc=0.451 sumlogdet=0.000 acc_mask=0.250 plaqs=0.912 intQ=-0.187 sinQ=-0.149\n[09/21/23 12:24:34][INFO][trainer.py:1188] - hstep=300 dt=0.024 beta=6.000 loss=14.041 dQsin=0.094 dQint=0.000 energy=1554.118 logprob=1554.118 logdet=0.000 acc=0.438 sumlogdet=0.000 acc_mask=0.438 plaqs=0.914 intQ=-0.125 sinQ=-0.114\n[09/21/23 12:24:38][INFO][trainer.py:1188] - hstep=400 dt=0.024 beta=6.000 loss=-0.739 dQsin=0.199 dQint=0.000 energy=1566.516 logprob=1566.516 logdet=0.000 acc=0.509 sumlogdet=0.000 acc_mask=0.562 plaqs=0.912 intQ=-0.437 sinQ=-0.452\n[09/21/23 12:24:41][INFO][trainer.py:1188] - hstep=500 dt=0.045 beta=6.000 loss=1.545 dQsin=0.100 dQint=0.000 energy=1570.837 logprob=1570.837 logdet=0.000 acc=0.448 sumlogdet=0.000 acc_mask=0.562 plaqs=0.911 intQ=0.125 sinQ=0.189\n[09/21/23 12:24:45][INFO][trainer.py:1188] - hstep=600 dt=0.025 beta=6.000 loss=3.780 dQsin=0.094 dQint=0.000 energy=1568.012 logprob=1568.012 logdet=0.000 acc=0.463 sumlogdet=0.000 acc_mask=0.500 plaqs=0.913 intQ=0.438 sinQ=0.466\n[09/21/23 12:24:50][INFO][trainer.py:1188] - hstep=700 dt=0.023 beta=6.000 loss=-0.902 dQsin=0.113 dQint=0.000 energy=1563.778 logprob=1563.778 logdet=0.000 acc=0.475 sumlogdet=0.000 acc_mask=0.375 plaqs=0.913 intQ=0.688 sinQ=0.628\n[09/21/23 12:24:53][INFO][trainer.py:1188] - hstep=800 dt=0.024 beta=6.000 loss=11.416 dQsin=0.061 dQint=0.000 energy=1561.427 logprob=1561.427 logdet=0.000 acc=0.339 sumlogdet=0.000 acc_mask=0.438 plaqs=0.913 intQ=0.813 sinQ=0.755\n[09/21/23 12:24:57][INFO][trainer.py:1188] - hstep=900 dt=0.028 beta=6.000 loss=1.114 dQsin=0.127 dQint=0.000 energy=1564.465 logprob=1564.465 logdet=0.000 acc=0.699 sumlogdet=0.000 acc_mask=0.625 plaqs=0.913 intQ=0.938 sinQ=0.893\n# %matplotlib inline\nfrom l2hmc.common import plot_dataset\nsns.set_context('notebook')\nhdataset = outputs['hmc']['history'].get_dataset()\nplot_dataset(hdataset, outdir=PLOTS_DIR, job_type='HMC')\n\n[09/21/23 12:25:06][INFO][plot_helpers.py:1049] - Saving figure to: l2hmc-diffusion-2dU1/2023-09-21/plots/ridgeplots/svgs/energy_ridgeplot.svg\n[09/21/23 12:25:09][INFO][plot_helpers.py:1049] - Saving figure to: l2hmc-diffusion-2dU1/2023-09-21/plots/ridgeplots/svgs/logprob_ridgeplot.svg\n[09/21/23 12:25:11][INFO][plot_helpers.py:1049] - Saving figure to: l2hmc-diffusion-2dU1/2023-09-21/plots/ridgeplots/svgs/logdet_ridgeplot.svg\nimport torch\n\ninitial_states = []\nstate_init = exp.trainer.dynamics.random_state(6.0)\nx = state_init.x\nbeta = state_init.beta\n\nNSAMPLES = 1000\nfor idx in range(NSAMPLES + int(0.1 * NSAMPLES)):\n    if idx % 100 == 0:\n        console.print(f\"step: {idx}\")\n        \n    x, metrics = exp.trainer.hmc_step((x, beta))\n    if idx &gt; int((0.1 * NSAMPLES)):\n        initial_states.append(x)\n\ninitial_states = torch.stack(initial_states).squeeze()\ninitial_states_np = initial_states.detach().cpu().numpy()\n\nstep: 0\n\n\nstep: 100\n\n\nstep: 200\n\n\nstep: 300\n\n\nstep: 400\n\n\nstep: 500\n\n\nstep: 600\n\n\nstep: 700\n\n\nstep: 800\n\n\nstep: 900\n\n\nstep: 1000\ninitial_states_np.shape\n\n(999, 16, 2048)\nx_ = initial_states_np.reshape(-1, 16, 2, 32, 32)\ntmp_ = x_[:, 0, ...]\nconsole.print(f'{x_.shape}')\nconsole.print(f'{tmp_.shape}')\n\n(999, 16, 2, 32, 32)\n\n\n(999, 2, 32, 32)\nfrom l2hmc.common import savefig\n\n#x_ = initial_states_np[:100].reshape(-1, 2, 32, 32)\ntmp_ = x_[:, 0, ...]\nfig, ax = plt.subplots()\nsns.kdeplot(\n    x=tmp_[-100:, 0].flatten(),\n    y=tmp_[-100:, 1].flatten(),\n    # ax=ax,\n    cmap='viridis',\n    # ax=axes[0],\n    # cmap=\"Blues\",\n    shade=False,\n    # bw_adjust=0.5,\n    thresh=0\n)\nax.set_xlim((-4, 4))\nax.set_ylim((-4, 4))\nsavefig(\n    f'hmc_samples-{NSAMPLES}',\n    Path(PLOTS_DIR),\n    tstamp=True,\n)\n\nSaving hmc_samples-1000-2023-09-21-122840 to l2hmc-diffusion-2dU1/2023-09-21/plots\nclass Diffusion:\n    def __init__(\n            self,\n            noise_steps: int = 1000,\n            beta_start: float = 1e-4,\n            beta_end: float = 0.02,\n            nchannels: int = 2,\n            img_size: int = 256,\n            device: str = \"cuda\"\n    ):\n        self.noise_steps = noise_steps\n        self.beta_start = beta_start\n        self.beta_end = beta_end\n        self.img_size = img_size\n        self.device = device\n        self.nchannels = nchannels\n\n        self.beta = self.prepare_noise_schedule().to(device)\n        self.alpha = 1. - self.beta\n        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n\n    def prepare_noise_schedule(self):\n        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n\n    def noise_images(self, x, t):\n        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n        sqrt_one_minus_alpha_hat = torch.sqrt(\n            1 - self.alpha_hat[t]\n        )[:, None, None, None]\n        eps = torch.randn_like(x)\n        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * eps, eps\n\n    def sample_timesteps(self, n):\n        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n\n    def sample(self, model, n):\n        # console.print(f\"Sampling {n} new images....\")\n        model.eval()\n        with torch.no_grad():\n            x = torch.randn(\n                (n, self.nchannels, self.img_size, self.img_size)\n            ).to(self.device)\n            sample_bar = tqdm(\n                reversed(range(1, self.noise_steps)),\n                position=0,\n                total=self.noise_steps - 1,\n                dynamic_ncols=True,\n            )\n            for i in sample_bar:\n                t = (torch.ones(n) * i).long().to(self.device)\n                predicted_noise = model(x, t)\n                alpha = self.alpha[t][:, None, None, None]\n                alpha_hat = self.alpha_hat[t][:, None, None, None]\n                beta = self.beta[t][:, None, None, None]\n                if i &gt; 1:\n                    noise = torch.randn_like(x)\n                else:\n                    noise = torch.zeros_like(x)\n                x = (\n                    (1 / torch.sqrt(alpha))\n                    * (\n                        x \n                        - ((1 - alpha) / (torch.sqrt(1 - alpha_hat)))\n                        * predicted_noise\n                    ) \n                    + (torch.sqrt(beta) * noise)\n                )\n        model.train()\n        x = (x + np.pi) % (2 * np.pi) - np.pi\n        return x\ninitial_states.shape\n\ntorch.Size([999, 16, 2048])\nTrain Diffusion Model\nimport torchvision\nimport os\nimport random\nfrom pathlib import Path\nimport torch\nimport torchvision\nimport torchvision.transforms as T\nimport numpy as np\nfrom PIL import Image\n#from fastdownload import FastDownload\nfrom torch.utils.data import DataLoader\n\ndef save_images(images, path, **kwargs):\n    grid = torchvision.utils.make_grid(images, **kwargs)\n    ndarr = grid.permute(1, 2, 0).to('cpu').numpy()\n    im = Image.fromarray(ndarr)\n    im.save(path)\nBuild Diffusion Model with UNet Architecure\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\nfrom l2hmc.common import savefig\nfrom l2hmc.diffusion.modules import NoiseScheduler, UNet\nfrom l2hmc.diffusion import ddpm\n\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nconfig = {\n    'channels_in': 2,\n    'channels_out': 2,\n    'train_batch_size': 5,\n    'learning_rate': 0.001,\n    'num_epochs': 1,\n    'noise_steps': 100,\n    'beta': 6.0,\n    'img_size': 32,\n    'retrains': 10,\n    'samples_per_retrain': 500,\n    'diffusion_prob': 0.1,\n}\n\nmodel = UNet(c_in=2, c_out=2)\n\ndataset = TensorDataset(initial_states.reshape(-1, 2, 32, 32))\ndataloader = DataLoader(\n    dataset,\n    batch_size=config[\"train_batch_size\"],\n    shuffle=False,\n    drop_last=True\n)\n\n\noptimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\nmse = nn.MSELoss()\ndiffusion = Diffusion(\n    noise_steps=100,\n    img_size=32,\n    device=DEVICE,\n    nchannels=2,\n)\n#logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\nl = len(dataloader)\n\nrun_name = 'diffusion2dU1'\nPerform initial training on HMC samples\nfrom torch import optim\ndevice = 'cpu'\n#dataloader = get_data(args)\n#model = UNet().to(device)\n\nsampled_images_history = []\n\nfor epoch in range(config['num_epochs']):\n    console.print(f\"Starting epoch {epoch}:\")\n    pbar = tqdm(dataloader)\n    for i, images in enumerate(pbar):\n        if isinstance(images, (tuple, list)) and len(images) == 1:\n            images = images[0]\n        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n        x_t, noise = diffusion.noise_images(images, t)\n        predicted_noise = model(x_t, t)\n        loss = mse(noise, predicted_noise)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        pbar.set_postfix({'epoch': epoch, 'batch': i, 'MSE': loss.item()})\n    console.print(f'epoch: {epoch}, loss: {loss.item()}')\n    sampled_images = diffusion.sample(model, n=images.shape[0])\n    sampled_images_history.append(sampled_images)\n    sns.set_context('notebook')\n    #tmp = initial_states.reshape(-1, 2, 32, 32)\n    fig, ax = plt.subplots(ncols=2)\n    _ = ax[0].imshow(sampled_images[0, 0, :, :])\n    _ = ax[1].imshow(sampled_images[0, 1, :, :])\n    _ = ax[0].set_xticklabels([])\n    _ = ax[1].set_xticklabels([])\n    _ = ax[0].set_yticklabels([])\n    _ = ax[1].set_yticklabels([])\n    _ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n    _ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n    _ = fig.suptitle('Diffusion Samples', y=0.8)\n    plt.show()\n    savefig(fname=f'sampled_image_epoch{epoch}', outdir=PLOTS_DIR, tstamp=True)\n    MODEL_FILE = OUTDIR.joinpath(\"models\", f\"unet-diffusion-epoch{epoch}.pt\")\n    MODEL_FILE.parent.mkdir(exist_ok=True, parents=True)\n    console.print(f\"Saving model checkpoint to: {MODEL_FILE}\")\n    torch.save(model.state_dict(), MODEL_FILE)\n\nStarting epoch 0:\n\n\n{\"model_id\":\"19b415c346b24bef8b60336d7f7bc355\",\"version_major\":2,\"version_minor\":0}\n\n\nepoch: 0, loss: 0.6023472547531128\n\n\n{\"model_id\":\"eea24504754f4cb9ab4d9925a6225c10\",\"version_major\":2,\"version_minor\":0}\n\n\n\n\n\nSaving sampled_image_epoch0-2023-09-21-124506 to l2hmc-diffusion-2dU1/2023-09-21/plots\n\n\nSaving model checkpoint to: l2hmc-diffusion-2dU1/2023-09-21/models/unet-diffusion-epoch0.pt\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\nsns.set_context('notebook')\ntmp = initial_states.reshape(-1, 2, 32, 32)\nfig, ax = plt.subplots(ncols=2)\n_ = ax[0].imshow(tmp[0, 0, :, :])\n_ = ax[1].imshow(tmp[0, 1, :, :])\n_ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n_ = ax[0].set_xticklabels([])\n_ = ax[1].set_xticklabels([])\n_ = ax[0].set_yticklabels([])\n_ = ax[1].set_yticklabels([])\n_ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n_ = fig.suptitle('HMC Samples', y=0.8)\nsampled_images_history_ = torch.stack(sampled_images_history)\nsampled_images_history_.shape\n\ntorch.Size([1, 5, 2, 32, 32])\nsns.set_context('notebook')\nfig, ax = plt.subplots(ncols=2)\n_ = ax[0].imshow(sampled_images_history_[0][0][0])\n_ = ax[1].imshow(sampled_images_history_[0][0][1])\n_ = ax[0].set_xticklabels([])\n_ = ax[1].set_xticklabels([])\n_ = ax[0].set_yticklabels([])\n_ = ax[1].set_yticklabels([])\n_ = ax[0].set_title(r\"$U_{0}$\", loc='center')\n_ = ax[1].set_title(r\"$U_{1}$\", loc='center')\n_ = fig.suptitle('Diffusion Samples', y=0.85)\nfor idx in range(sampled_images_history_.shape[0]):\n    q = exp.trainer.lattice.charges(x=sampled_images_history_[idx])\n    console.print(f'{idx}: {q}')\n\n0: Charges(intQ=tensor([ 5.0000e+00, -4.0000e+00, -6.0000e+00, -4.5535e-07,  1.0000e+00]), sinQ=tensor([ 1.6426, -1.7244, -4.4651,  0.5680,  0.7046]))\nHMC Sampling with Diffusion\n#for retrain_iter in range(config['retrains']):\nstate = exp.trainer.dynamics.random_state(config['beta'])\nx = state.x\n\nhistories = {}\nsamples = []\nhmc_samples = []\ndiffusion_samples = []\n\nglobal_step = 0\nwatcher = {}\nupdate_types = []\ncombined_samples = {}\nglobal_step\n\n0\nfor retrain_iter in range(2):\n    console.print(f'retrain_iter: {retrain_iter}')\n    ndiff_acc = 0\n    ndiff_proposed = 0\n    histories[retrain_iter] = {\n        'diffusion': [],\n        'hmc': [],\n    }\n    #for idx in range(config['samples_per_retrain']):\n    sbar = tqdm(range(10))\n    for idx in sbar:\n        t0_ = time.perf_counter()\n        if idx % 100 == 0:\n            console.print(f'sample idx: {idx}')\n        rand = np.random.uniform()\n        if (retrain_iter &gt;= 1) and rand &lt; diffusion_prob:\n            console.print(f'rand: {rand} &lt; {diffusion_prob}')\n            # Sample from diffusion model\n            x_ = diffusion.sample(model, n=x.shape[0])\n            ll_ = exp.trainer.dynamics.potential_energy(x_, config['beta'])\n            ll = exp.trainer.dynamics.potential_energy(x, config['beta'])\n            ratio = ll_ / ll\n            a = torch.min(torch.ones_like(ratio), ratio)\n            u = torch.rand(a.shape)\n            #u = np.random.uniform()\n            #for jdx in range(u.shape[0]):\n            #    if u[jdx] &lt; a[jdx]:\n            #        samples.append(x_[jdx])\n            #        diffusion_samples.append(x_[jdx])\n            #x = torch.where((u &lt; a), x_, x.reshape_as(x_)).reshape_as(x)\n            x = torch.where((u &lt; a)[:, None, None, None], x_, x.reshape_as(x_))\n            samples.append(x)\n            diffusion_samples.append(x)\n            combined_samples[global_step] = x\n            watcher[global_step] = 'diffusion'\n            #diffusion_samples.extend(x)\n            #samples.extend(x)\n            #ndiff_acc += \n            #if u &lt; a:\n            #    console.print('Accepted diffusion sample!')\n            #    console.print(f'{ndiff_acc} / {ndiff_proposed}')\n            #    ndiff_acc += 1\n            #    x = x_\n            #    diffusion_samples.append(x)\n            #    samples.append(x)\n        else:\n            # Oherwise, HMC\n            x, metrics = exp.trainer.hmc_step((x, config['beta']))\n            hmc_samples.append(x)\n            samples.append(x)\n            combined_samples[global_step] = x\n            watcher[global_step] = 'HMC'\n        smetrics = {\n            'idx': idx,\n            'global_step': global_step,\n            'dt': time.perf_counter() - t0_,\n        }\n        global_step += 1\n        #smetrics |= {\n        #    f'{k}': {torch.tensor(v).mean().item()} for k, v in metrics.items()\n        #}\n        sbar.set_postfix(smetrics)\n    # Train loop\n    dataset = TensorDataset(\n        torch.stack(hmc_samples).reshape(-1, 2, 32, 32)\n    )\n    dataloader = DataLoader(\n        dataset,\n        shuffle=False,\n        drop_last=True,\n        batch_size=config[\"train_batch_size\"],\n    )\n    pbar = tqdm(dataloader)\n    for i, batch in enumerate(pbar):\n        if i == 0:\n            console.print('Retraining...')\n        if isinstance(batch, (tuple, list)) and len(batch) == 1:\n            batch, = batch\n        batch = batch.reshape(-1, 2, 32, 32)\n        t0 = time.time()\n        t = diffusion.sample_timesteps(batch.shape[0]).to(device)\n        x_t, noise = diffusion.noise_images(batch, t)\n        predicted_noise = model(x_t, t)\n        loss = mse(noise, predicted_noise)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        t1 = time.time()\n        pbar.set_postfix(\n            {\n                'global_step': global_step,\n                'retrain_iter': retrain_iter,\n                'batch': i,\n                'dt': t1 - t0,\n                'MSE': loss.item()\n            }\n        )\n\nretrain_iter: 0\n\n\n{\"model_id\":\"17132d7ca8624fa387ee9467e4f1fa4d\",\"version_major\":2,\"version_minor\":0}\n\n\nsample idx: 0\n\n\n{\"model_id\":\"0ed1080fdebd4f7b9aae80db0d36b96b\",\"version_major\":2,\"version_minor\":0}\n\n\nRetraining...\n\n\nretrain_iter: 1\n\n\n{\"model_id\":\"d0346019e21b4d2a9b624dc59e84015b\",\"version_major\":2,\"version_minor\":0}\n\n\nsample idx: 0\n\n\nrand: 0.05506106760134255 &lt; 0.1\n\n\n{\"model_id\":\"c02b09d53ada46a194a47921f0ab3cba\",\"version_major\":2,\"version_minor\":0}\n\n\nrand: 0.07860283644524213 &lt; 0.1\n\n\n{\"model_id\":\"184df3f1c9714ece9756866b2617ed02\",\"version_major\":2,\"version_minor\":0}\n\n\n{\"model_id\":\"eaa0d84229c04618b7a2bffe2a4b1739\",\"version_major\":2,\"version_minor\":0}\n\n\nRetraining...\nconsole.print('\\n'.join([f\"{i.shape}\" for i in samples[:100]]))\n\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2048])\ntorch.Size([16, 2, 32, 32])\ntorch.Size([16, 2048])\ntorch.Size([16, 2, 32, 32])\nsamples_ = torch.stack([i.reshape(-1, 2, 32, 32) for i in samples])\nsamples_.shape\n\ntorch.Size([30, 16, 2, 32, 32])\nlen(hmc_samples)\n\n28\nlen(diffusion_samples)\n\n2\nhmc_samples_ = torch.stack([i.reshape(-1, 2, 32, 32) for i in hmc_samples])\ndiffusion_samples_ = torch.stack(\n    [i.reshape(-1, 2, 32, 32) for i in diffusion_samples]\n)\nhmc_samples_.shape\n\ntorch.Size([28, 16, 2, 32, 32])\ndiffusion_samples_.shape\n\ntorch.Size([2, 16, 2, 32, 32])\nsamples_.shape\n\ntorch.Size([30, 16, 2, 32, 32])\ndef calc_plaqs(x):\n    return torch.stack([\n        exp.trainer.lattice.plaqs(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\n\ndef calc_intQ(x):\n    return torch.stack([\n        exp.trainer.lattice.int_charges(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\n    \ndef calc_sinQ(x):\n    return torch.stack([\n        exp.trainer.lattice.sin_charges(\n            x[:, idx]\n        ) for idx in range(x.shape[1])\n    ], -1)\nsamples_init_ = initial_states.reshape(-1, initial_states.shape[1], 2, 32, 32)\nsamples_init_.shape\n\ntorch.Size([999, 16, 2, 32, 32])\nmetrics_init_ = {\n    'plaqs': calc_plaqs(samples_init_),\n    'intQ': calc_intQ(samples_init_),\n    'sinQ': calc_sinQ(samples_init_)\n}\n    \nmetrics_ = {\n    'plaqs': calc_plaqs(samples_),\n    'intQ': calc_intQ(samples_),\n    'sinQ': calc_sinQ(samples_)\n}\n\nmetrics_hmc_ = {\n    'plaqs': calc_plaqs(hmc_samples_),\n    'intQ': calc_intQ(hmc_samples_),\n    'sinQ': calc_sinQ(hmc_samples_)\n}\n\nmetrics_diffusion_ = {\n    'plaqs': calc_plaqs(diffusion_samples_),\n    'intQ': calc_intQ(diffusion_samples_),\n    'sinQ': calc_sinQ(diffusion_samples_)\n}\nmetrics_['plaqs'].shape\n\ntorch.Size([30, 16])\nconsole.print('\\n'.join([f\"{k}: {v}\" for k, v in watcher.items()]))\n\n0: HMC\n1: HMC\n2: HMC\n3: HMC\n4: HMC\n5: HMC\n6: HMC\n7: HMC\n8: HMC\n9: HMC\n10: HMC\n11: HMC\n12: HMC\n13: HMC\n14: HMC\n15: HMC\n16: HMC\n17: HMC\n18: HMC\n19: HMC\n20: HMC\n21: HMC\n22: HMC\n23: HMC\n24: HMC\n25: HMC\n26: HMC\n27: diffusion\n28: HMC\n29: diffusion\nfig, ax = plt.subplots()\n\n_ = ax.plot(metrics_['plaqs'][:, 0], label='Combined')\n_ = ax.plot(metrics_hmc_['plaqs'][:, 0], label='HMC')\n_ = ax.plot(metrics_diffusion_['plaqs'][:, 0], label='Diffusion')\n#_ = ax.plot(metrics_hmc1['plaqs'], label='HMC 1')\n#_ = ax.plot(metrics_diff_['plaqs'], label='Diffusion')\n_ = ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1.00))\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_init_.items()):\n    _ = ax[idx].plot(val[:, 0], label='HMC (Initial Samples)')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n    #_ = ax[idx].legend(loc='best', frameon=True, edgecolor=\"#838383\")\n\n_ = fig.suptitle(f\"Initial HMC States\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_.items()):\n    _ = ax[idx].plot(val[:, 0], label='Combined')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n    #_ = ax[idx].legend(loc='best', frameon=True, edgecolor=\"#838383\")\n\n_ = fig.suptitle(f\"Combined Samples\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_hmc_.items()):\n    _ = ax[idx].plot(val[:, 0], label='HMC')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n_ = fig.suptitle(f\"Generated HMC States\", y=0.92)\nfig, ax = plt.subplots(ncols=3, figsize=(14, 4))\nfor idx, (key, val) in enumerate(metrics_diffusion_.items()):\n    _ = ax[idx].plot(val[:, 0], label='Diffusion')\n    _ = ax[idx].set_ylabel(key, loc='center')\n    _ = ax[idx].set_xlabel('Draw', loc='center')\n_ = fig.suptitle(f\"Generated Diffusion States\", y=0.92)\nfrom l2hmc.lattice.u1.pytorch.lattice import plaq_exact\nplaq_exact(torch.tensor(6.0))\n\ntensor(0.9124)\nfig, ax = plt.subplots()\n#_ = plt.hist(metrics_['intQ'].flatten(), color='C0', alpha=0.6, label='Combined', edgecolor='none')\n_ = ax.hist(\n    metrics_diffusion_['intQ'].flatten(),\n    color='C0',\n    alpha=0.6,\n    edgecolor='none',\n    label='Diffusion',\n    density=True,\n)\n_ = ax.hist(\n    metrics_hmc_['intQ'].flatten(),\n    color='C1',\n    alpha=0.6,\n    edgecolor='none',\n    label='HMC',\n    density=True,\n)\n_ = ax.legend(loc='best', frameon=True, edgecolor='#666666')\n_ = ax.set_xlabel(r\"$Q$\", loc='center')\n_ = ax.set_title('Topological Charge ($Q$) Distribution', loc='center')\nfig, ax = plt.subplots()\n_ = plt.plot(metrics_['plaqs'][:, 0], color='C0', label='Diffusion')\n_ = plt.plot(metrics_hmc_['plaqs'][:, 0], color='C1', label='HMC')\n_ = ax.legend(loc='best', frameon=True, edgecolor='#666666', ncols=2)\n_ = ax.set_ylabel(r\"$\\left\\langle U_{\\mu\\nu}\\right\\rangle $\", loc='center')\n_ = ax.set_xlabel(f\"Draw\", loc='center')\nwloops = {\n    'hmc': [\n        exp.trainer.lattice.wilson_loops(i) for i in hmc_samples_\n    ],\n    'diffusion': [\n        exp.trainer.lattice.wilson_loops(i) for i in diffusion_samples_\n    ],\n}\n\nplaqs = {\n    'hmc': [\n        exp.trainer.lattice.plaqs(i) for i in hmc_samples_\n    ],\n    'diffusion': [\n        exp.trainer.lattice.plaqs(i) for i in diffusion_samples_\n    ],\n}\nwlhmc = torch.stack(wloops['hmc']).squeeze()\nwldiff = torch.stack(wloops['diffusion']).squeeze()\nwlhmc.shape\n\ntorch.Size([28, 16, 32, 32])\n_ = plt.tight_layout()\nfor idx in range(2):\n    fig, ax = plt.subplots(ncols=2)\n    _ = ax[0].imshow(wlhmc[idx, 0])\n    _ = ax[0].set_title(\"HMC\", loc='center')\n    _ = ax[1].imshow(wldiff[idx, 0])\n    _ = ax[1].set_title(\"Diffusion\", loc='center')\n    _ = fig.suptitle(r\"$U_{\\mu\\nu}$\", y=0.8)\n    for ax_ in ax:\n        _ = ax_.set_xticklabels([])\n        _ = ax_.set_yticklabels([])\n\n&lt;Figure size 640x480 with 0 Axes&gt;\nqhmc = metrics_hmc_['intQ']\nqdiff = metrics_diffusion_['intQ']\nqhmc.shape\n\ntorch.Size([28, 16])\nphmc = torch.stack(plaqs['hmc']).squeeze()\npdiff = torch.stack(plaqs['diffusion']).squeeze()\nphmc.shape\n\ntorch.Size([28, 16])\npdiff.shape\n\ntorch.Size([2, 16])\nfig, ax = plt.subplots()\n\n_ = ax.hist(\n    metrics_['plaqs'].flatten(),\n    color='C1',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='HMC',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_diffusion_['plaqs'].flatten(),\n    color='C0',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Diffusion',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_hmc_['plaqs'].flatten(),\n    color='C2',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Combined',\n    linewidth=1.5\n)\n_ = ax.set_xlabel(r\"$U_{\\mu\\nu}$\", loc='center')\n_ = ax.legend(\n    loc='upper left',\n    frameon=True,\n    #ncols=2,\n    bbox_to_anchor=(0.55, 1.00),\n    edgecolor=\"#838383\",\n)\n_ = ax.set_title('Plaquette Distribution', loc='center')\nfig, ax = plt.subplots()\n\n_ = ax.hist(\n    metrics_['intQ'].flatten(),\n    color='C1',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='HMC',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_diffusion_['intQ'].flatten(),\n    color='C0',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Diffusion',\n    linewidth=1.5\n)\n_ = ax.hist(\n    metrics_hmc_['intQ'].flatten(),\n    color='C2',\n    histtype='step',\n    stacked=True,\n    density=True,\n    label='Combined',\n    linewidth=1.5\n)\n_ = ax.set_xlabel('$Q_{\\mathbb{Z}}$', loc='center')\n_ = ax.legend(\n    loc='upper left',\n    frameon=True,\n    #ncols=2,\n    bbox_to_anchor=(0.55, 1.00),\n    edgecolor=\"#838383\",\n)\n_ = ax.set_title('Charge Distribution', loc='center')\nglobal_step = 0\nframes = []\nlosses = []\nprint(\"Training model...\")\nfor epoch in range(config[\"num_epochs\"]):\n    model.train()\n    progress_bar = tqdm(total=len(dataloader))\n    progress_bar.set_description(f\"Epoch {epoch}\")\n    for step, batch in enumerate(dataloader):\n        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n\n        noise = torch.randn(batch.shape)\n        timesteps = torch.randint(\n            0, noise_scheduler.num_timesteps, (batch.shape[0],)\n        ).long()\n\n        #noisy = noise_scheduler.add_noise(batch, noise, timesteps)\n        noisy = noise_scheduler.noise_images(batch, timesteps)\n        noise_pred = model(noisy, timesteps)\n        loss = F.mse_loss(noise_pred, noise)\n        loss.backward(loss)\n\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n\n        progress_bar.update(1)\n        logs = {\"loss\": loss.detach().item(), \"step\": global_step}\n        losses.append(loss.detach().item())\n        progress_bar.set_postfix(**logs)\n        global_step += 1\n    progress_bar.close()\n\n    if epoch % config[\"save_images_step\"] == 0 or epoch == config[\"num_epochs\"] - 1:\n        # generate data with the model to later visualize the learning process\n        model.eval()\n        sample = torch.randn(config[\"eval_batch_size\"], 2)\n        timesteps = list(range(len(noise_scheduler)))[::-1]\n        for i, t in enumerate(tqdm(timesteps)):\n            t = torch.from_numpy(np.repeat(t, config[\"eval_batch_size\"])).long()\n            with torch.no_grad():\n                residual = model(sample, t)\n            sample = noise_scheduler.step(residual, t[0], sample)\n        frames.append(sample.numpy())\ndataset[6]\nlen(dataloader)\neval_batch_size = 10\nnum_timesteps = 50\nplot_step = 5\nnoise_scheduler = ddpm.NoiseScheduler(num_timesteps=num_timesteps)\nsample = torch.randn(eval_batch_size, 2)\ntimesteps = list(range(num_timesteps))[::-1]\nsamples = []\nsteps = []\n\nretrains = 10\ndiffusion_prob = 0.3\nsamples_per_retrain = 100\neval_batch_size = 10\nt = torch.from_numpy(np.repeat(timesteps[0], eval_batch_size)).long()\nwith torch.no_grad():\n    residual = model(sample, t)\nsample_ = noise_scheduler.step(residual, t[0], sample)\nsample.shape\nresidual.shape\nsample_.shape\ndiffusion_samples = []\nhmc_samples = []\nbeta = 1.\nfor retrain_iter in range(retrains):\n    console.print(f'retrain_iter: {retrain_iter}')\n    ndiff_acc = 0\n    ndiff_proposed = 0\n    for idx in range(samples_per_retrain):\n        console.print(f'sample idx: {idx}')\n        rand = np.random.uniform()\n        if rand &lt; diffusion_prob:\n            ndiff_proposed += 1\n            rand_pick = randrange(len(dataloader))\n            #theta_prime = dataset[rand_pick]\n            t = torch.from_numpy(np.repeat(t, eval_batch_size)).long()\n            with torch.no_grad():\n                residual = model(sample, t)\n            sample_ = noise_scheduler.step(residual, t[0], sample)\n            ratio = (\n                log_likelihood_2dU1(sample_, 2)\n                / log_likelihood_2dU1(sample, 2)\n            )\n            a = min(1, ratio)\n            u = np.random.uniform()\n            if u &lt; a:\n                ndiff_acc += 1\n                sample = sample_\n                diffusion_samples.append(sample)\n        else:\n            sample_, metrics = exp.trainer.hmc_step((sample_, beta))\n            hmc_samples.append(sample)\nfor i, t in enumerate(tqdm(timesteps)):\n    t = torch.from_numpy(np.repeat(t, eval_batch_size)).long()\n    with torch.no_grad():\n        residual = model(sample, t)\n    sample = noise_scheduler.step(residual, t[0], sample)\n    if (i + 1) % plot_step == 0:\n        samples.append(sample.numpy())\n        steps.append(i + 1)\nAlternate\ndiffusion_ = DiffusionAlt(img_size=64, device='cpu')\nunet\nimage = torch.rand(1, 2, 64, 64)\nt = diffusion_.sample_timesteps(image.shape[0]).to('cpu')\nunet(image, t)\ndiffusion_.sample("
  },
  {
    "objectID": "qmd/diffusion-alt/diffusion.html#imports-setup",
    "href": "qmd/diffusion-alt/diffusion.html#imports-setup",
    "title": "Denoising Diffusion Probabilistic Models",
    "section": "Imports / Setup",
    "text": "Imports / Setup"
  },
  {
    "objectID": "qmd/diffusion-alt/diffusion.html#d-u1",
    "href": "qmd/diffusion-alt/diffusion.html#d-u1",
    "title": "Denoising Diffusion Probabilistic Models",
    "section": "2D U(1)",
    "text": "2D U(1)"
  },
  {
    "objectID": "qmd/diffusion-alt/diffusion.html#train-diffusion-model",
    "href": "qmd/diffusion-alt/diffusion.html#train-diffusion-model",
    "title": "Denoising Diffusion Probabilistic Models",
    "section": "Train Diffusion Model",
    "text": "Train Diffusion Model"
  },
  {
    "objectID": "qmd/diffusion-alt/diffusion.html#build-diffusion-model-with-unet-architecure",
    "href": "qmd/diffusion-alt/diffusion.html#build-diffusion-model-with-unet-architecure",
    "title": "Denoising Diffusion Probabilistic Models",
    "section": "Build Diffusion Model with UNet Architecure",
    "text": "Build Diffusion Model with UNet Architecure"
  },
  {
    "objectID": "qmd/diffusion-alt/diffusion.html#hmc-sampling-with-diffusion",
    "href": "qmd/diffusion-alt/diffusion.html#hmc-sampling-with-diffusion",
    "title": "Denoising Diffusion Probabilistic Models",
    "section": "HMC Sampling with Diffusion",
    "text": "HMC Sampling with Diffusion"
  },
  {
    "objectID": "qmd/diffusion-alt/diffusion.html#alternate",
    "href": "qmd/diffusion-alt/diffusion.html#alternate",
    "title": "Denoising Diffusion Probabilistic Models",
    "section": "Alternate",
    "text": "Alternate"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "l2hmc-qcd",
    "section": "",
    "text": "Contents\n\n\n\n\n\n\n\nOverview\n\nPapers üìö, Slides üìä, etc.\nBackground\n\nInstallation\nTraining\n\nConfiguration Management\nRunning @ ALCF\n\nDetails\n\nOrganization\n\nDynamics / Network\n\nNetwork Architecture"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA good way to do this is on top of a conda environment, e.g.:\nbash   conda activate base;  # with either {pytorch, tensorflow}   mkdir venv   python3 -m venv venv --system-site-packages   source venv/bin/activate   # for development addons:   # python3 -m pip install -e \".[dev]\"   python3 -m pip install -e .‚Ü©Ô∏é\nNote that throughout the code, we refer to the link variables as x and the conjugate momenta as v.‚Ü©Ô∏é\nreferred to as vNet for the network used to update v‚Ü©Ô∏é\nreferred to as xNet for the network used to update x‚Ü©Ô∏é"
  },
  {
    "objectID": "index.html#lattice-dynamics",
    "href": "index.html#lattice-dynamics",
    "title": "",
    "section": "Lattice Dynamics",
    "text": "Lattice Dynamics\n\n\n\nFigure¬†1: A 2D view of the lattice, with an elementary plaquette, U_{\\mu\\nu}(x) illustrated.\n\n\nGoal: Use L2HMC to efficiently generate gauge configurations for calculating observables in lattice QCD.\nA detailed description of the (ongoing) work to apply this algorithm to simulations in lattice QCD (specifically, a 2D U(1) lattice gauge theory model) can be found in arXiv:2105.03418.\nFor a given target distribution, \\pi(U) the Dynamics object (src/l2hmc/dynamics/) implements methods for generating proposal configurations\nU_{0} \\rightarrow U_{1} \\rightarrow \\cdots \\rightarrow U_{n} \\sim \\pi(U)\nusing the generalized leapfrog update, as shown to the right in Figure¬†2.\nThis generalized leapfrog update takes as input a buffer of lattice configurations U2 and generates a proposal configuration:\n\nU^{\\prime}= Dynamics(U)\n\nby evolving the generalized L2HMC dynamics."
  },
  {
    "objectID": "index.html#network-architecture",
    "href": "index.html#network-architecture",
    "title": "",
    "section": "Network Architecture",
    "text": "Network Architecture\nWe use networks with identical architectures, \\Gamma^{\\pm}3, \\Lambda^{\\pm}4 to update our momenta P and links U, respectively.\n\n\n\nFigure¬†2: An illustration of the leapfrog layer updating (P, U) \\rightarrow (P', U')."
  },
  {
    "objectID": "index.html#l2hmc",
    "href": "index.html#l2hmc",
    "title": "",
    "section": "L2HMC",
    "text": "L2HMC\nGoal: Use L2HMC to efficiently generate gauge configurations for calculating observables in lattice QCD.\nA detailed description of the (ongoing) work to apply this algorithm to simulations in lattice QCD (specifically, a 2D U(1) lattice gauge theory model) can be found in arXiv:2105.03418."
  },
  {
    "objectID": "index.html#configuring-your-experiment",
    "href": "index.html#configuring-your-experiment",
    "title": "",
    "section": "Configuring your Experiment",
    "text": "Configuring your Experiment\nThis project uses hydra for configuration management and supports distributed training for both PyTorch and TensorFlow.\nIn particular, we support the following combinations of framework + backend for distributed training:\n\nTensorFlow (+ Horovod for distributed training)\nPyTorch +\n\nDDP\nHorovod\nDeepSpeed\n\n\nThe main entry point is src/l2hmc/main.py, which contains the logic for running an end-to-end Experiment.\nAn Experiment consists of the following sub-tasks:\n\nTraining\nEvaluation\nHMC (for comparison and to measure model improvement)"
  },
  {
    "objectID": "index.html#running-an-experiment",
    "href": "index.html#running-an-experiment",
    "title": "",
    "section": "Running an Experiment",
    "text": "Running an Experiment\nAll configuration options can be dynamically overridden via the CLI at runtime, and we can specify our desired framework and backend combination via:\npython3 main.py mode=debug framework=pytorch backend=deepspeed precision=fp16\nto run a (non-distributed) Experiment with pytorch + deepspeed with fp16 precision.\nThe l2hmc/conf/config.yaml contains a brief explanation of each of the various parameter options, and values can be overriden either by modifying the config.yaml file, or directly through the command line, e.g.\ncd src/l2hmc\n./train.sh mode=debug framework=pytorch &gt; train.log 2&gt;&1 &\ntail -f train.log $(tail -1 logs/latest)\nAdditional information about various configuration options can be found in:\n\nsrc/l2hmc/configs.py: Contains implementations of the (concrete python objects) that are adjustable for our experiment.\nsrc/l2hmc/conf/config.yaml: Starting point with default configuration options for a generic Experiment.\n\nfor more information on how this works I encourage you to read Hydra‚Äôs Documentation Page.\n\nRunning at ALCF\nFor running with distributed training on ALCF systems, we provide a complete src/l2hmc/train.sh script which should run without issues on either Polaris or ThetaGPU @ ALCF.\n\nALCF:\n# Polaris --------------------------------\nif [[ \"$(hostname)==x3*\" ]]; then\n  MACHINE=\"Polaris\"\n  CONDA_DATE=\"2023-10-02\"\n# thetaGPU -------------------------------\nelif  [[ \"$(hostname)==thetagpu*\" ]]; then\n  MACHINE=\"thetaGPU\"\n  CONDA_DATE=\"2023-01-11\"\nelse\n  echo \"Unknown machine\"\n  exit 1\nfi\n# Setup conda + build virtual env -----------------------------------------\nmodule load \"conda/${CONDA_DATE}\"\nconda activate base\ngit clone https://github.com/saforem2/l2hmc-qcd\ncd l2hmc-qcd\nmkdir -p \"venvs/${MACHINE}/${CONDA_DATE}\"\npython3 -m venv \"venvs/${MACHINE}/${CONDA_DATE}\" --system-site-packages\nsource \"venvs/${MACHINE}/${CONDA_DATE}/bin/activate\"\npython3 -m pip install --upgrade pip setuptools wheel\n# Install `l2hmc` ----------\npython3 -m pip install -e .\n# Train ----------------------------------------------------------------------\ncd src/l2hmc\n./bin/train.sh mode=test framework=pytorch backend=deepspeed seed=\"${RANDOM}\""
  }
]