{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauge Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "### TODO:\n",
    "* [x] Generate multiple chain lengths and deal with loading in from multiple `samples_history` files.\n",
    "* [x] Implement the same logic for `observables` as for `samples_history`.\n",
    "* [x] Modify remainder of code below to deal with case where `samples` and `observables` are dictionaries with keys specifying the length of the MCMC chain.\n",
    "* [x] Re-run the cells below for the remainder of `HMC` directory to get ESS values for comparing against ESS from L2HMC.\n",
    "* [x] Try training sampler for >> 1000 steps and running the trained sampler for a variety of different chain lengths to see what the integrated autocorrelation time approaches as  $N_{steps} \\longrightarrow \\infty$.\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from scipy.stats import sem\n",
    "from mpl_toolkits.axes_grid.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "COLORS = 5 * ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9']\n",
    "MARKERS = 5 * ['o', 's', 'x', 'v', 'h', '^', 'p', '<', 'd', '>', 'P', 'D']\n",
    "LINESTYLES = ['-', '--', ':', '-.', '-', '--', ':', '-.', '-', '--']\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "######################## MATPLOTLIB SETTINGS ############################\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "#mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "#params = {\n",
    "#    'axes.titlesize': 14,\n",
    "#    'axes.labelsize': 12,\n",
    "#    #'font.size': 12,\n",
    "#    'legend.fontsize': 12,\n",
    "#    'xtick.labelsize': 12,\n",
    "#    'ytick.labelsize': 12,\n",
    "#    'text.usetex': False,\n",
    "#    'lines.linewidth': 2.0,\n",
    "#    #'figure.figsize': [6.4, 4.8] # instead of 4.5, 4.5\n",
    "#    'figure.figsize': [5.3333, 4.0] # instead of 4.5, 4.5\n",
    "#}\n",
    "#_ = mpl.rcParams.update(params)\n",
    "\n",
    "#plt.rcParams['text.latex.preamble'] = [r'\\usepackage{lmodern}']\n",
    "#plt.rc('text',usetex=True)\n",
    "\n",
    "#font = {'family':'serif','size':16}  # desired use\n",
    "# font = {'family':'serif','size':16, 'serif': ['computer modern roman']}  # what you need to do now \n",
    "# font = {'size':16} # desired use\n",
    "# font = {'size':16, 'sans-serif': ['computer modern sans-serif']} # what you need to do now \n",
    "\n",
    "#plt.rc('font',**font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "import utils.file_io as io\n",
    "from lattice.lattice import GaugeLattice, u1_plaq_exact\n",
    "from gauge_model import GaugeModel\n",
    "from utils.file_io import save_params_to_pkl_file\n",
    "from utils.plot_helper import plot_multiple_lines\n",
    "from utils.autocorr import *\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILE I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def check_else_make_dir(d):\n",
    "    if not os.path.isdir(d):\n",
    "        print(f\"Making directory: {d}\")\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers for locating and loading observables and run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_run_dirs(log_dir):\n",
    "    run_dir_root = os.path.join(log_dir, 'runs')\n",
    "    contents = os.listdir(run_dir_root)\n",
    "    runs_dirs = [\n",
    "        os.path.join(run_dir_root, i) for i in contents if 'steps' in i\n",
    "    ]\n",
    "    params = []\n",
    "    for d in runs_dirs:\n",
    "        d_arr = d.split('/')[-1].split('_')\n",
    "        params.append((int(d_arr[1]), d_arr[-1]))\n",
    "    return runs_dirs, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_chains(run_dir):\n",
    "    assert os.path.isdir(run_dir)\n",
    "    samples_file = os.path.join(run_dir, 'run_samples.pkl')\n",
    "    if os.path.isfile(samples_file):\n",
    "        with open(samples_file, 'rb') as f:\n",
    "            samples = pickle.load(f)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_run_data(run_dir):\n",
    "    assert os.path.isdir(run_dir)\n",
    "    run_data_file = os.path.join(run_dir, 'run_data.pkl')\n",
    "    print('Loading run_data from: {}'.format(run_data_file))\n",
    "    with open(run_data_file, 'rb') as f:\n",
    "        run_data = pickle.load(f)\n",
    "    return run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_observables_stats(run_dir):\n",
    "    assert os.path.isdir(run_dir)\n",
    "    obs_dir = os.path.join(run_dir, 'observables')\n",
    "    assert os.path.isdir(obs_dir)\n",
    "    _files = os.listdir(obs_dir)\n",
    "    obs_files = [i for i in _files if i.endswith('.pkl')]\n",
    "    observables = {}\n",
    "    stats = {}\n",
    "    for f in obs_files:\n",
    "        key = f.rstrip('.pkl')\n",
    "        in_file = os.path.join(obs_dir, f)\n",
    "        if 'stats' in f:\n",
    "            with open(in_file, 'rb') as f:\n",
    "                stats[key] = pickle.load(f)\n",
    "        else:\n",
    "            with open(in_file, 'rb') as f:\n",
    "                observables[key] = pickle.load(f)\n",
    "    return observables, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data helpers / autocorrelation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[result.size // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def arrs_from_dict(d):\n",
    "    assert isinstance(d, dict)\n",
    "    keys_arr = np.array(list(d.keys()))\n",
    "    vals_arr = np.array(list(d.values()))\n",
    "    return keys_arr, vals_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_observables(observables, hmc=False, out_dir=None, filetype='png'):\n",
    "    actions_arr, plaqs_arr, charges_arr = observables\n",
    "    steps_arr = np.arange(actions_arr.shape[0])\n",
    "    # Total actions plots\n",
    "    if not hmc:\n",
    "        title_str = (\n",
    "            f\"L2HMC: \"\n",
    "            r\"$\\beta = $\"\n",
    "            f\"{beta}\"#\", {run_steps} eval steps\"\n",
    "        )\n",
    "    else:\n",
    "        title_str = (\n",
    "            f\"HMC: \"\n",
    "            r\"$\\beta = $\"\n",
    "            f\"{beta}\"#\", {run_steps} train steps\"\n",
    "        )\n",
    "    kwargs = {\n",
    "        'out_file': None,\n",
    "        'markers': False,\n",
    "        'lines': True,\n",
    "        'alpha': 0.6,\n",
    "        'title': title_str,\n",
    "        'legend': False,\n",
    "        'ret': False,\n",
    "    }\n",
    "    if out_dir is not None:\n",
    "        kwargs['out_file'] = os.path.join(out_dir, \n",
    "                                          f'actions_vs_step.{filetype}')\n",
    "    plot_multiple_lines(steps_arr, actions_arr.T,  x_label='Step', \n",
    "                        y_label='Total action', **kwargs)\n",
    "    \n",
    "    # Average plaquettes plots\n",
    "    kwargs['ret'] = True\n",
    "    kwargs['out_file'] = None\n",
    "    _, ax = plot_multiple_lines(steps_arr, plaqs_arr.T, x_label='Step',\n",
    "                                y_label='Avg. plaquette', **kwargs)\n",
    "\n",
    "    _ = ax.axhline(y=u1_plaq_exact(beta),\n",
    "                   color='#CC0033', ls='-', lw=2.5, label='exact')\n",
    "\n",
    "    _ = ax.plot(steps_arr, plaqs_arr.T.mean(axis=0),\n",
    "                color='k', label='average', alpha=0.75)\n",
    "    if out_dir is not None:\n",
    "        out_file = os.path.join(out_dir, f'plaqs_vs_step.{filetype}')\n",
    "        print(f'Saving figure to: {out_file}.')\n",
    "        plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "        \n",
    "    # Topological charge plots\n",
    "    kwargs['markers'] = True\n",
    "    kwargs['lines'] = False\n",
    "    kwargs['alpha'] = 1.\n",
    "    kwargs['ret'] = False\n",
    "    if out_dir is not None:\n",
    "        out_file = os.path.join(out_dir, f'top_charge_vs_step.{filetype}')\n",
    "    plot_multiple_lines(steps_arr, charges_arr.T, x_label='Step',\n",
    "                        y_label='Topological charge', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     8,
     15,
     23,
     47,
     59
    ]
   },
   "outputs": [],
   "source": [
    "def plot_charge_probs(charges_arr, beta, params, out_dir=None, training=False,\n",
    "                      hmc=False):\n",
    "    if not hmc:\n",
    "        title_str = (\n",
    "            f\"L2HMC: \"\n",
    "            r\"$\\beta = $\"\n",
    "            f\"{beta}, {run_steps} eval steps\"\n",
    "        )\n",
    "    else:\n",
    "        title_str = (\n",
    "            f\"HMC: \"\n",
    "            r\"$\\beta = $\"\n",
    "            f\"{beta}, {run_steps} train steps\"\n",
    "        )\n",
    "        \n",
    "    if out_dir is not None:\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    num_samples = params['num_samples']\n",
    "    charges = np.array(charges_arr, dtype=int)\n",
    "    _run_steps = charges.shape[0]\n",
    "\n",
    "    # if we have more than 5 samples per batch, only plot first 5\n",
    "    for idx in range(5):\n",
    "        counts = Counter(charges[:, idx])\n",
    "        total_counts = np.sum(list(counts.values()))\n",
    "        _, ax = plt.subplots()\n",
    "        ax.plot(list(counts.keys()),\n",
    "                np.array(list(counts.values()) / total_counts),\n",
    "                marker=MARKERS[idx],\n",
    "                color=COLORS[idx],\n",
    "                ls='',\n",
    "                label=f'sample {idx}')\n",
    "        _ = ax.legend(loc='best')\n",
    "        _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "        _ = ax.set_ylabel('Probability', fontsize=14)\n",
    "        _ = ax.set_title(title_str, fontsize=16)\n",
    "        if out_dir is not None:\n",
    "            out_file = os.path.join(out_dir,\n",
    "                                    f'top_charge_prob_vs_val_{idx}.png')\n",
    "            io.log(f'Saving figure to: {out_file}.')\n",
    "            _ = plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "        #plt.close('all')\n",
    "\n",
    "    all_counts = Counter(list(charges.flatten()))\n",
    "    total_counts = np.sum(list(counts.values()))\n",
    "    _, ax = plt.subplots()\n",
    "    ax.plot(list(all_counts.keys()),\n",
    "            np.array(list(all_counts.values()) / (total_counts * num_samples)),\n",
    "            marker='o',\n",
    "            color='C0',\n",
    "            ls='',\n",
    "            alpha=0.6,\n",
    "            label=f\"total across {num_samples} samples\");\n",
    "    _ = ax.legend(loc='best')\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Probability', fontsize=14)\n",
    "    _ = ax.set_title(title_str, fontsize=16)\n",
    "    if out_dir is not None:\n",
    "        out_file = os.path.join(out_dir,\n",
    "                                f'TOP_CHARGE_FREQUENCY_VS_VAL_TOTAL.png')\n",
    "        io.log(f'Saving figure to: {out_file}.')\n",
    "        _ = plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     8,
     13,
     19,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def plot_top_charges(top_charges, beta, out_dir=None, hmc=False,\n",
    "                     filetype='png'):\n",
    "    \"\"\"Plot top. charge history vs. step for individual samples.\"\"\"\n",
    "    if out_dir is not None:\n",
    "        out_dir = os.path.join(out_dir, 'top_charge_plots')\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "            \n",
    "    if not isinstance(top_charges, np.ndarray):\n",
    "        top_charges = np.array(top_charges)\n",
    "            \n",
    "    run_steps = top_charges.shape[0]\n",
    "    num_samples = top_charges.shape[1]\n",
    "    if not hmc:\n",
    "        title_str = (\n",
    "            f\"L2HMC: \"\n",
    "            r\"$\\beta = $\"\n",
    "            f\"{beta}, {run_steps} eval steps\"\n",
    "        )\n",
    "    else:\n",
    "        title_str = (\n",
    "            f\"HMC: \"\n",
    "            r\"$\\beta = $\"\n",
    "            f\"{beta}, {run_steps} train steps\"\n",
    "        )\n",
    "    for idx in range(min(num_samples, 10)):\n",
    "        _, ax = plt.subplots()\n",
    "        _ = ax.plot(top_charges[:, idx],\n",
    "                    marker=MARKERS[idx],\n",
    "                    color=COLORS[idx],\n",
    "                    ls='',\n",
    "                    alpha=0.6,\n",
    "                    label=f'sample {idx}')\n",
    "        _ = ax.legend(loc='best')\n",
    "        _ = ax.set_xlabel('Step', fontsize=14)\n",
    "        _ = ax.set_ylabel('Topological charge', fontsize=14)\n",
    "        _ = ax.set_title(title_str, fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        if out_dir is not None:\n",
    "            out_file = os.path.join(out_dir, \n",
    "                                    f'top_charge_vs_step_{idx}.{filetype}')\n",
    "            print(f\"Saving figure to {out_file}.\")\n",
    "            plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_suscept(suscept_dict, fig_ax_pair=None, x_inset=5., **kwargs):\n",
    "    if fig_ax_pair is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig, ax = fig_ax_pair\n",
    "    #else:\n",
    "    #    if len(fig_ax_pair) == 2:\n",
    "    #        fig, ax = fig_ax_pair\n",
    "        #elif len(fig_ax_pair) == 3:\n",
    "        #    fig, ax, axins = fig_ax_pair\n",
    "        \n",
    "    for idx, (key, val) in enumerate(suscept_dict.items()):\n",
    "        beta = key\n",
    "        suscept, err = val\n",
    "        if idx == 0:\n",
    "            _ = ax.errorbar(beta, suscept, yerr=factor*err, **kwargs)\n",
    "            #_ = ax.plot(beta, suscept, **plt_kwargs)\n",
    "        else:\n",
    "            kwargs['label'] = ''\n",
    "            _ = ax.errorbar(beta, suscept, yerr=factor*err, **kwargs)\n",
    "            #_ = ax.plot(beta, suscept, **plt_kwargs)\n",
    "    #if axins is None:\n",
    "    #    axins = inset_axes(ax, width=\"30%\", height=\"40%\", loc=1, borderpad=1.5)\n",
    "        \n",
    "    #suscept5, err5 = suscept_dict[5.0]\n",
    "    #_ = axins.errorbar(x_inset, suscept5, yerr=factor*err5, **kwargs)\n",
    "\n",
    "    #x1, x2, y1, y2 = 4.97, 5.03, 0.005, 0.0065\n",
    "    #_ = axins.set_xlim(x1, x2)\n",
    "    #_ = axins.set_ylim(y1, y2)\n",
    "    return fig, ax #, axins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_individual_observables(figs_dir, observables, top_charges_autocorr):\n",
    "    multiple_lines_figs_axes = make_multiple_lines_plots(\n",
    "        figs_dir,\n",
    "        params['beta_final'],\n",
    "        observables,\n",
    "        top_charges_autocorr,\n",
    "        legend=False\n",
    "    )\n",
    "    return multiple_lines_figs_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_individual_acf_iat(acf_arr, iat_arr, ess_arr, figs_dir):\n",
    "    out_file = os.path.join(\n",
    "        figs_dir, \n",
    "        'integrated_autocorrelation_time_plot.pdf'\n",
    "    )\n",
    "    kwargs = {\n",
    "        'x_label': 'Lag',\n",
    "        'y_label': 'Autocorrelation (top. charge)',\n",
    "        'legend': True,\n",
    "        'out_file': out_file\n",
    "    }\n",
    "    fig, ax = plot_autocorr_with_iat(acf_arr, iat_arr, ess_arr, **kwargs)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observables analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define unique `log_dir` from which to load observables from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `DataLoader` Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "\n",
    "def _list_and_join(d):\n",
    "    contents = [os.path.join(d, i) for i in os.listdir(d)]\n",
    "    paths = [i for i in contents if os.path.isdir(i)]\n",
    "    \n",
    "    return paths\n",
    "    \n",
    "\n",
    "def list_and_join(d):\n",
    "    if isinstance(d, (list, np.ndarray)):\n",
    "        paths = []\n",
    "        for dd in d:\n",
    "            _path = _list_and_join(dd)[0]\n",
    "            paths.append(_path)\n",
    "    else:\n",
    "        paths = _list_and_join(d)\n",
    "        \n",
    "    return paths\n",
    "\n",
    "def get_eps_from_run_history_txt_file(txt_file):\n",
    "    with open(txt_file, 'r') as f:\n",
    "        data_line = [f.readline() for _ in range(10)][-1]\n",
    "    eps = float([i for i in data_line.split(' ') if i != ''][3])\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_log_dir = '../../logs/2019_5_1/'\n",
    "#rld = '../../logs/charge_weight_test/cooley_logs/may1_2019/lattice8/leapfrog5'\n",
    "#rld = '../../logs/charge_weight_test/cooley_logs/2019_5_2/'\n",
    "rld = '../../logs/charge_weight_test/cooley_logs/2019_5_5/leapfrog8'\n",
    "root_log_dir = os.path.join(*rld.split('/'))\n",
    "#time_dirs = list_and_join(root_log_dir)\n",
    "model_dirs = list_and_join(root_log_dir)\n",
    "log_dirs = list_and_join(model_dirs)\n",
    "#log_dirs = list_and_join(list_and_join(root_log_dir))\n",
    "#log_dirs = list_and_join(model_dirs)\n",
    "runs_dirs = [os.path.join(d, 'runs') for d in log_dirs if 'lattice' in d]\n",
    "# run_dirs is a list of lists, where each entry in run_dirs is a list\n",
    "# of all the run directories for that individual log_dir.\n",
    "# e.g. log_dirs = ['root_log_dir/log_dir1/run_1/',\n",
    "#                  'root_log_dir/log_dir2/run_1/', ...]\n",
    "# then:\n",
    "#     runs_dirs = ['root_log_dir/log_dir1/run_1/runs/',\n",
    "#                  'root_log_dir/log_dir2/run_1/runs/', ...]\n",
    "# then \n",
    "#     run_dirs = [\n",
    "#         ['root_log_dir/log_dir1/run_1/runs/steps100_beta2.0_eps0.1`,\n",
    "#          'root_log_dir/log_dir1/run_1/runs/steps100_beta3.0_eps0.1`, ...],\n",
    "#         ['root_log_dir/log_dir2/run_1/runs/steps100_beta2.0_eps0.1`,\n",
    "#          'root_log_dir/log_dir2/run_1/runs/steps100_beta3.0_eps0.1`, ...],\n",
    "#         ...\n",
    "#     ]\n",
    "run_dirs = [list_and_join(d) for d in runs_dirs]\n",
    "run_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader()\n",
    "runs_info = {}\n",
    "\n",
    "for i in run_dirs:\n",
    "    parent_dir = os.path.dirname(i[0])\n",
    "    print(f'Loading run_data from parent dir: {parent_dir}')\n",
    "    key = parent_dir.split('/')[-3]\n",
    "    existing = key in list(runs_info.keys())\n",
    "    if key in list(runs_info.keys()):\n",
    "        key += '_1'\n",
    "        if key in list(runs_info.keys()):\n",
    "            num = int(key[-1]) + int(1)\n",
    "            key = key.rstrip(str(num - 1)) + str(num)\n",
    "    runs_info[key] = {}\n",
    "    print(f'  key: {key}')\n",
    "    log_dir = os.path.dirname(parent_dir)\n",
    "    runs_info[key]['log_dir'] = log_dir\n",
    "    runs_info[key]['runs_data'] = {}\n",
    "    for p in i:\n",
    "        print(f'Loading run_data from: {p}')\n",
    "        rh_txt_file = os.path.join(p, 'run_history.txt')\n",
    "        if os.path.isfile(rh_txt_file):\n",
    "            eps = get_eps_from_run_history_txt_file(rh_txt_file)\n",
    "            params = data_loader.load_params(p)\n",
    "            params['eps'] = eps\n",
    "            run_data = data_loader.load_run_data(p)\n",
    "            p_split = p.split('_')\n",
    "            beta = float(p_split[-3])\n",
    "            runs_info[key]['eps'] = eps\n",
    "            runs_info[key]['runs_data'][beta] = {\n",
    "                'params': params,\n",
    "                'run_data': run_data,\n",
    "                'run_dir': p,\n",
    "                'eps': eps\n",
    "            }\n",
    "    print('  done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrs = {}\n",
    "for k1, v1 in runs_info.items():\n",
    "    print(f'k1: {k1}')\n",
    "    data = v1['runs_data']\n",
    "    #charges[k1] = {}\n",
    "    run_type = 'HMC' if 'HMC' in k1 else 'L2HMC'\n",
    "    #autocorrs[k1] = {}\n",
    "    #charges[k1]['log_dir'] = v1['log_dir']\n",
    "    for k2, v2 in data.items():\n",
    "        beta = str(k2)\n",
    "        eps = str(v2['eps'])\n",
    "        #if run_type == 'L2HMC':\n",
    "        charge_weight = str(v2['params']['charge_weight'])\n",
    "        #else:\n",
    "        #    charge_weight = 0.\n",
    "        num_steps = str(v2['params']['num_steps'])\n",
    "        num_samples = str(v2['params']['num_samples'])\n",
    "        size = str(v2['params']['space_size'])\n",
    "        key = (run_type, size, num_samples,\n",
    "               num_steps, eps, beta, charge_weight)\n",
    "        print(f'  key: {key}')\n",
    "        try:\n",
    "            autocorrs[key].append(\n",
    "                np.array(v2['run_data']['charges_autocorrs'])\n",
    "            )\n",
    "        except:\n",
    "            autocorrs[key] =  np.array(v2['run_data']['charges_autocorrs'])\n",
    "        #charges = np.array(list(v2['run_data']['charges'].values()))\n",
    "        #charges[k1][k2] = np.array(list(v2['run_data']['charges'].values()))\n",
    "        #charges = np.array(list(v2['run_data']['charges'].values()))\n",
    "        #autocorrs[k1][k2] = np.array([autocorr(i) for i in charges.T])\n",
    "        #try:\n",
    "        #    autocorrs[key].append(np.array([autocorr(i) for i in charges.T]))\n",
    "        #except:\n",
    "        #    autocorrs[key] = np.array([autocorr(i) for i in charges.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_arr = np.array(list(autocorrs.keys()))\n",
    "\n",
    "keys_arr = np.array(list(autocorrs.keys()))\n",
    "rt_unique = np.unique(keys_arr[:, 0])\n",
    "lx_unique = np.unique(keys_arr[:, 1])\n",
    "ns_unique = np.unique(keys_arr[:, 2])\n",
    "lf_unique = np.unique(keys_arr[:, 3])\n",
    "eps_unique = np.unique(keys_arr[:, 4])\n",
    "betas_unique = np.unique(keys_arr[:, 5])\n",
    "qw_unique = np.unique(keys_arr[:, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mpl.rcdefaults()\n",
    "\n",
    "LX = lx_unique[0]\n",
    "LF = lf_unique[0]\n",
    "BS = ns_unique[0]  # batch size = num samples\n",
    "for beta in betas_unique:\n",
    "    n = 0\n",
    "    fig, ax = plt.subplots()\n",
    "    for rt in rt_unique:\n",
    "        for qw in qw_unique:\n",
    "            for eps in eps_unique:\n",
    "                key = (rt, lx_unique[0], ns_unique[0],\n",
    "                       lf_unique[0], eps, beta, qw)\n",
    "                if key in autocorrs.keys():\n",
    "                    if rt == 'HMC':\n",
    "                        ls = ':'\n",
    "                        _qw = 'N/A'\n",
    "                    else:\n",
    "                        ls = '-'\n",
    "                        _qw = qw\n",
    "                    acorrs = np.array(autocorrs[key])\n",
    "                    if len(acorrs.shape) > 2:\n",
    "                        acorr = np.mean(np.mean(acorrs, axis=1), axis=0)\n",
    "                    else:\n",
    "                        acorr = np.mean(acorrs, axis=0)\n",
    "                    label = ('{:<4}'.format(r'$\\alpha_{\\mathrm{Q}}=$') \n",
    "                             + f'{_qw:<3}, ' \n",
    "                             + '{:>4}'.format(r'$\\varepsilon=$') \n",
    "                             + f'{float(eps):<.4g}, ' + f'{rt:>5}')\n",
    "                    _ = ax.plot(acorr / np.max(acorr), label=label, ls=ls,\n",
    "                                alpha = 1. - (n / 10.))\n",
    "                    title = (f'{LX} x {LX}; ' \n",
    "                             + r'$N_{\\mathrm{LF}} = $ ' + f'{LF}; '\n",
    "                             + r'$\\beta = $ ' + f'{beta}')\n",
    "    #_ = ax.set_xticklabels = np.array([\n",
    "    #    LF * np.array(ax.get_xticklabels(), dtype='float')\n",
    "    #], dtype='str')\n",
    "    n += 1\n",
    "    _ = ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "    _ = ax.set_xlabel('lag', fontsize=14)\n",
    "    _ = ax.set_title(title, fontsize=16)\n",
    "    _ = ax.legend(loc='best', fontsize=11)\n",
    "    _ = ax.set_xlim((-50, 10050))\n",
    "    #if float(beta) == 4.0:\n",
    "    #    _ = ax.set_xlim((-10, 250))\n",
    "    #if float(beta) == 6.0:\n",
    "    #    _ = ax.set_xlim((-50, 1.5e4))\n",
    "    #if float(beta) == 5.0:\n",
    "    #    _ = ax.set_xlim((-50, 0.5e4))\n",
    "    figs_dir = os.path.join(root_log_dir, 'autocorrelation_plots')\n",
    "    eps_dir = os.path.join(figs_dir, 'eps_plots')\n",
    "    io.check_else_make_dir(figs_dir)\n",
    "    io.check_else_make_dir(eps_dir)\n",
    "    out_file = os.path.join(\n",
    "        figs_dir, f'top_charge_autocorr_vs_md_step_beta{beta}_zoomed.png'\n",
    "    )\n",
    "    out_file1 = os.path.join(\n",
    "        eps_dir, f'top_charge_autocorr_vs_md_step_beta{beta}_zoomed.eps'\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    #print(f'Saving figure to: {out_file}.')\n",
    "    #plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    #print(f'Saving figure to: {out_file1}.')\n",
    "    #plt.savefig(out_file1, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrs = {}\n",
    "for k1, v1 in charges.items():\n",
    "    print(f'k1: {k1}')\n",
    "    autocorrs[k1] = {}\n",
    "    autocorrs[k1]['log_dir'] = v1['log_dir']\n",
    "    for k2, v2 in v1.items():\n",
    "        if k2 == 'log_dir':\n",
    "            continue\n",
    "        print(f'  k2: {k2}')\n",
    "        autocorr_arr = np.array([autocorr(i) for i in v2.T])\n",
    "        autocorrs[k1][k2] = np.array([autocorr(i) for i in v2.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "xx = 0\n",
    "for k1, v1 in autocorrs.items():\n",
    "    tmp = runs_info[k1]['runs_data']\n",
    "    print(f'({x}) k1:')\n",
    "    for k2, v2 in v1.items():\n",
    "        if k2 == 'log_dir':\n",
    "            continue\n",
    "        run_dir = tmp[k2]['run_dir']\n",
    "        autocorr_file = os.path.join(run_dir, 'charge_autocorrs.pkl')\n",
    "        print(f'  ({xx}) Saving charge autocorrelations to: {autocorr_file}.')\n",
    "        with open(autocorr_file, 'wb') as f:\n",
    "            pickle.dump(v2, f)\n",
    "        print('    done.')\n",
    "        xx += 1\n",
    "    x += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.gauge_model_plotter import GaugeModelPlotter\n",
    "plotter = GaugeModelPlotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_autocorrs_by_charge_weight = {}\n",
    "hmc_autocorrs = {}\n",
    "beta_qw_eps = []\n",
    "for k1, v1 in autocorrs.items():\n",
    "    tmp = runs_info[k1]['runs_data']\n",
    "    for k2, v2 in v1.items():\n",
    "        if k2 == 'log_dir':\n",
    "            continue\n",
    "        BETA = k2\n",
    "        params = tmp[k2]['params']\n",
    "        EPS = tmp[k2]['run_data']['eps']\n",
    "        QW = params['charge_weight']\n",
    "        LX = params['space_size']\n",
    "        LF = params['num_steps']\n",
    "        #EPS = float(f\"{params['eps']:.3g}\")\n",
    "        beta_qw_eps.append((BETA, QW, EPS))\n",
    "        if 'HMC' not in k1:\n",
    "            print('L2HMC:')\n",
    "            key = (LX, LF, EPS, BETA, QW)\n",
    "            try:\n",
    "                l2hmc_autocorrs_by_charge_weight[key].append(v2)\n",
    "            except:\n",
    "                l2hmc_autocorrs_by_charge_weight[key] = [v2]\n",
    "                \n",
    "        else:\n",
    "            print('HMC:')\n",
    "            key = (LX, LF, EPS, BETA)\n",
    "            try:\n",
    "                hmc_autocorrs[key].append(v2)\n",
    "            except:\n",
    "                hmc_autocorrs[key] = [v2]\n",
    "        print(f'  k1: {k1}')\n",
    "        print(f'    k2: {k2}')\n",
    "        print(f'      key: {key}')\n",
    "        print(80*'-' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(l2hmc_autocorrs_by_charge_weight.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_autocorrs = {\n",
    "    4.0: []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_autocorrs_by_charge_weight[(4, 4, 0.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LX\n",
    "for key, val in l2hmc_autocorrs_by_charge_weight.items():\n",
    "    LX, LF, EPS, BETA, QW = key\n",
    "    l2hmc_autocorrs[BETA] =\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1, v1 in autocorrs.items():\n",
    "    tmp = runs_info[k1]['runs_data']\n",
    "    fig, ax = plt.subplots()\n",
    "    for k2, v2 in v1.items():\n",
    "        if k2 == 'log_dir':\n",
    "            continue\n",
    "        params = tmp[k2]['params']\n",
    "        LX = params['space_size']\n",
    "        LF = params['num_steps']\n",
    "        EPS = params['eps']\n",
    "        QW = params['charge_weight']\n",
    "        title = (f'{LX} x {LX}; ' + r'$N_{\\mathrm{LF}} = $ ' + f'{LF}; '\n",
    "                 + r'$\\varepsilon = $ ' + f'{EPS:.3g}; '\n",
    "                 + r'$\\alpha_{\\mathrm{Q}} = $ ' + f'{QW}')\n",
    "        if 'HMC' in k1:\n",
    "            title = 'HMC ' + title\n",
    "        autocorr = np.mean(v2, axis=0)\n",
    "        _ = ax.plot(autocorr, label=r\"$\\beta = $ \" + f\"{k2}\")\n",
    "    _ = ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "    _ = ax.set_xlabel('lag', fontsize=14)\n",
    "    _ = ax.set_title(title, fontsize=16)\n",
    "    _ = ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrs[key0][5.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr0 = autocorrs[key0][5.0]\n",
    "steps = np.arange(autocorr0.shape[1])\n",
    "autocorr0.shape; steps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrs0 = autocorrs[key0]\n",
    "fig, ax = plt.subplots()\n",
    "for key, val in autocorrs0.items():\n",
    "    if key == 'log_dir':\n",
    "        continue\n",
    "    autocorr = np.mean(val, axis=0)\n",
    "    ax.plot(autocorr, label=r\"$\\beta = $\" + f\"{key}\")\n",
    "    \n",
    "ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "ax.set_xlabel('lag', fontsize=14)\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.ticklabel_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plotter._plot_autocorrs((steps, autocorr0), ret=True)\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_params_from_dir(dir_str):\n",
    "    split_str = dir_str.split('_')  # split_str is a list !!\n",
    "    params = {}\n",
    "    if split_str[0] == 'HMC':\n",
    "        split_str = split_str[1:]\n",
    "    params = {\n",
    "        'lattice_size': int(split_str[0].lstrip('lattice')),\n",
    "        'num_samples': int(split_str[1].lstrip('batch')),\n",
    "        'num_steps': int(split_str[2].lstrip('lf')),\n",
    "        'eps': float(split_str[3].lstrip('eps')),\n",
    "    }\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_log_dir = os.path.join('..', '..', 'logs')\n",
    "search_str = '2019_4_30_'\n",
    "root_log_dirs = [\n",
    "    os.path.join(root_log_dir, i, os.listdir(os.path.join(root_log_dir, i))[0])\n",
    "    for i in os.listdir(root_log_dir) if search_str in i\n",
    "]\n",
    "model_params = [model_params_from_dir(i.split('/')[-1]) for i in root_log_dirs]\n",
    "\n",
    "log_dirs = [os.path.join(i, os.listdir(i)[0]) for i in root_log_dirs]\n",
    "log_params; log_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params_from_run_dir(run_dir):\n",
    "    params_file = os.path.join(run_dir, 'parameters.pkl')\n",
    "    with open(params_file, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir_dict = {}\n",
    "for params, log_dir in zip(model_params, log_dirs):\n",
    "    runs_dir = os.path.join(log_dir, 'runs')\n",
    "    run_dirs = []\n",
    "    run_params = []\n",
    "    for d in os.listdir(runs_dir):\n",
    "        run_dirs.append(os.path.join(runs_dir, d))\n",
    "        run_params.append(load_params_from_run_dir(os.path.join(runs_dir, d)))\n",
    "    #run_dirs = [\n",
    "    #    os.path.join(runs_dir, i) for i in os.listdir(runs_dir)\n",
    "    #]\n",
    "    #run_params = [\n",
    "    #    load_params_from_run_dir(run_dir) for run_dir in run_dirs\n",
    "    #]\n",
    "    log_dir_dict[log_dir] = {\n",
    "        'model_params': params,\n",
    "        'run_dirs': run_dirs,\n",
    "        'run_params': run_params\n",
    "    }\n",
    "list(log_dir_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_str = ('../../logs/cooley_logs/april_2019/2019_04_24/'\n",
    "#           'lattice16_steps5_batch128_beta25_qweight0/run_1/')\n",
    "dir_str = ('../../logs/cooley_logs/2019_4_30/lattice8')\n",
    "dir_str_hmc = dir_str + 'HMC/run_1/'\n",
    "log_dir = os.path.join(*dir_str.split('/'))\n",
    "log_dir_hmc = os.path.join(*dir_str_hmc.split('/'))\n",
    "params_strs = dir_str.split('/')[5].split('_')\n",
    "assert os.path.isdir(log_dir)\n",
    "assert os.path.isdir(log_dir_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dirs, run_params = get_run_dirs(log_dir)\n",
    "run_dirs_hmc, run_params_hmc = get_run_dirs(log_dir_hmc)\n",
    "\n",
    "run_dirs\n",
    "run_dirs_hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_str_hmc1 = '../../logs/2019_4_26/HMC_lattice16_batch128_lf5_eps1/run_1/'\n",
    "log_dir_hmc1 = os.path.join(*dir_str_hmc1.split('/'))\n",
    "\n",
    "dir_str_hmc2 = '../../logs/2019_4_26/HMC_lattice16_batch128_lf5_eps2/run_1/'\n",
    "log_dir_hmc2 = os.path.join(*dir_str_hmc2.split('/'))\n",
    "\n",
    "dir_str_hmc3 = '../../logs/2019_4_26/HMC_lattice16_batch128_lf5_eps35/run_1/'\n",
    "log_dir_hmc3 = os.path.join(*dir_str_hmc3.split('/'))\n",
    "\n",
    "#dir_str_hmc3 = '../../logs/2019_4_26/HMC_lattice16_batch128_lf3_eps1/run_1/'\n",
    "#log_dir_hmc3 = os.path.join(*dir_str_hmc3.split('/'))\n",
    "\n",
    "run_dirs_hmc1, run_params_hmc1 = get_run_dirs(log_dir_hmc1)\n",
    "run_dirs_hmc2, run_params_hmc2 = get_run_dirs(log_dir_hmc2)\n",
    "run_dirs_hmc3, run_params_hmc3 = get_run_dirs(log_dir_hmc3)\n",
    "\n",
    "run_dirs_hmc1; run_dirs_hmc2; run_dirs_hmc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_lf_eps_hmc(dir_str):\n",
    "    lf_hmc = int(\n",
    "        dir_str.split('/')[-3].split('_')[-2].lstrip('lf')\n",
    "    ) \n",
    "    eps_hmc = float(\n",
    "        '0.' + dir_str.split('/')[-3].split('_')[-1].lstrip('eps')\n",
    "    )\n",
    "    \n",
    "    return lf_hmc, eps_hmc\n",
    "\n",
    "lf_hmc1, eps_hmc1 = get_lf_eps_hmc(dir_str_hmc1)\n",
    "lf_hmc2, eps_hmc2 = get_lf_eps_hmc(dir_str_hmc2)\n",
    "lf_hmc3, eps_hmc3 = get_lf_eps_hmc(dir_str_hmc3)\n",
    "\n",
    "lf_hmc1, eps_hmc1; lf_hmc2, eps_hmc2; lf_hmc3, eps_hmc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over all directories in `run_dirs` and `run_dirs_hmc`, and append the topological charge autocorrelations to `charges_autocorrs` and `charges_autocorrs_hmc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charges_autocorrs_from_run_dirs(run_dirs, run_params):\n",
    "    charges_autocorrs_dict = {}\n",
    "    for d, p in zip(run_dirs, run_params):\n",
    "        assert os.path.isdir(d)\n",
    "        obs_dir = os.path.join(d, 'observables')\n",
    "        charges_file = os.path.join(obs_dir, 'charges.pkl')\n",
    "        print(\"Loading charges from: {}\".format(charges_file))\n",
    "        with open(charges_file, 'rb') as f:\n",
    "            charges = pickle.load(f)\n",
    "        _, charges_arr = arrs_from_dict(charges)\n",
    "        charge_autocorrs = np.array([autocorr(i) for i in charges_arr.T])\n",
    "        charges_autocorrs_dict[params['beta']] = charge_autocorrs\n",
    "    return charges_autocorrs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir_dict[list(log_dir_dict.keys())[0]]['run_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_autocorrs_dict = {}\n",
    "for key, val in log_dir_dict.items():\n",
    "    run_dirs = val['run_dirs']\n",
    "    run_params = val['run_params']\n",
    "    charges_autocorrs_dict[key] = {\n",
    "        'run_dirs': run_dirs,\n",
    "        'run_params': run_params,\n",
    "        'charges_autocorrs': charges_autocorrs_from_run_dirs(run_dirs,\n",
    "                                                             run_params),\n",
    "        'model_params': val['model_params'],\n",
    "    }\n",
    "list(charges_autocorrs_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_autocorrs_dict = charges_autocorrs_from_run_dirs(run_dirs)\n",
    "charges_autocorrs_dict_hmc = charges_autocorrs_from_run_dirs(run_dirs_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_autocorrs_dict_hmc1 = charges_autocorrs_from_run_dirs(run_dirs_hmc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_autocorrs_dict_hmc2 = charges_autocorrs_from_run_dirs(run_dirs_hmc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_autocorrs_dict_hmc3 = charges_autocorrs_from_run_dirs(run_dirs_hmc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Topological Charge $Q$ Autocorrelations (L2HMC, HMC) for multiple values of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_l2hmc = 0.2776\n",
    "eps_hmc = 0.2776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acorr_avg_max(acorr_dict, beta):\n",
    "    acorr = acorr_dict[beta]\n",
    "    acorr_avg = acorr.mean(axis=0)\n",
    "    acorr_max = acorr_avg.max()\n",
    "    return acorr, acorr_avg, acorr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "out_dir = os.path.join(figs_dir, 'top_charge_autocorrelations')\n",
    "eps_dir = os.path.join(out_dir, 'eps')\n",
    "_ = [os.makedirs(d) for d in (out_dir, eps_dir) if not os.path.isdir(d)]\n",
    "   \n",
    "for idx, beta in enumerate(charges_autocorrs_dict.keys()):\n",
    "    fig, ax = plt.subplots()\n",
    "    l2hmc = get_acorr_avg_max(charges_autocorrs_dict, beta)\n",
    "    acorr_l2hmc, acorr_avg_l2hmc, acorr_max_l2hmc = l2hmc\n",
    "    \n",
    "    hmc0 = get_acorr_avg_max(charges_autocorrs_dict_hmc, beta)\n",
    "    acorr_hmc, acorr_avg_hmc, acorr_max_hmc = hmc0\n",
    "    \n",
    "    hmc1 = get_acorr_avg_max(charges_autocorrs_dict_hmc1, beta)\n",
    "    acorr_hmc1, acorr_avg_hmc1, acorr_max_hmc1 = hmc1\n",
    "    \n",
    "    hmc2 = get_acorr_avg_max(charges_autocorrs_dict_hmc2, beta)\n",
    "    acorr_hmc2, acorr_avg_hmc2, acorr_max_hmc2 = hmc2\n",
    "    \n",
    "    hmc3 = get_acorr_avg_max(charges_autocorrs_dict_hmc3, beta)\n",
    "    acorr_hmc3, acorr_avg_hmc3, acorr_max_hmc3 = hmc3\n",
    "    \n",
    "    label_l2hmc = ('L2HMC ' + r\"$\\varepsilon = $\" + f' {eps_l2hmc}')\n",
    "    label_hmc0 = ('HMC     ' + r\"$\\varepsilon = $\" + f' {eps_hmc}')\n",
    "    label_hmc1 = ('HMC     ' + r\"$\\varepsilon = $\" + f' {eps_hmc1}')\n",
    "    label_hmc2 = ('HMC     ' + r\"$\\varepsilon = $\" + f' {eps_hmc2}')\n",
    "    label_hmc3 = ('HMC     ' + r\"$\\varepsilon = $\" + f' {eps_hmc3}')\n",
    "\n",
    "    _ = ax.plot(acorr_avg_hmc1 / acorr_max_hmc1,\n",
    "                ls='--', color=COLORS[1], label=label_hmc1)\n",
    "    _ = ax.plot(acorr_avg_hmc2 / acorr_max_hmc2,\n",
    "                ls='-.', color=COLORS[2], label=label_hmc2)\n",
    "    _ = ax.plot(acorr_avg_hmc / acorr_max_hmc,\n",
    "                ls='-', color=COLORS[0], label=label_hmc0)\n",
    "    _ = ax.plot(acorr_avg_hmc3 / acorr_max_hmc3,\n",
    "                ls=':', color=COLORS[3], label=label_hmc3)\n",
    "    _ = ax.plot(acorr_avg_l2hmc / acorr_max_l2hmc, \n",
    "                ls='-', color='k',  lw=2., label=label_l2hmc)\n",
    "    \n",
    "    _ = ax.legend(loc='best')\n",
    "    _ = ax.set_xlabel('lag')\n",
    "    _ = ax.set_ylabel('Autocorrelation')\n",
    "    _ = ax.set_title(r\"$16\\times 16$,  \"\n",
    "                     r\"$N_{\\mathrm{LF}} = $\" + f\"{lf_hmc1},    \"\n",
    "                     + r\"$\\beta = $\" + f\"{beta}\")\n",
    "    _ = fig.tight_layout()\n",
    "    \n",
    "    out_file1 = os.path.join(\n",
    "        eps_dir, f'top_charge_autocorrelations_beta{beta}_{idx}.eps'\n",
    "    )\n",
    "    out_file2 = os.path.join(\n",
    "        out_dir, f'top_charge_autocorrelations_beta{beta}_{idx}.png'\n",
    "    )\n",
    "    \n",
    "    print(f\"Saving figure to: {out_file1}.\")\n",
    "    _ = plt.savefig(out_file1, dpi=400, bbox_inches='tight')\n",
    "    print(f\"Saving figure to: {out_file2}.\")\n",
    "    _ = plt.savefig(out_file2, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "if not os.path.isdir(figs_dir):\n",
    "    os.makedirs(figs_dir)\n",
    "\n",
    "beta = 5.0\n",
    "acorr_l2hmc = charges_autocorrs_dict[beta]\n",
    "acorr_avg_l2hmc = acorr_l2hmc.mean(axis=0)\n",
    "acorr_max_l2hmc = acorr_avg_l2hmc.max()\n",
    "acorr_hmc = charges_autocorrs_dict_hmc[beta]\n",
    "acorr_avg_hmc = acorr_hmc.mean(axis=0)\n",
    "acorr_max_hmc = acorr_avg_hmc.max()\n",
    "l2hmc_label = 'L2HMC ' + r\"\"\"$\\beta = $\"\"\" + f'{beta}'\n",
    "hmc_label = 'HMC ' + r\"\"\"$\\beta = $\"\"\" + f'{beta}'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(acorr_avg_l2hmc / acorr_max_l2hmc, \n",
    "            ls='-', color=COLORS[0],  label=l2hmc_label)\n",
    "_ = ax.plot(acorr_avg_hmc / acorr_max_hmc,\n",
    "            ls='--', color=COLORS[0], label=hmc_label)\n",
    "_ = ax.legend(loc='best')\n",
    "_ = ax.set_xlabel('lag', fontsize=14)\n",
    "_ = ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "_ = fig.tight_layout()\n",
    "out_file1 = os.path.join(figs_dir, 'top_charge_autocorrelations.eps')\n",
    "out_file2 = os.path.join(figs_dir, 'top_charge_autocorrelations.png')\n",
    "print(f\"Saving figure to: {out_file1}.\")\n",
    "_ = plt.savefig(out_file1, dpi=400, bbox_inches='tight')\n",
    "print(f\"Saving figure to: {out_file2}.\")\n",
    "_ = plt.savefig(out_file2, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = charge_autocorrs.shape[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "    \n",
    "avg_l2hmc = charge_autocorrs.mean(axis=0)\n",
    "max_l2hmc = avg_l2hmc.max()\n",
    "avg_hmc = charge_autocorrs_hmc.mean(axis=0)\n",
    "max_hmc = avg_hmc.max()\n",
    "\n",
    "ax.plot(avg_l2hmc / max_l2hmc,  #color='k', ls='-', lw=2.,\n",
    "        label='L2HMC (avg. over {} samples)'.format(num_samples))\n",
    "ax.plot(avg_hmc / max_hmc,\n",
    "        #color='k', ls='-', lw=2.,\n",
    "        label='HMC (avg. over {} samples)'.format(num_samples))\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('lag', fontsize=14)\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_dir = run_dirs[0]\n",
    "run_dir_hmc = run_dirs_hmc[0]\n",
    "\n",
    "chains = np.array(load_chains(run_dir))\n",
    "chains_hmc = np.array(load_chains())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def lattice_autocorr(chain):\n",
    "    \"\"\"Calc avg. autocorrelation over all individual links on the lattice.\"\"\"\n",
    "    num_links = chain.shape[-1]\n",
    "    links_autocorr = [autocorr(i) for i in chain.T]\n",
    "    links_autocorr_avg = np.mean(links_autocorr, axis=0)\n",
    "    return links_autocorr_avg\n",
    "\n",
    "chains = np.array(load_chains(run_dir))\n",
    "chains_hmc = np.array(load_chains(run_dir_hmc))\n",
    "\n",
    "#chain = chains[:, 0, :]\n",
    "#num_links = chain.shape[-1]\n",
    "#links_autocorr = np.array([autocorr(i) for i in chain.T])\n",
    "#links_autocorr_avg = np.mean(links_autocorr, axis=0)\n",
    "#links_autocorr_avg = np.mean(links_autocorr.shape)\n",
    "\n",
    "#lattice_autocorrs = [\n",
    "#    lattice_autocorr(i) for i in chains.transpose((1, 0, -1))\n",
    "#]\n",
    "#lattice_autocorrs_hmc = [\n",
    "#    lattice_autocorr(i) for i in chains_hmc.transpose((-1, 0, 1))\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Look at the autocorrelation of individual links on the lattice (poor indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice_autocorrs = np.array(lattice_autocorrs)\n",
    "lattice_autocorrs_hmc = np.array(lattice_autocorrs_hmc)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#for idx in range(20):\n",
    "#    ax.plot(charge_autocorrs[idx] / charge_autocorrs[idx].max(), ls='--')\n",
    "    \n",
    "avg_l2hmc = lattice_autocorrs.mean(axis=0)\n",
    "max_l2hmc = avg_l2hmc.max()\n",
    "avg_hmc = lattice_autocorrs.mean(axis=0)\n",
    "max_hmc = avg_hmc.max()\n",
    "\n",
    "ax.plot(avg_l2hmc / max_l2hmc,  #color='k', ls='-', lw=2.,\n",
    "        label='L2HMC (avg. over {} samples)'.format(num_samples))\n",
    "ax.plot(avg_hmc / max_hmc,\n",
    "        #color='k', ls='-', lw=2.,\n",
    "        label='HMC (avg. over {} samples)'.format(num_samples))\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('lag', fontsize=14)\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Define multiple `log_dir`'s with different lattice sizes for plotting the topological susceptibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir16 = os.path.join('..', '..', 'logs', '2019_04_10', 'lattice_L16', \n",
    "                          'num_steps3', 'num_samples32', 'beta_i2_f5', \n",
    "                          'charge_weight0', 'run_1')\n",
    "log_dir16_hmc = os.path.join('..', '..', 'logs', 'HMC', 'runs_L16',\n",
    "                             'num_steps3', 'eps02094', 'num_samples32',\n",
    "                             'beta_i1_f5', 'run_1')\n",
    "#log_dir16_hmc = os.path.join(log_dir16, 'HMC', 'run_1')\n",
    "assert os.path.isdir(log_dir16)\n",
    "assert os.path.isdir(log_dir16_hmc)\n",
    "\n",
    "log_dir12 = os.path.join('..', '..', 'logs', '2019_04_10', 'lattice_L12', \n",
    "                          'num_steps5', 'num_samples50', 'beta_i2_f5', \n",
    "                          'charge_weight0', 'run_1')\n",
    "#log_dir12_hmc = os.path.join(log_dir12, 'HMC', 'run_1')\n",
    "log_dir12_hmc = os.path.join('..', '..', 'logs', 'HMC', 'runs_L12', \n",
    "                             'num_steps5', 'eps02097', 'num_samples50',\n",
    "                             'beta_i1_f5', 'run_2')\n",
    "assert os.path.isdir(log_dir12)\n",
    "assert os.path.isdir(log_dir12_hmc)\n",
    "\n",
    "log_dir8 = os.path.join('..', '..', 'logs', '2019_04_08', 'lattice_L8', \n",
    "                        'num_steps5',  'num_samples64', 'beta_i2_f45', \n",
    "                        'charge_weight0', 'run_1')\n",
    "log_dir8_hmc = os.path.join('..', '..', 'logs', 'HMC', 'runs_L8',\n",
    "                            'num_steps5', 'eps0228', 'num_samples64',\n",
    "                            'beta_i1_f5', 'run_1')\n",
    "#log_dir8_hmc = os.path.join(log_dir8, 'HMC', 'run_3')\n",
    "assert os.path.isdir(log_dir8)\n",
    "assert os.path.isdir(log_dir8_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output16 = get_observables(log_dir16)\n",
    "output16_hmc = get_observables(log_dir16_hmc)\n",
    "\n",
    "output12 = get_observables(log_dir12)\n",
    "output12_hmc = get_observables(log_dir12_hmc)\n",
    "\n",
    "output8 = get_observables(log_dir8)\n",
    "output8_hmc = get_observables(log_dir8_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_xy(suscept, offset):\n",
    "    x = np.array(list(suscept.keys())) + offset\n",
    "    xx = np.array(list(suscept.keys())) \n",
    "    y = np.array(list(suscept.values()))[:, 0]\n",
    "    err = np.array(list(suscept.values()))[:, 1]\n",
    "    return x, xx, y, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "suscept8 = output8['observables']['dicts']['suscept']\n",
    "suscept8_hmc = output8_hmc['observables']['dicts']['suscept']\n",
    "suscept12 = output12['observables']['dicts']['suscept']\n",
    "suscept12_hmc = output12_hmc['observables']['dicts']['suscept']\n",
    "suscept16 = output16['observables']['dicts']['suscept']\n",
    "suscept16_hmc = output16_hmc['observables']['dicts']['suscept']\n",
    "\n",
    "offsets = 2 * np.array([0., 0.015, 0.03, 0.045, 0.06, 0.075, 0.1])\n",
    "x16, xx16, y16, y16_err = get_xy(suscept16, offsets[0])\n",
    "x16_hmc, xx16_hmc, y16_hmc, y16_hmc_err = get_xy(suscept16_hmc, offsets[1])\n",
    "x12, xx12, y12, y12_err = get_xy(suscept12, offsets[2])\n",
    "x12_hmc, xx12_hmc, y12_hmc, y12_hmc_err = get_xy(suscept12_hmc, offsets[3])\n",
    "x8, xx8, y8, y8_err = get_xy(suscept8, offsets[4])\n",
    "x8_hmc, xx8_hmc, y8_hmc, y8_hmc_err = get_xy(suscept8_hmc, offsets[5])\n",
    "\n",
    "\n",
    "ys = [y16, y16_hmc, y12, y12_hmc, y8, y8_hmc]\n",
    "xs = [x16, x16_hmc, x12, x12_hmc, x8, x8_hmc]\n",
    "xxs = [xx16, xx16_hmc, xx12, xx12_hmc, xx8, xx8_hmc]\n",
    "xxs = [xx16, xx16_hmc, xx12, xx12_hmc, xx8, xx8_hmc]\n",
    "errs = [y16_err, y16_hmc_err, y12_err, y12_hmc_err, y8_err, y8_hmc_err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "markers = []\n",
    "colors = []\n",
    "\n",
    "fig_ax = plt.subplots()\n",
    "kwargs = {\n",
    "    'label': 'L2HMC $L=16$',\n",
    "    'marker': 's',\n",
    "    'markersize': 8.,\n",
    "    'color': 'C0',\n",
    "    'alpha': 0.8,\n",
    "    'capsize': 4.,\n",
    "    'capthick': 1.5,\n",
    "    #'fillstyle': 'none'\n",
    "}\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept16, fig_ax, x_inset=offsets[1], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'HMC $L=16$' # ' + r\"\"\"$L = 12$\"\"\"\n",
    "kwargs['marker'] = 's'\n",
    "kwargs['color'] = 'C0'\n",
    "kwargs['alpha'] = 1.\n",
    "kwargs['fillstyle'] = 'none'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept16_hmc, fig_ax, x_inset=offsets[2], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'L2HMC $L=12$' # + r\"\"\"$L = 16$\"\"\"\n",
    "kwargs['marker'] = 'o'\n",
    "kwargs['color'] = 'C2'\n",
    "kwargs['alpha'] = 0.8\n",
    "kwargs['fillstyle'] = 'full'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept12, fig_ax, x_inset=offsets[1], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'HMC $L=12$' #  ' + r\"\"\"$L = 8$\"\"\"\n",
    "kwargs['color'] = 'C2'\n",
    "kwargs['marker'] = 'o'\n",
    "kwargs['fillstyle'] = 'none'\n",
    "kwargs['alpha'] = 1.\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept12_hmc, fig_ax, x_inset=offsets[3], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'L2HMC $L=8$' #  ' + r\"\"\"$L = 8$\"\"\"\n",
    "kwargs['color'] = 'C3'\n",
    "kwargs['marker'] = 'd'\n",
    "kwargs['fillstyle'] = 'full'\n",
    "kwargs['alpha'] = 0.8\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept8, fig_ax, x_inset=offsets[0], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'HMC $L=8$' #  ' + r\"\"\"$L = 8$\"\"\"\n",
    "kwargs['color'] = 'C3'\n",
    "kwargs['marker'] = 'd'\n",
    "kwargs['alpha'] = 1.\n",
    "kwargs['fillstyle'] = 'none'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept8_hmc, fig_ax, x_inset=offsets[3], **kwargs)\n",
    "\n",
    "axins = inset_axes(fig_ax[1], width=\"25%\", height=\"40%\", loc='upper center', borderpad=1.25)\n",
    "axins1 = inset_axes(fig_ax[1], width=\"25%\", height=\"40%\", loc='upper right', borderpad=1.25)\n",
    "fmts = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5']\n",
    "alphas = [0.8, 1., 0.8, 1., 0.8, 1., 0.8, 1.]\n",
    "linestyles = ['-', '--', '-', '--', '-', '--']\n",
    "fillstyles = ['full', 'none', 'full', 'none', 'full', 'none']\n",
    "for idx, (x, y) in enumerate(zip(xs, ys)):\n",
    "    _ = fig_ax[1].plot(xxs[idx], y, color=colors[idx], label=labels[idx],\n",
    "                       ls=linestyles[idx], fillstyle=fillstyles[idx], alpha=alphas[idx],\n",
    "                       marker=markers[idx], markersize=kwargs['markersize'])#, lw=1.)\n",
    "    _ = axins.errorbar(xs[idx], y, yerr=errs[idx], ls='',\n",
    "                       marker=markers[idx], fillstyle=fillstyles[idx],\n",
    "                       color=colors[idx], capsize=4., capthick=1.25)\n",
    "    _ = axins1.errorbar(xs[idx], y, yerr=errs[idx], ls='',\n",
    "                        marker=markers[idx], fillstyle=fillstyles[idx],\n",
    "                        color=colors[idx], capsize=4., capthick=1.25)\n",
    "    \n",
    "fig, ax = fig_ax\n",
    "_ = ax.tick_params(labelsize=12)\n",
    "_ = ax.set_xlabel(r\"\"\"$\\beta$\"\"\", fontsize=18)\n",
    "_ = ax.set_ylabel(r\"\"\"$\\chi$\"\"\", fontsize=18)\n",
    "_ = ax.legend(loc='lower left')#, fontsize=12)\n",
    "\n",
    "x1, x2, y1, y2 = 3.95, 4.2, 0.0072, 0.0079\n",
    "_ = axins.set_xlim(x1, x2)\n",
    "_ = axins.set_ylim(y1, y2)\n",
    "_ = axins.grid('on')\n",
    "_ = axins.tick_params(labelsize=12)\n",
    "_ = axins.ticklabel_format(style='sci', scilimits=(-2, 2),\n",
    "                           useMathText=False)\n",
    "x1, x2, y1, y2 = 4.95, 5.2, 0.0052, 0.0063\n",
    "_ = axins1.set_xlim(x1, x2)\n",
    "_ = axins1.set_ylim(y1, y2)\n",
    "_ = axins1.grid('on')\n",
    "_ = axins1.tick_params(labelsize=12)\n",
    "_ = axins1.ticklabel_format(style='sci', scilimits=(-2, 2),\n",
    "                            useMathText=False)\n",
    "axins.set_xticks([4.075])\n",
    "axins.set_xticklabels(['4.0'])\n",
    "axins1.set_xticks([5.075])\n",
    "axins1.set_xticklabels(['5.0'])\n",
    "\n",
    "_ = plt.tight_layout()\n",
    "out_dir = os.path.join('..', '..', '..', 'writeup',\n",
    "                       'l2hmc_writeup', 'figures', 'suscept_plots')\n",
    "io.check_else_make_dir(out_dir)\n",
    "suscept_files = [\n",
    "    i for i in os.listdir(out_dir) if i.startswith('topological_suscept_vs_beta_all_')\n",
    "]\n",
    "try:\n",
    "    file_num = int(sorted(\n",
    "        [i.split('_')[-1][:-4] for i in suscept_files]\n",
    "    )[-1]) + 1\n",
    "except IndexError:\n",
    "    file_num = 1\n",
    "\n",
    "out_file = os.path.join(out_dir, f'topological_suscept_vs_beta_all_{file_num}.eps')\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "_ = plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xs_ = np.copy(xs)\n",
    "for i in xs_:\n",
    "    i[-2] -= 0.25\n",
    "    i[-1] += 0.25\n",
    "#[i[-2] + 0.25 for i in xxs]\n",
    "#[i[-1] - 0.25 for i in xxs]\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file_num = sorted([i.split('_')[-1].rstrip('.eps') for i in suscept_files])[-1] + 1\n",
    "out_file = os.path.join(out_dir, f'topological_suscept_vs_beta_all_{file_num}.eps')\n",
    "\n",
    "out_file = os.path.join(out_dir, 'topological_suscept_vs_beta_L8_12_16_1.eps')\n",
    "\n",
    "file_name = out_file.split('/')[-1]\n",
    "file_num = int(file_name.split('_')[-1].rstrip('.eps'))\n",
    "file_num += 1\n",
    "_file_name = file_name.rstrip(str(file_num-1) + '.eps')\n",
    "file_name = _file_name + str(file_num) + '.eps'\n",
    "file_name\n",
    "\n",
    "from scipy.stats import sem\n",
    "charges_dict = {}\n",
    "actions_dict = {}\n",
    "plaqs_dict = {}\n",
    "volume = params['time_size'] * params['space_size']\n",
    "print(\"time_size: {}\".format(params['time_size']))\n",
    "print(\"space_size: {}\".format(params['space_size']))\n",
    "print(\"num_steps: {}\".format(params['num_steps']))\n",
    "print(\"num_samples: {}\".format(params['num_samples']))\n",
    "      \n",
    "\n",
    "for idx, d in enumerate(obs_dirs):\n",
    "    output = load_stats_and_observables(d)\n",
    "    _actions_dict, _plaqs_dict, _charges_dict, tun_events = output\n",
    "    actions_arr = np.array(list(_actions_dict.values()))\n",
    "    plaqs_arr = np.array(list(_plaqs_dict.values()))\n",
    "    charges_arr = np.array(list(_charges_dict.values()))\n",
    "    \n",
    "    keys_arr = np.array(list(_actions_dict.keys()))\n",
    "    steps_arr = keys_arr[:, 0]\n",
    "    beta = betas[idx]\n",
    "    run_steps = charges_arr.shape[0]\n",
    "    \n",
    "    key = (run_steps, beta)\n",
    "    charges_dict[key] = charges_arr\n",
    "    actions_dict[key] = actions_arr\n",
    "    plaqs_dict[key] = plaqs_arr\n",
    "\n",
    "suscept_dict = {}\n",
    "for key, val in charges_dict.items():\n",
    "    beta = key[1]\n",
    "    suscept_dict[beta] = np.mean(val ** 2, axis=0) / volume\n",
    "\n",
    "charges_dict_hmc = {}\n",
    "actions_dict_hmc = {}\n",
    "plaqs_dict_hmc = {}\n",
    "\n",
    "for idx, d in enumerate(obs_dirs_hmc):\n",
    "    output = load_stats_and_observables(d)\n",
    "    _actions_dict, _plaqs_dict, _charges_dict, tun_events = output\n",
    "    actions_arr = np.array(list(_actions_dict.values()))\n",
    "    plaqs_arr = np.array(list(_plaqs_dict.values()))\n",
    "    charges_arr = np.array(list(_charges_dict.values()))\n",
    "    \n",
    "    keys_arr = np.array(list(_actions_dict.keys()))\n",
    "    steps_arr = keys_arr[:, 0]\n",
    "    beta = betas[idx]\n",
    "    run_steps = charges_arr.shape[0]\n",
    "    \n",
    "    key = (run_steps, beta)\n",
    "    charges_dict_hmc[key] = charges_arr\n",
    "    actions_dict_hmc[key] = actions_arr\n",
    "    plaqs_dict_hmc[key] = plaqs_arr\n",
    "\n",
    "suscept_dict_hmc = {}\n",
    "for key, val in charges_dict_hmc.items():\n",
    "    beta = key[1]\n",
    "    suscept_dict_hmc[beta] = np.mean(val ** 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax.tick_params(labelsize=12)\n",
    "\n",
    "_ = ax.set_xlabel(r\"\"\"$\\beta$\"\"\", fontsize=18)\n",
    "_ = ax.set_ylabel(r\"\"\"$\\chi$\"\"\", fontsize=18)\n",
    "_ = ax.legend(loc='best', fontsize=16)\n",
    "\n",
    "_figs_dir = os.path.join(log_dir, 'figures_orig')\n",
    "out_file = os.path.join(_figs_dir, 'topological_suscept_vs_beta_both.eps')\n",
    "_ = plt.tight_layout()\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "_ = plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "obs_arrs8 = output8['observables']['arrs']\n",
    "\n",
    "_log_dir8_1 = '../../logs/conv3D_logs/lattice_L8/old_charge_loss/num_steps5/eps_init03/num_samples64/beta_i2_f5/lr_init1e-3/charge_weight1/run_2/'\n",
    "#..,..,logs,conv3D_logs,lattice_L8,old_charge_loss,num_steps5,eps_init03,num_samples64,beta_i2_f5,lr_init1e-3,charge_weight1,run_2,\n",
    "_log_dir8_0= '../../logs/conv3D_logs/lattice_L8/old_charge_loss/num_steps5/eps_init03/num_samples64/beta_i2_f5/lr_init1e-3/charge_weight0/run_4/'\n",
    "\n",
    "_output8_1 = get_observables(_log_dir8_1)\n",
    "_output8_0 = get_observables(_log_dir8_0)\n",
    "\n",
    "obs_arrs8_1 = _output8_1['observables']['arrs']\n",
    "obs_arrs8_0 = _output8_0['observables']['arrs']\n",
    "\n",
    "keys_arr8_1 = np.array(list(_output8_1['observables']['dicts']['actions'].keys()))\n",
    "keys_arr8_0 = np.array(list(_output8_0['observables']['dicts']['actions'].keys()))\n",
    "keys_arr8_1 == keys_arr8_0\n",
    "steps_arr = keys_arr[:, 0]\n",
    "\n",
    "#out_dir = output8['fi']\n",
    "obs8_1 = (obs_arrs8_1['actions'], obs_arrs8_1['plaqs'], obs_arrs8_1['charges'])\n",
    "obs8_0 = (obs_arrs8_0['actions'], obs_arrs8_0['plaqs'], obs_arrs8_0['charges'])\n",
    "\n",
    "steps_arr = np.arange(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_dir = '../../../writeup/l2hmc_writeup/figures/plaq_plots/good_converge/'\n",
    "io.check_else_make_dir(out_dir)\n",
    "plot_observables(steps_arr, obs8_0, out_dir=out_dir, filetype='eps', hmc=False)\n",
    "\n",
    "out_dir = '../../../writeup/l2hmc_writeup/figures/plaq_plots/bad_converge/'\n",
    "io.check_else_make_dir(out_dir)\n",
    "plot_observables(steps_arr, obs8_1, out_dir=out_dir, filetype='eps', hmc=False)\n",
    "\n",
    "out_dir = '../../../writeup/l2hmc_writeup/figures/plaq_plots/'\n",
    "fig, ax = plt.subplots()\n",
    "plot_observables()\n",
    "plot_observables(steps_arr, , out_dir=out_dir, filetype='eps', hmc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx, d in enumerate(obs_dirs):\n",
    "    output = load_stats_and_observables(d)\n",
    "    actions_dict, plaqs_dict, charges_dict, tun_events = output\n",
    "    \n",
    "    actions_arr = np.array(list(actions_dict.values()))\n",
    "    plaqs_arr = np.array(list(plaqs_dict.values()))\n",
    "    charges_arr = np.array(list(charges_dict.values()))\n",
    "\n",
    "    keys_arr = np.array(list(actions_dict.keys()))\n",
    "    steps_arr = keys_arr[:, 0]\n",
    "    beta = betas[idx]\n",
    "    run_steps = charges_arr.shape[0]\n",
    "    if not os.path.isdir(figs_dirs[idx]):\n",
    "        os.makedirs(figs_dirs[idx])\n",
    "    observables = (actions_arr, plaqs_arr, charges_arr)\n",
    "    plot_observables(steps_arr, observables, hmc=False,\n",
    "                     out_dir=figs_dirs[idx], filetype='eps')\n",
    "    plot_top_charges(charges_arr, beta, out_dir=figs_dir, filetype='eps',\n",
    "                     hmc=False)\n",
    "    #out_dir = os.path.join(figs_dirs[idx], 'top_charge_probs')\n",
    "    #num_samples = params['num_samples']\n",
    "    #plot_charge_probs(charges_arr, beta, params, out_dir, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx, d in enumerate(obs_dirs):\n",
    "    plt.close('all')\n",
    "    output = load_stats_and_observables(d)\n",
    "    actions_dict, plaqs_dict, charges_dict, tun_events = output\n",
    "    \n",
    "    actions_arr = np.array(list(actions_dict.values()))\n",
    "    plaqs_arr = np.array(list(plaqs_dict.values()))\n",
    "    charges_arr = np.array(list(charges_dict.values()))\n",
    "\n",
    "    keys_arr = np.array(list(actions_dict.keys()))\n",
    "    steps_arr = keys_arr[:, 0]\n",
    "    beta = keys_arr[0, 1]\n",
    "    run_steps = charges_arr.shape[0]\n",
    "    #run_steps = charges.shape[0]\n",
    "    if not os.path.isdir(figs_dir):\n",
    "        os.makedirs(figs_dir)\n",
    "    observables = (actions_arr, plaqs_arr, charges_arr)\n",
    "    plot_susceptibility(charges_arr[::5], beta, out_dir=figs_dir, filetype='eps')\n",
    "    beta = betas[idx]\n",
    "    #out_dir = os.path.join(figs_dirs[idx], 'top_charge_probs')\n",
    "    #num_samples = params['num_samples']\n",
    "    #plot_charge_probs(charges_arr, beta, params, out_dir, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gauge_model import create_dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples = tf.convert_to_tensor(np.zeros((params['num_samples'],\n",
    "                                         params['time_size'],\n",
    "                                         params['space_size'],\n",
    "                                         params['dim'])))\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.reshape(samples, (params['num_samples'], -1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params['eps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_np = np.zeros(x.shape)\n",
    "x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lattice.lattice import u1_plaq_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_np = np.zeros(samples.shape)\n",
    "samples_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'eps': params['eps'],\n",
    "    'hmc': False,\n",
    "    'network_arch': None,\n",
    "    'num_steps': params['num_steps'],\n",
    "    'eps_trainable': False,\n",
    "    'data_format': 'channels_last',\n",
    "    'rand': False,\n",
    "    'link_type': 'U1',\n",
    "}\n",
    "dynamics, potential_fn = create_dynamics(samples_np, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dynamics_kwargs = {\n",
    "    'eps': params.get('eps', 0.1),\n",
    "    'hmc': params.get('hmc', False),\n",
    "    'network_arch': params.get('network_arch', 'conv3d'),\n",
    "    'num_steps': params.get('num_steps', 5),\n",
    "    'eps_trainable': params.get('eps_trainable', True),\n",
    "    'data_format': params.get('data_format', 'channels_last'),\n",
    "    'rand': params.get('rand', False),\n",
    "    'link_type': params.get('link_type')\n",
    "}\n",
    "dynamics, potential_fn = create_dynamics(samples_np, **dynamics_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.array(x_np, dtype=np.float32)\n",
    "x_proposed, _, px, x_out = dynamics(x, beta=5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output =  load_stats_and_observables(obs_dirs[1])\n",
    "actions_dict, plaqs_dict, charges_dict, tun_events = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "actions_arr = np.array(list(actions_dict.values()))\n",
    "plaqs_arr = np.array(list(plaqs_dict.values()))\n",
    "charges_arr = np.array(list(charges_dict.values()))\n",
    "\n",
    "keys_arr = np.array(list(actions_dict.keys()))\n",
    "steps_arr = keys_arr[:, 0]\n",
    "beta = keys_arr[0, 1]\n",
    "_run_steps = charges.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charges_arr = np.array(charges_arr, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.plot_helper import plot_multiple_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observables = (actions_arr, plaqs_arr, charges_arr)\n",
    "plot_observables(steps_arr, observables, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "beta = betas[1]\n",
    "out_dir = os.path.join(figs_dirs[1], 'top_charge_probs')\n",
    "num_samples = params['num_samples']\n",
    "\n",
    "plot_charge_probs(charges_arr, beta, params, out_dir, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(-4, 4, 1e-4)\n",
    "y_exact = project_angle(x)\n",
    "y_slow = linear_fft(x)\n",
    "y_approx_arr = []\n",
    "num_terms = [10, 20, 50, 100, 250, 500, 1000]\n",
    "times = []\n",
    "for n in num_terms:\n",
    "    t0 = time.time()\n",
    "    y_approx_arr.append(linear_fs(x, n))\n",
    "    dt = time.time() - t0\n",
    "    print(f'Time to complete ({n} terms): {dt:.4g}')\n",
    "    times.append(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "errs = []\n",
    "for idx, y in enumerate(y_approx_arr):\n",
    "    err = sum((y - y_exact)/len(y_exact.numpy()))\n",
    "    print(f\"Error ({num_terms[idx]} terms): {err:.4g}\")\n",
    "    errs.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges = int(\n",
    "    0.1 + (tf.reduce_sum(ps_proj, axis=(1, 2),\n",
    "                         name='top_charges') / 2 * np.pi)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yy1 = np.array((y_exact / 2 * np.pi), dtype=int)\n",
    "yy = np.array(y_approx_arr[1] / 2 * np.pi, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(yy)), yy1, label='exact')\n",
    "ax.plot(np.arange(len(yy)), yy, label='fft')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for idx, y in enumerate(y_approx_arr):\n",
    "    ax.plot(x, y, label = f'{num_terms[idx]} terms', alpha=0.7, ls='-');\n",
    "ax.plot(x, y_exact, label='Exact', color='k');\n",
    "ax.legend(loc='best', fontsize=10);\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');\n",
    "#ax.set_xlim((-np.pi-0.05, -np.pi + 0.05))\n",
    "out_file = os.path.join(os.getcwd(), 'fourier_series_approx_zoom.png');\n",
    "print(f'Saving figure to: {out_file}.');\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for idx, y in enumerate(y_approx_arr):\n",
    "    ax.plot(x, y, label = f'{num_terms[idx]} terms', alpha=0.7, ls='-');\n",
    "ax.plot(x, y_exact, label='Exact', color='k');\n",
    "ax.legend(loc='best', fontsize=10);\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');\n",
    "ax.set_xlim((-np.pi-0.05, -np.pi + 0.05))\n",
    "out_file = os.path.join(os.getcwd(), 'fourier_series_approx_zoom.png');\n",
    "print(f'Saving figure to: {out_file}.');\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_plaq_sums(x, batch_size, links_shape):\n",
    "    \"\"\"Calculate plaquette sums.\n",
    "\n",
    "    Explicitly, calculate the sum of the links around each plaquette in the\n",
    "    lattice for each sample in samples.\n",
    "\n",
    "    Args:\n",
    "        samples: Tensor of shape (N, D) where N is the batch size and D is\n",
    "        the number of links on the lattice (flattened)\n",
    "    \"\"\"\n",
    "    x = np.reshape(x, shape=(batch_size, *links.shape))\n",
    "\n",
    "    plaq_sums = (x[:, :, :, 0]\n",
    "                 - x[:, :, :, 1]\n",
    "                 - np.roll(x[:, :, :, 0], shift=-1, axis=2)\n",
    "                 + np.roll(x[:, :, :, 1], shift=-1, axis=1))\n",
    "    return plaq_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_top_charges(x, batch_size, links_Shape, fn=np.floor):\n",
    "    \"\"\"Calculate topological charges for each sample in samples.\"\"\"\n",
    "    top_charges = fn(\n",
    "        0.1 + (np.sum(project_angle(calc_plaq_sums(x)), axis=(1, 2))\n",
    "               / (2 * np.pi))\n",
    "    )\n",
    "    return top_charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "# OLD SUSCEPTIBILITY PLOTTER\n",
    "###############################################\n",
    "factor = 1.\n",
    "labels = []\n",
    "markers = []\n",
    "colors = []\n",
    "\n",
    "fig_ax = plt.subplots()\n",
    "kwargs = {\n",
    "    'label': 'L2HMC $L=16$',\n",
    "    'marker': 's',\n",
    "    'markersize': 8.,\n",
    "    'color': 'C0',\n",
    "    'alpha': 1.,\n",
    "    'capsize': 4.,\n",
    "    'capthick': 1.5,\n",
    "    #'fillstyle': 'none'\n",
    "}\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept16, fig_ax, x_inset=offsets[1], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'HMC $L=16$' # ' + r\"\"\"$L = 12$\"\"\"\n",
    "kwargs['marker'] = 's'\n",
    "kwargs['color'] = 'C0'\n",
    "kwargs['alpha'] = 0.8\n",
    "kwargs['fillstyle'] = 'none'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept16_hmc, fig_ax, x_inset=offsets[2], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'L2HMC $L=12$' # + r\"\"\"$L = 16$\"\"\"\n",
    "kwargs['marker'] = 'o'\n",
    "kwargs['color'] = 'C2'\n",
    "kwargs['alpha'] = 0.8\n",
    "kwargs['fillstyle'] = 'full'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept12, fig_ax, x_inset=offsets[1], **kwargs)\n",
    "\n",
    "\n",
    "kwargs['label'] = 'HMC $L=12$' #  ' + r\"\"\"$L = 8$\"\"\"\n",
    "kwargs['color'] = 'C2'\n",
    "kwargs['marker'] = 'o'\n",
    "kwargs['fillstyle'] = 'none'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept12_hmc, fig_ax, x_inset=offsets[3], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'L2HMC $L=8$' #  ' + r\"\"\"$L = 8$\"\"\"\n",
    "kwargs['color'] = 'C3'\n",
    "kwargs['marker'] = 'd'\n",
    "kwargs['fillstyle'] = 'full'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept8, fig_ax, x_inset=offsets[0], **kwargs)\n",
    "\n",
    "kwargs['label'] = 'HMC $L=8$' #  ' + r\"\"\"$L = 8$\"\"\"\n",
    "kwargs['color'] = 'C3'\n",
    "kwargs['marker'] = 'd'\n",
    "kwargs['fillstyle'] = 'none'\n",
    "labels.append(kwargs['label'])\n",
    "markers.append(kwargs['marker'])\n",
    "colors.append(kwargs['color'])\n",
    "kwargs['label'] = ''\n",
    "fig_ax = plot_suscept(suscept8_hmc, fig_ax, x_inset=offsets[3], **kwargs)\n",
    "\n",
    "axins = inset_axes(fig_ax[1], width=\"55%\", height=\"55%\", loc=1, borderpad=1.25)\n",
    "#axins = zoomed_inset_axes(fig_ax[1], zoom=5.1, loc=1, borderpad=1.5)\n",
    "fmts = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5']\n",
    "linestyles = ['-', '--', '-', '--', '-', '--']\n",
    "fillstyles = ['full', 'none', 'full', 'none', 'full', 'none']\n",
    "#q = 1.\n",
    "alphas = [1., 0.9, 0.8, 0.7]\n",
    "#plt.rc('font', size=8)\n",
    "for idx, (x, y) in enumerate(zip(xs, ys)):\n",
    "    #if idx != 1:\n",
    "    #    xx = x + 0.00001\n",
    "    #else:\n",
    "    #    xx = x + (0.00001 / 2)\n",
    "    fig_ax[1].plot(xxs[idx], y, color=colors[idx], ls=linestyles[idx], label=labels[idx],\n",
    "                   fillstyle=fillstyles[idx],\n",
    "                   marker=markers[idx], markersize=kwargs['markersize'])#, lw=1.)\n",
    "    #fig_ax[1].plot(x_avgs, avgs, color='k', ls='-', alpha=0.7)\n",
    "    axins.errorbar(x, y, yerr=errs[idx], marker=markers[idx], ls='',\n",
    "                   fillstyle=fillstyles[idx],\n",
    "                   #ls=linestyles[idx], lw=1.2,\n",
    "                   #alpha=0.8,\n",
    "                   #fillstyle='none',\n",
    "                   #markersize=1.5*kwargs['markersize'], fillstyle='none',\n",
    "                   color=colors[idx], capsize=4., capthick=1.25)\n",
    "                   #alpha=alphas[idx]) #linestyle=linestyles[idx])\n",
    "    #q += 2\n",
    "    #axins.plot(x, y, fmts[idx], alpha=0.7, lw=1.)\n",
    "    \n",
    "x1, x2, y1, y2 = 3.95, 5.2, 0.0049, 0.0078\n",
    "_ = axins.set_xlim(x1, x2)\n",
    "_ = axins.set_ylim(y1, y2)\n",
    "_ = axins.grid('on')\n",
    "\n",
    "#plt.rc('font', size=8)\n",
    "axins.ticklabel_format(style='sci', scilimits=(-2, 2), useMathText=False)\n",
    "_ = axins.tick_params(labelsize=12)\n",
    "#plt.rc('font', size=12)\n",
    "    \n",
    "fig, ax = fig_ax\n",
    "#axins = zoomed_inset_axes(ax, zoom=1.1, width=\"30%\", height=\"40%\", loc=1, borderpad=1.5)\n",
    "#axins = inset_axes(ax, width=\"30%\", height=\"40%\", loc=1, borderpad=1.5)\n",
    "\n",
    "#Axes.ticklabel_format(*, axis='both', style='', scilimits=None, \n",
    "#                      useOffset=None, useLocale=None, useMathText=None)¶\n",
    "#tt = np.arange(1., 5., 0.05)\n",
    "\n",
    "\n",
    "plt.rc('font', size=10)\n",
    "#ax.ticklabel_format(style='sci', scilimits=(-2, 2))#, useMathText=True)\n",
    "_ = ax.tick_params(labelsize=12)\n",
    "_ = ax.set_xlabel(r\"\"\"$\\beta$\"\"\", fontsize=18)\n",
    "_ = ax.set_ylabel(r\"\"\"$\\chi$\"\"\", fontsize=18)\n",
    "_ = ax.legend(loc='lower left')#, fontsize=12)\n",
    "\n",
    "#_ = axins.set_xticklabels(['', '', '5.0', '', ''])\n",
    "_ = plt.tight_layout()\n",
    "\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "#out_dir = output['dirs']['figs_dir']\n",
    "out_dir = os.path.join('..', '..', '..', 'writeup', 'l2hmc_writeup', 'figures')\n",
    "io.check_else_make_dir(out_dir)\n",
    "out_file = os.path.join(out_dir, 'topological_suscept_vs_beta_L8_12_16.eps')\n",
    "_ = plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Calculate and plot observables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Calculate observables for samples generated **_during_** training:\n",
    "- Every $\\approx 500$ steps or so during training procedure, we run the sampler at $\\beta \\equiv \\beta_{\\mathrm{final}}$. \n",
    "- By calculating observables (``total action``, ``average plaquette``, and ``topological charge``) for these samples and looking at the ``thermalization time``, we can get an idea of how well the sampler is performing.\n",
    "- We expect that as the training procedure continues, the ``thermalization time`` should decrease as the sampler improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 53.3s\n",
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_233')\n",
    "train_observables_dicts = calc_observables(log_dir,\n",
    "                                           observables_dicts=None,\n",
    "                                           training=True,\n",
    "                                           frac=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1., 1., 1., -1., -1., -1., 2., -2., 0., 0., 0., -2.])\n",
    "y = np.array([0., 2., -1., -2., 0., 1., 0., 2., -2., 2., 1., -2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1 = np.sqrt(np.sum((x - y))**2)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c2 = np.sum(np.abs(x-y))\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.where(x != y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(np.where(x != y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tot_diff(x, y):\n",
    "    z = np.where(x != y)[0]\n",
    "    return np.sum([x[i] - y[i] if x[i] > y[i] else y[i] - x[i] for i in z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tot_diff1(x, y):\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xx = np.random.randint(-2, 2, size=1000)\n",
    "yy = np.random.randint(-2, 2, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(-2, 2, size=10)\n",
    "j = np.random.randint(-2, 2, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tot_diff2(x, y):\n",
    "    return len(np.where(x != y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.reduce_sum(i - j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples2 = tf.random_normal(samples.shape, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples = tf.cast(samples, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples = tf.reshape(samples, shape=(5, -1))\n",
    "samples2 = tf.reshape(samples2, shape=(5, -1))\n",
    "samples.shape, samples2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff = tf.cast(i - j, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_ = (tf.reduce_sum(1. - tf.cos(samples - samples2), axis=1)\n",
    "          + tf.reduce_sum(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_plaq_exact(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(i - j).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ca = []\n",
    "ca.append(i)\n",
    "ca.append(j)\n",
    "tot_diff1(ca[-1], ca[-2])\n",
    "tot_diff2(ca[-1], ca[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charges_arr.extend(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_plaq_exact(2.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit d = tot_diff(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit d1 = tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tot_diff(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "####  Update train_observables_dicts:  \n",
    " * If `observables_dicts` argument of `calc_training_observables` is not `None`, only calculate observables that haven't been previously calculated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_observables_dicts = calc_observables(\n",
    "    log_dir, \n",
    "    observables_dicts=train_observables_dicts,\n",
    "    training=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot observables for samples generated **_during_** training:\n",
    "- In addition, for each batch of samples generated during, plot the topological charge history of each individual chain in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, train_observables_dicts, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, train_observables_dicts[2], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges_counts(log_dir,  train_observables_dicts[2],  training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Plot top charges counts totaled over all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_charges_dict = train_observables_dicts[2]\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir, training=True)\n",
    "title_str_key = 'training'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in train_charges_dict.items():\n",
    "    step, beta = key\n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='')\n",
    "                #fillstyle='none')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} {title_str_key} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=14)\n",
    "    out_dir = os.path.join(\n",
    "        figs_dir_dict[key], 'topological_charges_counts'\n",
    "    )\n",
    "    check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "        out_dir,\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Calculate observables for samples generated **_after_** training.\n",
    " - Again, samples are generated at $\\beta = \\beta_{\\mathrm{final}}$.\n",
    " - In contrast to the samples generated **_during_** training (which are all ran for $\\sim 100$ steps), we now look at generating longer chains (i.e. longer runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_227')\n",
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=None, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=observables_dicts, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot observables for samples generated **_after_** training:\n",
    "- In addition, for each batch of samples generated during, plot the topological charge history of each individual chain in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, train_observables_dicts, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, train_observables_dicts[2], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges_counts(log_dir,  train_observables_dicts[2],  training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Plot top charges counts totaled over all samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "COLORS *= 10\n",
    "MARKERS *= 10\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir)\n",
    "charges_dict = observables_dicts[2]\n",
    "title_str_key = 'evaluation'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in charges_dict.items():\n",
    "    step, beta = key \n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='',\n",
    "                fillstyle='full')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=16)\n",
    "    #out_dir = os.path.join(\n",
    "    #    figs_dir_dict[key], 'topological_charges_counts'\n",
    "    #)\n",
    "    #check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "       figs_dir_dict[key],\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
