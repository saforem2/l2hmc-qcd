{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example script for training the L2HMC sampler\n",
    "\n",
    " - **NOTE**:\n",
    "   - The following results were generated on my local MacBook Pro with a 2.3 GHz 8-Core Intel Core i9 CPU\n",
    "   - The following notebook CAN be ran WITHOUT having `Horovod` installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports / setup for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 --tf_xla_enable_xla_devices'\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "if os.path.abspath('..') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('..'))\n",
    "    \n",
    "from utils.hvd_init import RANK, SIZE\n",
    "\n",
    "from rich.theme import Theme\n",
    "from rich import print, get_console\n",
    "\n",
    "from config import PROJECT_DIR, BIN_DIR\n",
    "from utils.logger import Logger, print_dict\n",
    "\n",
    "sns.set_palette('bright')\n",
    "plt.style.use('default')\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('bright')\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "\n",
    "logger = Logger()\n",
    "console = get_console()\n",
    "console._width = 180\n",
    "#console.use_theme(theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook', font_scale=0.8)\n",
    "colors = ['#228BE6', '#FA5252', '#40C057',\n",
    "          '#FF920B', '#BE4BDB', '#FAB005',\n",
    "          '#E64980', '#6A777E', '#4C6EF5']\n",
    "sns.set_palette(colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load configs from `BIN_DIR/train_configs.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from config import BIN_DIR\n",
    "\n",
    "from utils.logger import Logger, print_dict\n",
    "\n",
    "logger = Logger()\n",
    "\n",
    "train_configs_file = os.path.join(BIN_DIR, 'train_configs.json')\n",
    "with open(train_configs_file, 'rt') as f:\n",
    "    configs = json.load(f)\n",
    "    \n",
    "restore_from = os.path.abspath(\n",
    "    '/lus/grand/projects/DLHMC/l2hmc-qcd/logs/GaugeModel_logs/2021_08/'\n",
    "    'L16_b256_lf10_actswish_bi1_bf2_dp0025_nh16161616_sepNets_NCProj_ConvNets_bNorm_nw111111/'\n",
    ")\n",
    "configs.update({\n",
    "    'ensure_new': False,\n",
    "    'train_steps': 100000,\n",
    "    'debug': False,\n",
    "    'run_steps': 20000,\n",
    "    'save_steps': 20000,\n",
    "    'steps_per_epoch': 5000,\n",
    "    'patience': 2,\n",
    "    'min_lr': 1e-4,\n",
    "    'logging_steps': 1000,\n",
    "    'print_steps': 1000,\n",
    "    'beta_init': 1.,\n",
    "    'beta_final': 3.,\n",
    "    'restore_from': restore_from,\n",
    "})\n",
    "\n",
    "configs['dynamics_config'].update({\n",
    "    'use_conv_net': True,\n",
    "    'use_mixed_loss': False,\n",
    "    'aux_weight': 0.0,\n",
    "    'num_steps': 10,\n",
    "    'x_shape': [256, 16, 16, 2],\n",
    "\n",
    "})\n",
    "\n",
    "configs['network_config'].update({\n",
    "    'units': [16, 16, 16, 16],\n",
    "    'dropout_prob': 0.025,\n",
    "})\n",
    "\n",
    "configs['conv_config'].update({\n",
    "    'input_shape': configs['dynamics_config']['x_shape'][1:]\n",
    "})\n",
    "\n",
    "logger.log(print_dict(configs, name='Configs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', 'UserWarning')\n",
    "warnings.filterwarnings('ignore', 'CustomMaskWarning')\n",
    "warnings.filterwarnings('ignore', 'WARNING:matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "from utils.training_utils import train \n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "colors = ['#228BE6', '#FA5252', '#40C057',\n",
    "          '#FF920B', '#BE4BDB', '#FAB005',\n",
    "          '#E64980', '#6A777E', '#4C6EF5']\n",
    "sns.set_palette(colors)\n",
    "\n",
    "# only make plots for 8 chains to speed up plotting\n",
    "num_chains = 16 \n",
    "\n",
    "# draw initial x uniformly from [-pi, pi]:\n",
    "x_shape = configs['dynamics_config'].get('x_shape', None)\n",
    "x = tf.random.uniform(x_shape, minval=-np.pi, maxval=np.pi)\n",
    "x = tf.reshape(x, (x.shape[0], -1))\n",
    "\n",
    "logger.console.log(Markdown('#Training'))\n",
    "train_outputs = train(configs, x=x,\n",
    "                      make_plots=True,\n",
    "                      num_chains=num_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_outputs.data.get_dataset()\n",
    "\n",
    "draws = len(train_dataset.loss)\n",
    "xscale = configs['train_steps'] // draws\n",
    "x = xscale * np.arange(configs['train_steps'])[:draws]\n",
    "\n",
    "loss = train_dataset.loss\n",
    "dq_int = train_dataset.dq_int.mean(dim='chain')\n",
    "dq_sin = train_dataset.dq_sin.mean(dim='chain')\n",
    "px = train_dataset.accept_prob.mean(dim='chain')\n",
    "beta = train_dataset.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIN = 15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4), dpi=150,\n",
    "                       constrained_layout=True)\n",
    "\n",
    "ax.plot(x[::THIN], loss[::THIN], color='C0', label='Loss');\n",
    "ax.set_ylabel('Loss', color='C0');\n",
    "ax.tick_params(axis='y', labelcolor='C0');\n",
    "\n",
    "ax1 = ax.twinx();\n",
    "ax.set_xlabel(f'Training step');\n",
    "ax.grid(False);\n",
    "ax1.grid(False);\n",
    "#ax1.set_xlim((30000, 90000))\n",
    "#ax1.axhline(y=1, color='#828282');\n",
    "ax1.plot(x[::THIN], beta[::THIN], color='k', ls='--', label=r\"$\\beta$\");\n",
    "ax1.plot(x[::THIN], px[::THIN], color='C2', alpha=0.9, label=r\"$A(\\xi'|\\xi)$\");\n",
    "ax1.plot(x[::THIN], dq_int[::THIN], color='C3', alpha=0.9, label=r\"$\\delta\\mathcal{Q}_{\\mathbb{Z}}$\");\n",
    "ax1.plot(x[::THIN], dq_sin[::THIN], color='C4', alpha=0.9, label=r\"$\\delta\\mathcal{Q}_{\\mathbb{R}}$\");\n",
    "ax1.legend(fontsize='small', ncol=2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.inference_utils import run as run_inference\n",
    "\n",
    "configs['run_steps'] = 5000\n",
    "log_dir = configs.get('log_dir', None)\n",
    "beta = configs.get('beta_final', None)\n",
    "dynamics = train_outputs.dynamics\n",
    "\n",
    "inference_results = run_inference(dynamics=dynamics,  # pass the trained dynamics\n",
    "                                  configs=configs, \n",
    "                                  md_steps=0,\n",
    "                                  beta=beta,\n",
    "                                  make_plots=True,\n",
    "                                  therm_frac=0.,\n",
    "                                  num_chains=16,\n",
    "                                  save_x=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make plots from training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **NOTE**: Primed quantities below refer to the (modified) proposal configurations at the end of each trajectory, i.e. for an initial configuration $\\xi=(x, v, \\pm)$, we generate a proposal configuration by passing $\\xi$ through $N_{\\mathrm{LF}}$ *leapfrog layers*, i.e.\n",
    "$\\xi\\rightarrow \\xi_1\\rightarrow \\cdots\\rightarrow \\xi_{N_{\\mathrm{LF}}-1}\\rightarrow \\xi_{N_{\\mathrm{LF}}} \\equiv \\xi'$\n",
    "\n",
    "- Mostly, we are interested in the following quantities:\n",
    "\n",
    "    - Various **stepsizes**, $\\varepsilon^{k}_{x},\\, \\varepsilon^{k}_{v}$, for $k = 0, 1, \\ldots, N_{\\mathrm{LF}}$\n",
    "\n",
    "    - **Error in the average plaquette**: $\\langle\\delta x_{P}\\rangle \\equiv  x_{P}^{*} - \\langle x_{P}\\rangle$ where $ x_{P}^{*}$ is the exact result from the infinite volume limit, and is given by\n",
    "      $ x_{P}^{*}(\\beta) = \\tfrac{I_{1}(\\beta)}{I_{0}(\\beta)}$\n",
    "\n",
    "    - **Error in the average $4\\times4$ Wilson loop** $\\langle\\mathcal{W}_{4\\times4}\\rangle$\n",
    "\n",
    "    - **log Jacobian factor**, denoted by `sumlogdet`, i.e. the total log determinant of the Jacobian of transformation $\\xi\\rightarrow\\xi'$, given by:\n",
    "      $\\sum\\left|\\mathcal{J}\\right| = \\left|\\tfrac{\\partial\\xi'}{\\partial\\xi^{T}}\\right|$\n",
    "\n",
    "    - **Effective energy**, $\\tilde{\\mathcal{H}} = \\mathcal{H} - \\sum\\left|\\mathcal{J}\\right|$\n",
    "\n",
    "    - **Acceptance probability** $A(\\xi'|\\xi) = \\min\\left\\{1, \\tfrac{p(\\xi')}{p(\\xi)}\\left|\\tfrac{\\partial\\xi'}{\\partial\\xi^{T}}\\right|\\right\\}$\n",
    "\n",
    "    - *Integer-valued* **topological charge** $\\mathcal{Q}_{\\mathbb{Z}} \\equiv \\tfrac{1}{2\\pi}\\sum_{P}\\left\\lfloor x_{P}\\right\\rfloor$, where \n",
    "      $\\left\\lfloor x_{P}\\right\\rfloor \\equiv  x_{P} - 2\\pi\\left\\lfloor\\tfrac{ x_{P}+\\pi}{2\\pi}\\right\\rfloor$\n",
    "\n",
    "    - *Real-valued* **topological charge** $\\mathcal{Q}_{\\mathbb{R}} \\equiv = \\tfrac{1}{2\\pi}\\sum_{P}\\sin x_{P}$\n",
    "\n",
    "    - **Tunneling rates** $\\delta\\mathcal{Q}_{\\mathcal{X}}(x', x) \\equiv |\\mathcal{Q}_{\\mathcal{X}}' -  \\mathcal{Q}_{\\mathcal{X}}|$ for $\\mathcal{X} \\in \\left\\{\\mathbb{R}, \\mathbb{Z}\\right\\}$.\n",
    "\n",
    "    - **Loss** $\\mathcal{L}_{\\theta}\\left(x', x, A(\\xi'|\\xi)\\right) = -A(\\xi'|\\xi)\\cdot \\delta\\mathcal{Q}_{\\mathbb{R}}$\n",
    "    \n",
    "    - **Integrated autocorrelation time** $\\tau_{\\mathcal{Q}_{\\mathcal{Z}}}$ which serves as a usefeul metric for quantifying the models' improvements when compared with HMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils.file_io as io\n",
    "from utils.plotting_utils import set_size, make_ridgeplots, plot_data\n",
    "\n",
    "logger.rule('Plotting training dataset')\n",
    "num_chains_to_plot = 10\n",
    "plt.style.use('default')\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook', font_scale=0.8)\n",
    "colors = ['#228BE6', '#FA5252', '#40C057',\n",
    "          '#FF920B', '#BE4BDB', '#FAB005',\n",
    "          '#E64980', '#6A777E', '#4C6EF5']\n",
    "sns.set_palette(colors)\n",
    "\n",
    "output = plot_data(train_outputs.data,\n",
    "                   out_dir=None,\n",
    "                   configs=configs,\n",
    "                   therm_frac=0.,\n",
    "                   num_chains=16,\n",
    "                   cmap='viridis_r',\n",
    "                   logging_steps=configs['logging_steps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dynamics = inference_results.dynamics\n",
    "run_data = inference_results.run_data\n",
    "xeps_avg = tf.reduce_mean(dynamics.xeps)\n",
    "veps_avg = tf.reduce_mean(dynamics.veps)\n",
    "eps_avg = (xeps_avg + veps_avg) / 2.\n",
    "run_params = {\n",
    "    'hmc': dynamics.config.hmc,\n",
    "    'beta': beta,\n",
    "    'run_steps': configs['run_steps'],\n",
    "    'plaq_weight': dynamics.plaq_weight,\n",
    "    'charge_weight': dynamics.charge_weight,\n",
    "    'x_shape': dynamics.x_shape,\n",
    "    'num_steps': dynamics.config.num_steps,\n",
    "    'net_weights': dynamics.net_weights,\n",
    "    'input_shape': dynamics.x_shape,\n",
    "    'xeps': dynamics.xeps,\n",
    "    'veps': dynamics.veps,\n",
    "    'xeps_avg': xeps_avg,\n",
    "    'veps_avg': veps_avg,\n",
    "    'eps_avg': eps_avg,\n",
    "    'traj_len': tf.reduce_sum(dynamics.xeps),\n",
    "}\n",
    "output = plot_data(inference_results.run_data,\n",
    "                   out_dir=None,\n",
    "                   configs=configs,\n",
    "                   therm_frac=0.,\n",
    "                   num_chains=16,\n",
    "                   params=run_params,\n",
    "                   hmc=dynamics.config.hmc,\n",
    "                   cmap='crest',\n",
    "                   logging_steps=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46b55ec6904e12698153ecbe81f9eb1ec05b953e4beeb04829d8158b338a9aa8"
  },
  "kernelspec": {
   "display_name": "conda.2021-06-28",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": ""
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
