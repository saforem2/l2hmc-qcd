{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `sns.jointplots` for $\\delta \\phi_{P}$ and $A(\\xi^{\\prime}|\\xi)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import matplotlib.style as mplstyle\n",
    "mplstyle.use('fast')\n",
    "#import matplotlib as mpl\n",
    "#mpl.use('fast')\n",
    "#mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=3, linewidth=500, edgeitems=15, suppress=True)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('bright')\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "label_size = 9 \n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size \n",
    "\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=False)\n",
    "\n",
    "import utils.file_io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_observables import grid_plot, get_obs_dict\n",
    "import utils.file_io as io\n",
    "\n",
    "import pandas as pd\n",
    "from plotters.plot_utils import load_pkl\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import scipy\n",
    "import datetime\n",
    "#import matplotlib as mpl\n",
    "#label_size = 9\n",
    "#mpl.rcParams['xtick.labelsize'] = label_size \n",
    "#mpl.rcParams['ytick.labelsize'] = label_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(width, fraction=1, subplot=[1, 1]):\n",
    "    \"\"\" Set aesthetic figure dimensions to avoid scaling in latex.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Width in pts\n",
    "    fraction: float\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    #fig_height_in = fig_width_in * golden_ratio\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplot[0] / subplot[1])\n",
    "\n",
    "    fig_dim = (fig_width_in, fig_height_in)\n",
    "\n",
    "    return fig_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_palette('bright', 100)\n",
    "#colors = sns.color_palette()\n",
    "#sns.set_style('white')\n",
    "#sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "#sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def therm_arr(arr, therm_frac=0.2):\n",
    "    step_axis = np.argmax(arr.shape)\n",
    "    num_steps = arr.shape[step_axis]\n",
    "    therm_steps = int(therm_frac * num_steps)\n",
    "    arr = np.delete(arr, np.s_[:therm_steps], axis=step_axis)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def calc_tunneling_rate(charges):\n",
    "    if charges.shape[0] > charges.shape[1]:\n",
    "        charges = charges.T\n",
    "    charges = np.around(charges)\n",
    "    dq = np.abs(charges[:, 1:] - charges[:, :-1])\n",
    "    tunneling_rate = np.mean(dq, axis=1)\n",
    "    \n",
    "    return dq, tunneling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from plot_script import get_matching_log_dirs\n",
    "t0 = time.time()\n",
    "root_dir = os.path.abspath('../../gauge_logs/')\n",
    "dates = [\n",
    "    '2019_12_15',\n",
    "    '2019_12_16',\n",
    "    '2019_12_17',\n",
    "    '2019_12_18',\n",
    "    '2019_12_19',\n",
    "    '2019_12_20',\n",
    "    '2019_12_21',\n",
    "    '2019_12_22',\n",
    "    '2019_12_23',\n",
    "    '2019_12_24',\n",
    "    '2019_12_25',\n",
    "    '2019_12_26',\n",
    "    '2019_12_27',\n",
    "    '2019_12_28',\n",
    "    '2019_12_29',\n",
    "    '2019_12_30',\n",
    "    '2019_12_31',\n",
    "    '2020_01_02',\n",
    "    '2020_01_03',\n",
    "    '2020_01_04',\n",
    "    '2020_01_05',\n",
    "    '2020_01_06',\n",
    "    '2020_01_07',\n",
    "    '2020_01_08',\n",
    "    '2020_01_14',\n",
    "    '2020_01_15',\n",
    "    '2020_01_17',\n",
    "    '2020_01_18'\n",
    "]\n",
    "\n",
    "log_dirs = []\n",
    "for date in dates:\n",
    "    ld = get_matching_log_dirs(date, root_dir=root_dir)\n",
    "    for log_dir in ld:\n",
    "        log_dirs += [log_dir]\n",
    "    #log_dirs += [*ld]\n",
    "    \n",
    "print(len(log_dirs))\n",
    "log_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_inference_np import inference_plots\n",
    "for log_dir in log_dirs:\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    run_dirs = get_run_dirs(log_dir, filter_str='steps10000', runs_np=True)\n",
    "    for run_dir in run_dirs:\n",
    "        run_data_file = os.path.join(run_dir, 'run_data.pkl')\n",
    "        energy_data_file = os.path.join(run_dir, 'energy_data.pkl')\n",
    "        cond1 = os.path.isfile(run_data_file)\n",
    "        cond2 = os.path.isfile(energy_data_file)\n",
    "        if cond1 and cond2:\n",
    "            #print(f'Making plots for {run_dir}...')\n",
    "            run_params = load_pkl(os.path.join(run_dir, 'run_params.pkl'))\n",
    "            run_data = load_pkl(run_data_file)\n",
    "            energy_data = load_pkl(energy_data_file)\n",
    "            dataset, energy_dataset = inference_plots(run_data, energy_data, params, run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.seaborn_plots import build_dataframes\n",
    "#runs_np_arr = [True, True, True]\n",
    "#filter_strs = ['steps5000', 'steps10000', 'steps20000']\n",
    "runs_np_arr = [True]\n",
    "filter_strs = ['steps10000']\n",
    "dataframes_dict = {}\n",
    "dataframes_bs_dict = {}\n",
    "run_params_dict = {}\n",
    "for runs_np, filter_str in zip(runs_np_arr, filter_strs):\n",
    "    t0 = time.time()\n",
    "    df_dict, df_bs_dict, rp_dict = build_dataframes(log_dirs,\n",
    "                                                    filter_str=filter_str,\n",
    "                                                    runs_np=runs_np)\n",
    "    dataframes_dict[filter_str] = df_dict\n",
    "    dataframes_bs_dict[filter_str] = df_bs_dict\n",
    "    run_params_dict[filter_str] = rp_dict\n",
    "    print(f'Time to complete: {time.time() - t0}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.seaborn_plots import gridplots\n",
    "\n",
    "timestr = io.get_timestr()\n",
    "runs_np = True\n",
    "for filter_str in dataframes_dict.keys():\n",
    "    dirstr = f'/home/foremans/gridplots/gridplots'\n",
    "    if runs_np:\n",
    "        dirstr += '_np'\n",
    "    else:\n",
    "        dirstr += '_tf'\n",
    "    dirstr += f'_{filter_str}'\n",
    "    dirstr += f\"_{timestr['timestr']}\"\n",
    "    rootdir = os.path.abspath(dirstr)\n",
    "    io.check_else_make_dir(rootdir)\n",
    "    df_dict = dataframes_dict[filter_str]\n",
    "    df_bs_dict = dataframes_bs_dict[filter_str]\n",
    "    rp_dict = run_params_dict[filter_str]\n",
    "    t0 = time.time()\n",
    "    gridplots(log_dirs,\n",
    "              df_dict=df_dict,\n",
    "              df_bs_dict=df_bs_dict,\n",
    "              rp_dict=rp_dict,\n",
    "              rootdir=rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_io import rename_runs_np_dirs\n",
    "rename_runs_np_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.seaborn_plots import gridplots\n",
    "\n",
    "timestr = io.get_timestr()\n",
    "tstr = timestr['timestr']\n",
    "dirstr = f'/home/foremans/gridplots_{filter_str}'\n",
    "if runs_np:\n",
    "    dirstr += '_np'\n",
    "else:\n",
    "    dirstr += '_tf'\n",
    "timestr = io.get_timestr()\n",
    "dirstr += f\"_{timestr['timestr']}\"\n",
    "rootdir = os.path.abspath(dirstr)\n",
    "io.check_else_make_dir(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridplots(log_dirs,\n",
    "          df_dict=df_dict,\n",
    "          df_bs_dict=None,\n",
    "          rp_dict=rp_dict,\n",
    "          rootdir=rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import shutil\n",
    "os.system(\"some_command with args\")\n",
    "\n",
    "base_dir = os.path.abspath('/home/foremans/DLHMC/l2hmc-qcd/gauge_logs/')\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    fnames = [i.rstrip('.pdf') for i in files if i.endswith('.pdf')]\n",
    "    in_files = [os.path.join(root, i) for i in files if i.endswith('.pdf')]\n",
    "    if len(in_files) > 1:\n",
    "        png_dir = os.path.join(root, 'pngs')\n",
    "        io.check_else_make_dir(png_dir)\n",
    "        out_files = [os.path.join(png_dir, f'{i}.png') for i in fnames]\n",
    "        for inf, outf in zip(in_files, out_files):\n",
    "            if not os.path.isfile(outf):\n",
    "                print(f'in: {inf} --> out: {outf}\\n')\n",
    "                os.system(f'~/bin/pdftopng {inf} {outf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.seaborn_plots import violinplots\n",
    "fig, axes1, axes2 = violinplots(log_dirs,\n",
    "                                df_dict=df_dict,\n",
    "                                df_bs_dict=df_bs_dict,\n",
    "                                rp_dict=rp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = violinplots(log_dirs, df_dict=df_dict,\n",
    "                        df_bs_dict=df_bs_dict, rp_dict=rp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_weights(params):\n",
    "    xsw = int(params['x_scale_weight'])\n",
    "    xtw = int(params['x_translation_weight'])\n",
    "    xqw = int(params['x_transformation_weight'])\n",
    "    vsw = int(params['v_scale_weight'])\n",
    "    vtw = int(params['v_translation_weight'])\n",
    "    vqw = int(params['v_transformation_weight'])\n",
    "    return (xsw, xtw, xqw, vsw, vtw, vqw)\n",
    "\n",
    "def get_lf(log_dir):\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import bootstrap\n",
    "\n",
    "#def bootstrap(data, reps=10000):\n",
    "#    samples = []\n",
    "#    percentiles = []\n",
    "#    for x in data:\n",
    "#        n = len(x)\n",
    "#        xb = np.random.choice(x, (n, reps))\n",
    "#        mb = xb.mean(axis=0)\n",
    "#        mb.sort()\n",
    "#        pp = np.percentile(mb, [2.5, 97.5])\n",
    "#        samples.append(mb)\n",
    "#        percentiles.append(pp)\n",
    "#        \n",
    "#    return np.array(samples), percentiles\n",
    "def build_dataframes(run_dirs, data=None, data_bs=None, **kwargs):\n",
    "    has_dx = False\n",
    "    for run_dir in run_dirs:\n",
    "        try:\n",
    "            new_df, new_df_bs, run_params = get_observables(run_dir, **kwargs)\n",
    "            if data is None:\n",
    "                data = new_df\n",
    "            else:\n",
    "                data = pd.concat([data, new_df], axis=0).reset_index(drop=True)\n",
    "                \n",
    "            if data_bs is None:\n",
    "                data_bs = new_df_bs\n",
    "            else:\n",
    "                data_bs = pd.concat([data_bs, new_df_bs], axis=0).reset_index(drop=True)\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        \n",
    "        if os.path.isfile(os.path.join(run_dir, 'observables', 'dx.pkl')):\n",
    "            has_dx = True\n",
    "\n",
    "    return data, data_bs, run_params, has_dx\n",
    "        \n",
    "\n",
    "def get_observables(run_dir, log_dir=None, n_boot=500,\n",
    "                    therm_frac=0.25, nw_include=None, calc_stats=True):\n",
    "    run_params = load_pkl(os.path.join(run_dir, 'run_params.pkl'))\n",
    "    net_weights = tuple([int(i) for i in run_params['net_weights']])\n",
    "    eps = run_params['eps']\n",
    "    beta = run_params['beta']\n",
    "    observables_dir = os.path.join(run_dir, 'observables')\n",
    "    px = load_pkl(os.path.join(observables_dir, 'px.pkl'))\n",
    "    px = np.squeeze(np.array(px))\n",
    "    avg_px = np.mean(px)\n",
    "    \n",
    "    if nw_include is not None:\n",
    "        keep_data = net_weights in nw_include\n",
    "    else:\n",
    "        keep_data = True\n",
    "        \n",
    "    if avg_px < 0.1 or not keep_data:\n",
    "        print(f'INFO:Skipping! nw: {net_weights}, avg_px: {avg_px:.3g}')\n",
    "        return None, None, run_params\n",
    "    \n",
    "    io.log(f'Loading data for net_weights: {net_weights}')\n",
    "    \n",
    "    def load_sqz(fname):\n",
    "        data = load_pkl(os.path.join(observables_dir, fname))\n",
    "        return np.squeeze(np.array(data))\n",
    "    \n",
    "    charges = load_sqz('charges.pkl')\n",
    "    plaqs = load_sqz('plaqs.pkl')\n",
    "    dplq = u1_plaq_exact(beta) - plaqs\n",
    "    \n",
    "    num_steps = px.shape[0]\n",
    "    therm_steps = int(therm_frac * num_steps)\n",
    "    steps = np.arange(therm_steps, num_steps)\n",
    "    \n",
    "    # NOTE: Since the number of tunneling events is computed as \n",
    "    # `dq = charges[1:] - charges[:-1]`,\n",
    "    # we have that\n",
    "    # `dq.shape[0] = num_steps - 1`.\n",
    "    # Because of this, we drop the first step of `px` and `dplq` \n",
    "    # to enforce that they all have the same shape.\n",
    "    px = px[therm_steps:]\n",
    "    dplq = dplq[therm_steps:]\n",
    "    charges = np.insert(charges, 0, 0, axis=0)\n",
    "    charges = charges[therm_steps:]\n",
    "    dq, _ = calc_tunneling_rate(charges)\n",
    "    \n",
    "    dq = dq.T\n",
    "    \n",
    "    dx_file = os.path.join(observables_dir, 'dx.pkl')\n",
    "    if os.path.isfile(dx_file):\n",
    "        print(f'Found dx_file: {dx_file}')\n",
    "        dx = load_sqz('dx.pkl')\n",
    "        dx = dx[therm_steps:]\n",
    "        if dx.shape != px.shape:\n",
    "            dx = None\n",
    "    else:\n",
    "        dx = None\n",
    "        \n",
    "    # dxf.shape = dxb.shape = (num_steps, batch_size, num_links)\n",
    "    # Want to average over all links (last axis)\n",
    "    dxf_file = os.path.join(observables_dir, 'dxf.pkl')\n",
    "    if os.path.isfile(dxf_file):\n",
    "        print(f'Found dxf_file: {dxf_file}')\n",
    "        dxf = load_sqz('dxf.pkl')\n",
    "        dxf = dxf.mean(axis=-1)\n",
    "        dxf = dxf[therm_steps:]\n",
    "        if dxf.shape != px.shape:\n",
    "            dxf = None\n",
    "    else:\n",
    "        dxf = None\n",
    "            \n",
    "    dxb_file = os.path.join(observables_dir, 'dxf.pkl')\n",
    "    if os.path.isfile(dxb_file):\n",
    "        print(f'Found dxb_file: {dxf_file}')\n",
    "        dxb = load_sqz('dxf.pkl')\n",
    "        dxb = dxb.mean(axis=-1)\n",
    "        dxb = dxf[therm_steps:]\n",
    "        if dxb.shape != px.shape:\n",
    "            dxb = None\n",
    "    else:\n",
    "        dxb = None\n",
    "        \n",
    "    \n",
    "    if calc_stats:\n",
    "        px_avg, px_err, px_ = bootstrap(px, n_boot=n_boot)\n",
    "        dplq_avg, dplq_err, dplq_ = bootstrap(dplq, n_boot=n_boot)\n",
    "        dq_avg, dq_err, dq_ = bootstrap(dq, n_boot=n_boot)\n",
    "        px_ = px_.mean(axis=0)\n",
    "        dplq_ = dplq_.mean(axis=0)\n",
    "        dq_ = dq_.mean(axis=0)\n",
    "        num_entries = len(dq_.flatten())\n",
    "        data_bs = pd.DataFrame({\n",
    "            'plaqs_diffs': dplq_.flatten(),\n",
    "            'accept_prob': px_.flatten(),\n",
    "            'tunneling_rate': dq_.flatten(),\n",
    "            'net_weights': tuple([net_weights for _ in range(num_entries)]),\n",
    "            'log_dir': np.array([log_dir for _ in range(num_entries)]),\n",
    "        })\n",
    "        if dx is not None:\n",
    "            dx_avg, dx_err, dx_ = bootstrap(dx, n_boot=n_boot)\n",
    "            dx_ = dx_.mean(axis=0)\n",
    "            data_bs['dx'] = dx_.flatten()\n",
    "        if dxf is not None:\n",
    "            dxf_avg, dxf_err, dxf_ = bootstrap(dxf, n_boot=n_boot)\n",
    "            dxf_ = dxf_.mean(axis=0)\n",
    "            data_bs['dxf'] = dxf_.flatten()\n",
    "        if dxb is not None:\n",
    "            dxb_avg, dxb_err, dxb_ = bootstrap(dxb, n_boot=n_boot)\n",
    "            dxb_ = dxb_.mean(axis=0)\n",
    "            data_bs['dxb'] = dxb_.flatten()\n",
    "            \n",
    "    else:\n",
    "        data_bs = None\n",
    "\n",
    "    num_entries = len(dq.flatten())\n",
    "    data = pd.DataFrame({\n",
    "        'plaqs_diffs': dplq.flatten(),\n",
    "        'accept_prob': px.flatten(),\n",
    "        'tunneling_rate': dq.flatten(),\n",
    "        'net_weights': tuple([net_weights for _ in range(num_entries)]),\n",
    "        'log_dir': np.array([log_dir for _ in range(num_entries)]),\n",
    "    })\n",
    "    \n",
    "    if dx is not None:\n",
    "        data['dx'] = dx.flatten()\n",
    "    if dxf is not None:\n",
    "        data['dxf'] = dxf.flatten()\n",
    "    if dxb is not None:\n",
    "        data['dxb'] = dxb.flatten()\n",
    "    \n",
    "    return data, data_bs, run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "time_str = f'{day_str}_{hour_str}'\n",
    "\n",
    "m1 = ['x', 'v']\n",
    "m2 = ['scale', 'translation', 'transformation']\n",
    "matches = [f'{i}_{j}' for i in m1 for j in m2]\n",
    "\n",
    "#colors = sns.set_palette('bright', 5)\n",
    "colors = sns.color_palette('bright', 5)[::-1]\n",
    "t0 = time.time()\n",
    "dataframes_dict = {}\n",
    "dataframes_bs_dict = {}\n",
    "run_params_dict = {}\n",
    "has_dx_dict = {}\n",
    "\n",
    "log_dirs_sorted = sorted(log_dirs, key=get_lf, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx, log_dir in enumerate(sorted(log_dirs, key=get_lf, reverse=True)):\n",
    "t0 = time.time()\n",
    "for idx, log_dir in enumerate(log_dirs_sorted):\n",
    "    if log_dir in dataframes_dict.keys():\n",
    "        print(f'Already built dataframes for {log_dir}! Skipping!')\n",
    "        continue\n",
    "    if log_dir in dataframes_bs_dict.keys():\n",
    "        print(f'Already built dataframes for {log_dir}! Skipping!')\n",
    "        continue\n",
    "    if log_dir in run_params_dict.keys():\n",
    "        print(f'Already built dataframes for {log_dir}! Skipping!')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'Building dataframes for {log_dir}:\\n')\n",
    "        params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "        lf = params['num_steps']\n",
    "        clip_value = params.get('clip_value', 0)\n",
    "        #train_weights = tuple([\n",
    "        #    int(params[key]) for key in params if any([m in key for m in matches])\n",
    "        #])\n",
    "        train_weights = get_train_weights(params)\n",
    "        train_weights_str = ''.join((str(i) for i in train_weights))\n",
    "        eps_fixed = params.get('eps_fixed', False)\n",
    "\n",
    "        data = None\n",
    "        data_bs = None\n",
    "        n_boot = 1000\n",
    "        therm_frac = 0.25\n",
    "\n",
    "        try:\n",
    "            run_dirs = sorted(get_run_dirs(log_dir))[::-1]\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "\n",
    "        nw_include = [\n",
    "            (0, 0, 0, 0, 0, 0),\n",
    "            (1, 0, 1, 1, 0, 1),\n",
    "            (1, 0, 1, 1, 1, 1),\n",
    "            (1, 1, 1, 1, 0, 1),\n",
    "            (1, 1, 1, 1, 1, 1),\n",
    "        ]\n",
    "        #palette = dict(zip(nw_include, colors))\n",
    "\n",
    "        data, data_bs, run_params, has_dx = build_dataframes(run_dirs,\n",
    "                                                             data=data,\n",
    "                                                             data_bs=data_bs,\n",
    "                                                             n_boot=n_boot,\n",
    "                                                             calc_stats=True,\n",
    "                                                             therm_frac=therm_frac,\n",
    "                                                             nw_include=nw_include)\n",
    "\n",
    "        dataframes_dict[log_dir] = data\n",
    "        dataframes_bs_dict[log_dir] = data_bs\n",
    "        run_params_dict[log_dir] = run_params\n",
    "        has_dx_dict[log_dir] = has_dx\n",
    "print(f'Time to complete: {time.time() - t0}s') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create plots:\n",
    "\n",
    "For each `log_dir`, create a `pd.DataFrame` using all the inference data from `log_dir/runs/*`.\n",
    "\n",
    "Loop over all `log_dirs` and create a `sns.PairGrid` to visualize:\n",
    "\n",
    "- $\\delta \\phi_{P}$\n",
    "- $A(\\xi^{\\prime}|\\xi)$\n",
    "- $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def infer_cmap(color, palette='bright'):\n",
    "    hues = sns.color_palette(palette)\n",
    "    if color == hues[0]:\n",
    "        return sns.light_palette(hues[0], 4, as_cmap=True)\n",
    "    elif color == hues[1]:\n",
    "        return sns.light_palette(hues[1], 4, as_cmap=True)\n",
    "    elif color == hues[2]:\n",
    "        return sns.light_palette(hues[2], 4, as_cmap=True)\n",
    "    elif color == hues[3]:\n",
    "        return sns.light_palette(hues[3], 4, as_cmap=True)\n",
    "    elif color == hues[4]:\n",
    "        return sns.light_palette(hues[4], 4, as_cmap=True)\n",
    "    elif color == hues[5]:\n",
    "        return sns.light_palette(hues[5], 4, as_cmap=True)\n",
    "\n",
    "def kde_color_plot(x, y, **kwargs):\n",
    "    palette = kwargs.pop('palette', 'bright')\n",
    "    cmap = infer_cmap(kwargs['color'], palette=palette)\n",
    "    ax = sns.kdeplot(x, y, cmap=cmap, **kwargs)\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    sns.despine(ax=ax, bottom=True, left=True)\n",
    "    return ax\n",
    "\n",
    "def kde_diag_plot(x, y, **kwargs):\n",
    "    ax = sns.kdeplot(x, y, **kwargs)\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    return ax\n",
    "\n",
    "def plot_pts(x, y, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    _ = ax.plot(x, y, **kwargs)\n",
    "    #ax = sns.scatterplot(x, y, **kwargs)\n",
    "    #sns.despine(ax=ax)\n",
    "    return ax\n",
    "\n",
    "#g = sns.PairGrid(df, hue='left', vars=['satisfaction_level', 'last_evaluation'], palette='Set1')\n",
    "#g = g.map_upper(plt.scatter, s=1, alpha=0.5)\n",
    "#g = g.map_lower(kde_color_plot)\n",
    "#g = g.map_diag(sns.kdeplot, shade=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create grid plot using `sns.PairGrid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     36,
     41,
     43,
     56,
     58,
     66,
     70
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "time_str = f'{day_str}_{hour_str}'\n",
    "\n",
    "m1 = ['x', 'v']\n",
    "m2 = ['scale', 'translation', 'transformation']\n",
    "matches = [f'{i}_{j}' for i in m1 for j in m2]\n",
    "\n",
    "inv_colors = ['#007dff', '#fd971f',\n",
    "              '#87ff00', '#f92672',\n",
    "              '#909090', '#ffff00',\n",
    "              '#70f0f0', '#A742EA']\n",
    "inverse = sns.color_palette(inv_colors)\n",
    "#sns.set_palette(inverse)\n",
    "sns.set_palette('bright')\n",
    "\n",
    "t0 = time.time()\n",
    "#for idx, log_dir in enumerate(log_dirs):\n",
    "keys = list(dataframes_dict.keys())[::-1]\n",
    "#for idx, (log_dir, data) in enumerate(dataframes_dict.items()):\n",
    "for idx, log_dir in enumerate(keys):\n",
    "    io.log(f'log_dir: {log_dir}')\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    \n",
    "    train_weights = get_train_weights(params)\n",
    "    train_weights_str = ''.join((str(i) for i in train_weights))\n",
    "    eps_fixed = params.get('eps_fixed', False)\n",
    "    \n",
    "    data = dataframes_dict[log_dir]\n",
    "    data_bs = dataframes_bs_dict[log_dir]\n",
    "    \n",
    "    #data = data.dropna()\n",
    "    #data_bs = data_bs.dropna()\n",
    "    \n",
    "    run_params = run_params_dict[log_dir]\n",
    "    #has_dx = has_dx_dict[log_dir]\n",
    "    has_dx = hasattr(data, 'dx')\n",
    "\n",
    "    n_boot = 1000\n",
    "    therm_frac = 0.25\n",
    "\n",
    "    eps = run_params['eps']\n",
    "    with sns.axes_style('whitegrid'):\n",
    "        mpl.rcParams['xtick.labelsize'] = 14 \n",
    "        mpl.rcParams['ytick.labelsize'] = 14 \n",
    "        vars_ = ['accept_prob', 'tunneling_rate', 'plaqs_diffs']\n",
    "        #if has_dx:\n",
    "        #    vars_ += ['dx']\n",
    "        \n",
    "        g = sns.PairGrid(data, hue='net_weights', vars=vars_,\n",
    "                         palette='bright', diag_sharey=False, height=6)\n",
    "        g = g.map_diag(sns.kdeplot, shade=True)\n",
    "        #g = g.map_lower(plt.plot, markers=markers, ls='', #marker='x',\n",
    "        #                rasterized=True, alpha=0.4)#, markersize=0.9)#, markeredgewidth=0.1, alpha=0.3)\n",
    "        g = g.map_lower(sns.scatterplot, palette='bright')\n",
    "        g = g.map_upper(kde_color_plot, palette='bright',\n",
    "                        shade=False, gridsize=100, linewidths=1.5)\n",
    "                        #shade=True, shade_lowest=False,\n",
    "                        #alpha=0.75, gridsize=100) #, n_levels=8)#, linewidths=0.8)\n",
    "        ##n_levels=30,\n",
    "        g = g.add_legend(shadow=True)\n",
    "        for ax in g.axes[:, 0]:\n",
    "            ax.set_ylabel(ax.get_ylabel(), fontsize=16)\n",
    "            \n",
    "        for ax in g.axes[-1, :]:\n",
    "            ax.set_xlabel(ax.get_xlabel(), fontsize=16)\n",
    "        #legend = g.fig.legend(facecolor='#505050')\n",
    "        #legend = plt.legend(facecolor='#505050')\n",
    "        #legend = plt.legend()\n",
    "        #plt.setp(legend.get_texts(), color='w')\n",
    "        # Create title for plot\n",
    "        title_str = (r\"$N_{\\mathrm{LF}} = $\" + f'{lf}, '\n",
    "                     r\"$\\varepsilon = $\"  + f'{eps:.3g}')\n",
    "        if eps_fixed:\n",
    "            title_str += ' (fixed) '\n",
    "        if any([tw == 0 for tw in train_weights]):\n",
    "            tws = '(' + ', '.join((str(i) for i in train_weights_str)) + ')'\n",
    "            title_str += (', ' + r\"$\\vec{\\alpha}_{\\mathrm{train}}=$\" + f' {tws}')\n",
    "\n",
    "        if params['clip_value'] > 0:\n",
    "            title_str += f', clip: {clip_value}'\n",
    "        g.fig.suptitle(title_str, y=1.03, fontsize=22)\n",
    "\n",
    "    out_dir = os.path.abspath(f'/home/foremans/cooley_figures'\n",
    "                              f'/combined_pairplots_{time_str}')\n",
    "    io.check_else_make_dir(out_dir)\n",
    "\n",
    "    fname = f'lf{lf}'\n",
    "    if clip_value > 0:\n",
    "        fname += f'_clip{int(clip_value)}'\n",
    "    \n",
    "    if eps_fixed:\n",
    "        fname += f'_eps_fixed_'\n",
    "    \n",
    "    if any([tw == 0 for tw in train_weights]):\n",
    "        #out_dir = os.path.join(out_dir, f'train_{train_weights_str}')\n",
    "        fname += f'_train{train_weights_str}'\n",
    "        \n",
    "    id_str = log_dir.split('/')[-1].split('_')[-1]\n",
    "    out_file = os.path.join(out_dir, f'{fname}_{id_str}.png')\n",
    "    if os.path.isfile(out_file): \n",
    "        out_file = os.path.join(out_dir, f'{fname}_{id_str}_1.png')\n",
    "        #out_file = os.path.join(out_dir, fname + '_1.png')\n",
    "    io.log(f'INFO:Saving figure to: {out_file}')\n",
    "    g.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "\n",
    "    if not os.path.isfile(out_file):\n",
    "        plt.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "    print(f'Time spent plotting: {time.time() - t0:.3g}')\n",
    "    io.log(80 * '-' + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create violin plots using `sns.violinplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(palette='muted', n_colors=len(nw_include))[::-1]\n",
    "palette = dict(zip(nw_include, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "time_str = f'{day_str}_{hour_str}'\n",
    "fontsize = 14\n",
    "xticklabelsize = 14 \n",
    "yticklabelsize = 14 \n",
    "axeslabelsize = 18 \n",
    "labelsize = 22\n",
    "titlesize = 22\n",
    "\n",
    "nw_include = [\n",
    "    (0, 0, 0, 0, 0, 0),\n",
    "    (1, 0, 1, 1, 0, 1),\n",
    "    (1, 0, 1, 1, 1, 1),\n",
    "    (1, 1, 1, 1, 0, 1),\n",
    "    (1, 1, 1, 1, 1, 1),\n",
    "]\n",
    "#colors = sns.color_palette( 5)[::-1]\n",
    "#palette = dict(zip(nw_include, colors))\n",
    "colors = sns.color_palette(palette='muted', n_colors=len(nw_include))[::-1]\n",
    "palette = dict(zip(nw_include, colors))\n",
    "#sns.set_style(\"ticks\")\n",
    "#plt.style.use('seaborn-muted')\n",
    "\n",
    "keys = list(dataframes_dict.keys())[::-1]\n",
    "#for idx, (log_dir, data) in enumerate(dataframes_dict.items()):\n",
    "for idx, log_dir in enumerate(keys):\n",
    "    io.log(f'log_dir: {log_dir}')\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    \n",
    "    train_weights = get_train_weights(params)\n",
    "    train_weights_str = ''.join((str(i) for i in train_weights))\n",
    "    eps_fixed = params.get('eps_fixed', False)\n",
    "    \n",
    "    data = dataframes_dict[log_dir]\n",
    "    data_bs = dataframes_bs_dict[log_dir]\n",
    "    \n",
    "    run_params = run_params_dict[log_dir]\n",
    "    #has_dx = has_dx_dict[log_dir]\n",
    "    has_dx = hasattr(data, 'dx')\n",
    "    has_dxf = hasattr(data, 'dxf')\n",
    "    has_dxb = hasattr(data, 'dxb')\n",
    "    \n",
    "    date_str = log_dir.split('/')[-2]\n",
    "    y, m, d = date_str.split('_')\n",
    "    y = int(y)\n",
    "    m = int(m)\n",
    "    d = int(d)\n",
    "\n",
    "    old_dx = True\n",
    "    if y == 2020 and m == 1 and d >= 4:\n",
    "        old_dx = False\n",
    "        \n",
    "    #with sns.axes_style('darkgrid'):\n",
    "    eps = run_params['eps']\n",
    "    mpl.rcParams['xtick.labelsize'] = xticklabelsize \n",
    "    mpl.rcParams['ytick.labelsize'] = yticklabelsize \n",
    "\n",
    "    ncols = 3\n",
    "    figsize = [20, 10]\n",
    "    if has_dx:\n",
    "        ncols += 1\n",
    "        figsize[0] += 4\n",
    "    if has_dxf:\n",
    "        ncols += 1\n",
    "        figsize[0] += 4\n",
    "    if has_dxb:\n",
    "        ncols += 1\n",
    "        figsize[0] += 4\n",
    "\n",
    "    figsize = tuple(figsize)\n",
    "\n",
    "    fig, (axes0, axes1) = plt.subplots(nrows=2, ncols=ncols, figsize=figsize)\n",
    "    # Initialise figure instance\n",
    "    #fig, (axes0, axes1) = plt.subplots(nrows=2, ncols=ncols, sharey=True,\n",
    "    #                                   figsize=set_size(width, subplot=[2, ncols]))\n",
    "\n",
    "    axes = axes0.flatten()\n",
    "    axes[0].axvline(x=0, ls=':', color='k')#, lw=0.9)\n",
    "    axes[1].axvline(x=0, ls=':', color='k')#, lw=0.9)\n",
    "\n",
    "    axes[0] = sns.violinplot(x='plaqs_diffs', y='net_weights', data=data, palette=palette, ax=axes[0])#, scale='width')#, saturation=1.)\n",
    "    axes[1] = sns.violinplot(x='tunneling_rate', y='net_weights', data=data,  palette=palette, cut=0, ax=axes[1])#, scale='width')#, scale='width')#, saturation=1.)\n",
    "    axes[2] = sns.violinplot(x='accept_prob', y='net_weights', data=data, palette=palette, ax=axes[2])#, scale='width')#, saturation=1.)\n",
    "    if has_dx:\n",
    "        axes[3] = sns.violinplot(x='dx', y='net_weights', data=data[data.dx < 10], palette=palette, ax=axes[3])#, scale='width')#, saturation=1.)\n",
    "    if has_dxf:\n",
    "        axes[4] = sns.violinplot(x='dxf', y='net_weights', data=data[data.dxf < 10], palette=palette, ax=axes[4])#, scale='width')#, saturation=1.)\n",
    "    if has_dxb:\n",
    "        axes[5] = sns.violinplot(x='dxb', y='net_weights', data=data[data.dxb < 10], palette=palette, ax=axes[5])#, scale='width')#, saturation=1.)\n",
    "\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylabel('')\n",
    "        ax.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "\n",
    "    axes[0].set_xlabel(r\"\"\"$\\delta \\phi_{P}$\"\"\", fontsize=labelsize)\n",
    "    axes[1].set_xlabel(r\"\"\"$\\gamma$\"\"\", fontsize=labelsize)\n",
    "    axes[2].set_xlabel(r\"\"\"$A(\\xi^{\\prime}|\\xi)$\"\"\", fontsize=labelsize)\n",
    "\n",
    "    l2_str = r\"\"\"$\\|x^{(i+1)} - x^{(i)}\\|^{2}_{2}$\"\"\"\n",
    "    cos_str = r\"\"\"$1 - \\cos(x^{(i+1)} - x^{(i)})$\"\"\"\n",
    "\n",
    "    l2_strf = r\"\"\"$\\|x_{f}^{(i+1)} - x_{f}^{(i)}\\|^{2}_{2}$\"\"\"\n",
    "    cos_strf = r\"\"\"$1 - \\cos(x_{f}^{(i+1)} - x_{f}^{(i)})$\"\"\"\n",
    "\n",
    "    l2_strb = r\"\"\"$\\|x_{b}^{(i+1)} - x_{b}^{(i)}\\|^{2}_{2}$\"\"\"\n",
    "    cos_strb = r\"\"\"$1 - \\cos(x_{b}^{(i+1)} - x_{b}^{(i)})$\"\"\"\n",
    "\n",
    "    if has_dx:\n",
    "        if old_dx:\n",
    "            axes[3].set_xlabel(l2_str, fontsize=labelsize)\n",
    "\n",
    "        else:\n",
    "            axes[3].set_xlabel(cos_str, fontsize=labelsize)\n",
    "    if has_dxf:\n",
    "        if old_dx:\n",
    "            axes[4].set_xlabel(l2_strf, fontsize=labelsize)\n",
    "        else:\n",
    "            axes[4].set_xlabel(cos_strf, fontsize=labelsize)\n",
    "    if has_dxb:\n",
    "        if old_dx:\n",
    "            axes[5].set_xlabel(l2_strb, fontsize=labelsize)\n",
    "        else:\n",
    "            axes[5].set_xlabel(cos_strb, fontsize=labelsize)\n",
    "\n",
    "    #axes[0].set_ylabel('')\n",
    "    for ax in axes[1:]:\n",
    "        ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    axes = axes1.flatten()\n",
    "    axes[0].axvline(x=0, ls=':', color='k')#, lw=0.9)\n",
    "    axes[1].axvline(x=0, ls=':', color='k')#, lw=0.9)\n",
    "\n",
    "    axes[0] = sns.violinplot(x='plaqs_diffs', y='net_weights', data=data_bs, palette=palette, ax=axes[0])#, scale='width')#, saturation=1.)\n",
    "    axes[1] = sns.violinplot(x='tunneling_rate', y='net_weights', data=data_bs,  palette=palette, cut=0, ax=axes[1])#, scale='width')#, scale='width')#, saturation=1.)\n",
    "    axes[2] = sns.violinplot(x='accept_prob', y='net_weights', data=data_bs, palette=palette, ax=axes[2])#, scale='width')#, saturation=1.)\n",
    "\n",
    "    if has_dx:\n",
    "        axes[3] = sns.violinplot(x='dx', y='net_weights', data=data_bs[data_bs.dx < 10], palette=palette, ax=axes[3])#, scale='width')\n",
    "    if has_dxf:\n",
    "        axes[4] = sns.violinplot(x='dxf', y='net_weights', data=data_bs[data_bs.dxf < 10], palette=palette, ax=axes[4])#, scale='width')#, saturation=1.)\n",
    "    if has_dxb:\n",
    "        axes[5] = sns.violinplot(x='dxb', y='net_weights', data=data_bs[data_bs.dxb < 10], palette=palette, ax=axes[5])#, scale='width')#, saturation=1.)\n",
    "\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylabel('')\n",
    "        ax.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "\n",
    "    axes[0].set_xlabel(r\"\"\"$\\langle\\delta \\phi_{P}\\rangle$\"\"\", fontsize=labelsize)\n",
    "    axes[1].set_xlabel(r\"\"\"$\\langle\\gamma\\rangle$\"\"\", fontsize=labelsize)\n",
    "    axes[2].set_xlabel(r\"\"\"$\\langle A(\\xi^{\\prime}|\\xi)\\rangle$\"\"\", fontsize=labelsize)\n",
    "    l2_str = r\"\"\"$\\langle\\|x^{(i+1)} - x^{(i)}\\|^{2}_{2}\\rangle$\"\"\"\n",
    "    cos_str = r\"\"\"$\\langle 1 - \\cos(x^{(i+1)} - x^{(i)})\\rangle$\"\"\"\n",
    "\n",
    "    l2_strf = r\"\"\"$\\langle\\|x_{f}^{(i+1)} - x_{f}^{(i)}\\|^{2}_{2}\\rangle$\"\"\"\n",
    "    cos_strf = r\"\"\"$\\langle 1 - \\cos(x_{f}^{(i+1)} - x_{f}^{(i)})\\rangle$\"\"\"\n",
    "\n",
    "    l2_strb = r\"\"\"$\\langle \\|x_{b}^{(i+1)} - x_{b}^{(i)}\\|^{2}_{2}\\rangle$\"\"\"\n",
    "    cos_strb = r\"\"\"$\\langle 1 - \\cos(x_{b}^{(i+1)} - x_{b}^{(i)})\\rangle$\"\"\"\n",
    "\n",
    "    if has_dx:\n",
    "        if old_dx:\n",
    "            axes[3].set_xlabel(l2_str, fontsize=labelsize)\n",
    "\n",
    "        else:\n",
    "            axes[3].set_xlabel(cos_str, fontsize=labelsize)\n",
    "    if has_dxf:\n",
    "        if old_dx:\n",
    "            axes[4].set_xlabel(l2_strf, fontsize=labelsize)\n",
    "        else:\n",
    "            axes[4].set_xlabel(cos_strf, fontsize=labelsize)\n",
    "    if has_dxb:\n",
    "        if old_dx:\n",
    "            axes[5].set_xlabel(l2_strb, fontsize=labelsize)\n",
    "        else:\n",
    "            axes[5].set_xlabel(cos_strb, fontsize=labelsize)\n",
    "\n",
    "\n",
    "    for ax in axes[1:]:\n",
    "        ax.set_yticks([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    fname = f'lf{lf}' #_{idx}'\n",
    "    title_str = (r\"$N_{\\mathrm{LF}} = $\" + f'{lf}, '\n",
    "                 r\"$\\varepsilon = $\"  + f'{eps:.3g}')\n",
    "\n",
    "    eps_str = f'{eps:.3g}'.replace('.', '')\n",
    "    fname += f'_e{eps_str}'\n",
    "\n",
    "    if eps_fixed:\n",
    "        title_str += ' (fixed) '\n",
    "        fname += '_fixed'\n",
    "\n",
    "    if any([tw == 0 for tw in train_weights]):\n",
    "        tws = '(' + ', '.join((str(i) for i in train_weights_str)) + ')'\n",
    "        title_str += (', ' + r\"$\\mathrm{nw}_{\\mathrm{train}}=$\" + f' {tws}')\n",
    "        fname += f'_{train_weights_str}'\n",
    "\n",
    "\n",
    "    if params['clip_value'] > 0:\n",
    "        title_str += f', clip: {clip_value}'\n",
    "        fname += f'_clip{clip_value}'\n",
    "    fig.suptitle(title_str, fontsize=titlesize, y=1.025)\n",
    "    out_dir = os.path.abspath(\n",
    "        f'/home/foremans/cooley_figures/violinplots_{time_str}'\n",
    "    )\n",
    "    io.check_else_make_dir(out_dir)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #id_str = log_dir.split('/')[-1].split('_')[-1]\n",
    "    #out_file = os.path.join(out_dir, f'{fname}.png')\n",
    "    #id_str = f'{idx}'\n",
    "    #out_file = os.path.join(out_dir, f'{fname}_{id_str}.png')\n",
    "    out_file = os.path.join(out_dir, f'{fname}.pdf')\n",
    "    if os.path.isfile(out_file): \n",
    "        id_str = f'{idx}'\n",
    "        #out_file = os.path.join(out_dir, f'{fname}_{id_str}_{idx}.png')\n",
    "        out_file = os.path.join(out_dir, f'{fname}_{id_str}.pdf')\n",
    "    io.log(f'INFO:Saving figure to: {out_file}')\n",
    "    plt.savefig(out_file, bbox_inches='tight')# dpi=200, bbox_inches='tight')\n",
    "\n",
    "    if not os.path.isfile(out_file):\n",
    "        plt.savefig(out_file, bbox_inches='tight')#, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise figure instance\n",
    "fig, ax = plt.subplots(2, 4, sharey=True, figsize=set_size(width, subplot=[2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('muted', 5)\n",
    "with sns.axes_style('whitegrid'):\n",
    "    mpl.rcParams['xtick.labelsize'] = 14\n",
    "    mpl.rcParams['ytick.labelsize'] = 14 \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(15, 5))\n",
    "    #ax1.axhline(y=0, ls=':', color='k', lw=0.8)\n",
    "    axes = axes.flatten()[::-1]\n",
    "    axes[1].axvline(x=0, ls=':', color='k')#, lw=0.9)\n",
    "    axes[-1].axvline(x=0, ls=':', color='k')#, lw=0.9)\n",
    "    axes[0] = sns.violinplot(x='accept_prob', y='net_weights', data=data, palette=palette, ax=axes[0])#, saturation=1.)\n",
    "    axes[1] = sns.violinplot(x='tunneling_rate', y='net_weights', cut=0, data=data, palette=palette, ax=axes[1])#, saturation=1.)\n",
    "    axes[-1] = sns.violinplot(x='plaqs_diffs', y='net_weights', data=data, palette=palette, ax=axes[-1])#, saturation=1.)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylabel('')\n",
    "    ##for ax in axes:\n",
    "    #    ax.set_ylabel(ax.get_ylabel(), fontsize=16)\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=16)\n",
    "        \n",
    "    fig.suptitle('testing', fontsize=22, y=1.)\n",
    "\n",
    "    #axes[-1].set_xlabel(axes[-1].get_xlabel(), fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "time_str = f'{day_str}_{hour_str}'\n",
    "\n",
    "m1 = ['x', 'v']\n",
    "m2 = ['scale', 'translation', 'transformation']\n",
    "matches = [f'{i}_{j}' for i in m1 for j in m2]\n",
    "\n",
    "#sns.set_palette('bright')\n",
    "colors = sns.color_palette('bright', 5)[::-1]\n",
    "t0 = time.time()\n",
    "for idx, log_dir in enumerate(log_dirs):\n",
    "    io.log(f'log_dir: {log_dir}')\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    train_weights = tuple([\n",
    "        int(params[key]) for key in params if any([m in key for m in matches])\n",
    "    ])\n",
    "    train_weights_str = ''.join((str(i) for i in train_weights))\n",
    "    eps_fixed = params.get('eps_fixed', False)\n",
    "\n",
    "    data = None\n",
    "    n_boot = 1000\n",
    "    therm_frac = 0.25\n",
    "\n",
    "    try:\n",
    "        run_dirs = sorted(get_run_dirs(log_dir))[::-1]\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "        \n",
    "    nw_include = [\n",
    "        (0, 0, 0, 0, 0, 0),\n",
    "        (1, 0, 1, 1, 0, 1),\n",
    "        (1, 0, 1, 1, 1, 1),\n",
    "        (1, 1, 1, 1, 0, 1),\n",
    "        (1, 1, 1, 1, 1, 1),\n",
    "    ]\n",
    "    palette = dict(zip(nw_include, colors))\n",
    "    \n",
    "    if os.path.isfile(os.path.join(run_dirs[0], 'observables', 'dxf.pkl')):\n",
    "        data, run_params, has_dx = build_dataframes(run_dirs,\n",
    "                                                    data=data,\n",
    "                                                    n_boot=n_boot,\n",
    "                                                    calc_stats=True,\n",
    "                                                    therm_frac=therm_frac,\n",
    "                                                    nw_include=nw_include)\n",
    "        eps = run_params['eps']\n",
    "        with sns.axes_style('darkgrid'):\n",
    "            mpl.rcParams['xtick.labelsize'] = 10\n",
    "            mpl.rcParams['ytick.labelsize'] = 10 \n",
    "            if has_dx:\n",
    "                ncols = data['net_weights'].nunique()\n",
    "                fig, axes = plt.subplots(ncols=ncols, sharey=False)\n",
    "                nws = data['net_weights'].unique()\n",
    "                #colors = sns.color_palette('bright', ncols)\n",
    "                for idx, (nw, ax) in enumerate(zip(nws, axes.flatten())):\n",
    "                    #ax = sns.violinplot(y='dx', data=data[data.net_weights.isin([nw])], color=colors[idx], ax=ax, sharey=False, label=nw)\n",
    "                    ax = sns.violinplot(y='dx', data=data[data.net_weights.isin([nw])], palette=palette, ax=ax, sharey=False, label=nw)\n",
    "                for nw, ax in zip(nws, axes.flatten()):\n",
    "                    ax.set_xlabel(nw, fontsize=12)\n",
    "                for ax in axes[1:]:\n",
    "                    ax.set_ylabel('')\n",
    "                    \n",
    "                axes[0].set_ylabel(axes[0].get_ylabel(), fontsize=14)\n",
    "                #for idx, (nws, ax) in enumerate(zip(nws, axes.flatten())):\n",
    "                #    ns.catplot(x=\"continent\", y=\"lifeExp\", hue=\"year\", kind=\"point\", \n",
    "                #    #data=df[df.continent.isin(['Asia','Europe'])]);\n",
    "                #    ax = sns.violinplot(y='dx', data=data[data.net_weights.isin([nws])], palette='bright', ax=ax, hue='net_weights', sharey=False)\n",
    "                #g = sns.catplot(y='dx', col='net_weights', data=data, kind='violin',\n",
    "                #                hue='net_weights', dodge=False, palette='bright', sharey=False, )\n",
    "                #for ax in g.axes[0]:\n",
    "                #    ax.set_ylabel(ax.get_ylabel(), fontsize=18)\n",
    "                #g = sns.FacetGrid(tips, hue=\"time\", col=\"sex\", height=4)\n",
    "                #g.map(qqplot, \"total_bill\", \"tip\")\n",
    "                #g.add_legend();\n",
    "                #g = sns.FaceGrid()\n",
    "                #>>> g = sns.catplot(x=\"time\", y=\"pulse\", hue=\"kind\",\n",
    "                #    col=\"diet\", data=exercise)\n",
    "                #fig, ax = plt.subplots()\n",
    "                #ax = sns.violinplot(x='net_weights', y='dx', data=data, palette='bright', ax=ax)\n",
    "                #sns.kdeplot()\n",
    "                #ax.set_xlabel(ax.get_xlabel(), fontsize=12)\n",
    "\n",
    "                title_str = (r\"$N_{\\mathrm{LF}} = $\" + f'{lf}, '\n",
    "                             r\"$\\varepsilon = $\"  + f'{eps:.3g}')\n",
    "                if eps_fixed:\n",
    "                    title_str += ' (fixed) '\n",
    "                if any([tw == 0 for tw in train_weights]):\n",
    "                    tws = '(' + ', '.join((str(i) for i in train_weights_str)) + ')'\n",
    "                    title_str += (', ' + r\"$\\mathrm{nw}_{\\mathrm{train}}=$\" + f' {tws}')\n",
    "\n",
    "                if params['clip_value'] > 0:\n",
    "                    title_str += f', clip: {clip_value}'\n",
    "                #g.fig.suptitle(title_str, y=1.02, fontsize=16)\n",
    "                fig.suptitle(title_str, y=1.03, fontsize=16)\n",
    "                #plt.subplots_adjust(hspace=-0.1)\n",
    "                out_dir = os.path.abspath(\n",
    "                    f'/home/foremans/cooley_figures/dx_violinplots_{time_str}'\n",
    "                )\n",
    "                io.check_else_make_dir(out_dir)\n",
    "\n",
    "                fname = f'lf{lf}'\n",
    "                if clip_value > 0:\n",
    "                    fname += f'_clip{int(clip_value)}'\n",
    "\n",
    "                if eps_fixed:\n",
    "                    fname += f'_eps_fixed_'\n",
    "\n",
    "                if any([tw == 0 for tw in train_weights]):\n",
    "                    fname += f'_train{train_weights_str}'\n",
    "\n",
    "                plt.tight_layout()\n",
    "                id_str = log_dir.split('/')[-1].split('_')[-1]\n",
    "                #id_str = f'_{idx}'\n",
    "                out_file = os.path.join(out_dir, f'{fname}_{id_str}.png')\n",
    "                if os.path.isfile(out_file): \n",
    "                    out_file = os.path.join(out_dir, f'{fname}_{id_str}_1.png')\n",
    "                    #out_file = os.path.join(out_dir, fname + '_1.png')\n",
    "                io.log(f'INFO:Saving figure to: {out_file}')\n",
    "                plt.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "\n",
    "                if not os.path.isfile(out_file):\n",
    "                    plt.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "\n",
    "                print(f'Time spent plotting: {time.time() - t0:.3g}')\n",
    "                io.log(80 * '-' + '\\n')\n",
    "\n",
    "    else:\n",
    "        print('\\n')\n",
    "        print('INFO: `dx` not found. Skipping!')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = data['net_weights'].nunique()\n",
    "fig, axes = plt.subplots(ncols=ncols, sharey=False)\n",
    "nws = data['net_weights'].unique()\n",
    "colors = sns.color_palette('bright', ncols)\n",
    "for idx, (nw, ax) in enumerate(zip(nws, axes.flatten())):\n",
    "    ax = sns.violinplot(y='dx', data=data[data.net_weights.isin([nw])], color=colors[idx], ax=ax, sharey=False, label=nw)\n",
    "    \n",
    "    \n",
    "for nw, ax in zip(nws, axes.flatten()):\n",
    "    ax.set_xlabel(nw, fontsize=12)\n",
    "for ax in axes[1:]:\n",
    "    ax.set_ylabel('')\n",
    "    \n",
    "    \n",
    "#plt.subplots_adjust(wspace=0.2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import COLORS\n",
    "palette = {(1, 1, 1, 1, 1, 1): COLORS[0], (1, 1, 1, 1, 0, 1): COLORS[1], (1, 0, 1, 1, 1, 1): COLORS[0]}\n",
    "g = sns.catplot(y='dx', col='net_weights', data=data, kind='violin',\n",
    "                hue='net_weights', dodge=False, palette=palette, sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(y='dx', x='net_weights', data=data, palette='bright', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['net_weights'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame(data['dx'], columns=data['net_weights'].unique())\n",
    "s\n",
    "#[(1, 1, 1, 1, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in g.axes[0]:\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=18)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.axes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.suptitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    g = sns.catplot(y='dx', col='net_weights', data=data, kind='violin', hue='net_weights', palette='bright', sharey=False)\n",
    "    for ax in g.axes[0]:\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data['dx'], hueshade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(run_dir, 'observables'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    mpl.rcParams['xtick.labelsize'] = 9\n",
    "    mpl.rcParams['ytick.labelsize'] = 9\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, sharex=True, figsize=(8, 10))\n",
    "    ax1.axhline(y=0, ls=':', color='k', lw=0.8)\n",
    "    ax2.axhline(y=0, ls=':', color='k', lw=0.8)\n",
    "    ax3.axhline(y=0, ls=':', color='k', lw=0.8)\n",
    "    ax1 = sns.violinplot(x='net_weights', y='tunneling_rate', data=data, palette='bright', ax=ax1)\n",
    "    ax2 = sns.violinplot(x='net_weights', y='plaqs_diffs', data=data, palette='bright', ax=ax2)\n",
    "    ax3 = sns.violinplot(x='net_weights', y='accept_prob', data=data, palette='bright', ax=ax3)\n",
    "    ax1.set_xlabel('')\n",
    "    ax2.set_xlabel('')\n",
    "    #ax1.set_xticklabels([])\n",
    "    #ax2.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.axh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_yticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> ax = sns.violinplot(x=\"day\", y=\"total_bill\", hue=\"smoker\",\n",
    "...                     data=tips, palette=\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x='net_weights', y='plaqs_diffs', data=data, palette='bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "g = sns.PairGrid(data, hue='net_weights', diag_sharey=False, palette='bright',\n",
    "                 vars=['plaqs_diffs', 'accept_prob', 'tunneling_rate'], )\n",
    "g = g.map_diag(sns.kdeplot, shade=True, gridsize=5)\n",
    "g = g.map_lower(plt.plot, ls='', marker='+', rasterized=True, markeredgewidth=0.1)#, alpha=1.)\n",
    "g = g.map_upper(sns.kdeplot, shade=False, gridsize=5, linewidths=0.7)\n",
    "print(f'{time.time() - t0:.3g}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(data, hue='net_weights', diag_sharey=False, palette='husl')\n",
    "g = g.map_upper(plt.plot, ls='', marker=',', rasterized=True)#, alpha=1.)\n",
    "try:\n",
    "    g = g.map_diag(sns.kdeplot, shade=True, gridsize=100)\n",
    "    g.add_legend()\n",
    "    g = g.map_lower(sns.kdeplot, shade=False, gridsize=50)\n",
    "except:\n",
    "    g = g.map_diag(plt.hist, histtype='step', alpha=0.6, density=True)\n",
    "    g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log_dir in log_dirs:\n",
    "    io.log(f'log_dir: {log_dir}')\n",
    "    run_dirs = sorted(get_run_dirs(log_dir))\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    train_weights = tuple([\n",
    "        int(params[key]) for key in params if any([m in key for m in matches])\n",
    "    ])\n",
    "    train_weights_str = ''.join((str(i) for i in train_weights))\n",
    "    cmap = sns.light_palette(colors[idx], as_cmap=True)\n",
    "    for run_dir in run_dirs:\n",
    "        t1 = time.time()\n",
    "        data, run_params = get_observables(run_dir, n_boot=1000, therm_frac=0.2)\n",
    "        key = tuple([int(i) for i in run_params['net_weights']])\n",
    "        eps = run_params['eps']\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        g = sns.PairGrid(data, hue='net_weights', diag_sharey=False, palette='husl')\n",
    "        g = g.map_upper(plt.plot, ls='', marker=',', rasterized=True)#, alpha=1.)\n",
    "        try:\n",
    "            g = g.map_diag(sns.kdeplot, shade=True, gridsize=100)\n",
    "            g.add_legend()\n",
    "            g = g.map_lower(sns.kdeplot, shade=False, gridsize=50)\n",
    "        except:\n",
    "            g = g.map_diag(plt.hist, histtype='step', alpha=0.6, density=True)\n",
    "            g.add_legend()\n",
    "\n",
    "        # Create title for plot\n",
    "        title_str = (r\"$N_{\\mathrm{LF}} = $\" + f'{lf}, '\n",
    "                     r\"$\\varepsilon = $\"  + f'{eps:.3g}')\n",
    "        if params['clip_value'] > 0:\n",
    "            title_str += f', clip: {clip_value}'\n",
    "        title_str += f', nw: {key}'\n",
    "        g.fig.suptitle(title_str, y=1.02, fontsize='x-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from plotters.plot_utils import bootstrap\n",
    "import shutil\n",
    "import datetime\n",
    "from plotters.plot_utils import load_pkl\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import matplotlib.patches as patches\n",
    "np.set_printoptions(edgeitems=3,infstr='inf',\n",
    "                    linewidth=75, nanstr='nan', precision=8,\n",
    "                    suppress=False, threshold=1000, formatter=None)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "time_str = f'{day_str}_{hour_str}'\n",
    "from config import COLORS\n",
    "\n",
    "colors = 100 * [*COLORS]\n",
    "\n",
    "m1 = ['x', 'v']\n",
    "m2 = ['scale', 'translation', 'transformation']\n",
    "matches = [f'{i}_{j}' for i in m1 for j in m2]\n",
    "\n",
    "t0 = time.time()\n",
    "for idx, log_dir in enumerate(log_dirs):\n",
    "    io.log(f'log_dir: {log_dir}')\n",
    "    run_dirs = sorted(get_run_dirs(log_dir))\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    train_weights = tuple([\n",
    "        int(params[key]) for key in params if any([m in key for m in matches])\n",
    "    ])\n",
    "    train_weights_str = ''.join((str(i) for i in train_weights))\n",
    "    cmap = sns.dark_palette(colors[idx], as_cmap=True)\n",
    "    for run_dir in run_dirs:\n",
    "        t1 = time.time()\n",
    "        data, run_params = get_observables(run_dir, n_boot=1000, therm_frac=0.2)\n",
    "        key = tuple([int(i) for i in run_params['net_weights']])\n",
    "        eps = run_params['eps']\n",
    "        if data is None:\n",
    "            continue\n",
    "        \n",
    "        g = sns.PairGrid(data, diag_sharey=False)\n",
    "        g = g.map_upper(plt.plot, color=colors[idx], ls='', marker=',', rasterized=True)#, alpha=1.)\n",
    "        try:\n",
    "            g = g.map_diag(sns.kdeplot, shade=True, color=colors[idx], gridsize=100)\n",
    "            g = g.map_lower(sns.kdeplot, shade=False, cmap=cmap, Nchunk=5, gridsize=50)\n",
    "        except:\n",
    "            g = g.map_lower(plt.hist, histtype='step', color=colors[idx], alpha=0.6, ec=colors[idx], density=True)\n",
    "            g = g.map_diag(plt.hist, histtype='step', color=colors[idx], alpha=0.6, ec=colors[idx], density=True,)\n",
    "            \n",
    "        # Create title for plot\n",
    "        title_str = (r\"$N_{\\mathrm{LF}} = $\" + f'{lf}, '\n",
    "                     r\"$\\varepsilon = $\"  + f'{eps:.3g}')\n",
    "        if params['clip_value'] > 0:\n",
    "            title_str += f', clip: {clip_value}'\n",
    "        title_str += f', nw: {key}'\n",
    "        g.fig.suptitle(title_str, y=1.02, fontsize='x-large')\n",
    "        \n",
    "        out_dir = os.path.abspath(f'/home/foremans/cooley_figures/pairplots_{time_str}')\n",
    "        if any([tw == 0 for tw in train_weights]):\n",
    "            out_dir = os.path.join(out_dir, f'train_{train_weights_str}')\n",
    "        io.check_else_make_dir(out_dir)\n",
    "        \n",
    "        nw_str = ''.join((str(int(i)) for i in key))\n",
    "        fname = f'lf{lf}_'\n",
    "        if clip_value > 0:\n",
    "            fname += f'clip{int(clip_value)}_'\n",
    "        fname += f'_{nw_str}'\n",
    "\n",
    "        out_file = os.path.join(out_dir, fname + '.png')\n",
    "        if os.path.isfile(out_file):\n",
    "            out_file = os.path.join(out_dir, fname + '_1.png')\n",
    "        io.log(f'  Saving figure to: {out_file}')\n",
    "        g.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "        \n",
    "        if not os.path.isfile(out_file):\n",
    "            plt.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "            \n",
    "        print(f'Time spent plotting: {time.time() - t1:.3g}s.\\n')\n",
    "    print(80*'-' + '\\n')\n",
    "            \n",
    "print(80 * '-' + '\\n\\n')\n",
    "print(f'Time to complete: {time.time() - t0:.4g}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from plotters.plot_utils import bootstrap\n",
    "import shutil\n",
    "import datetime\n",
    "from plotters.plot_utils import load_pkl\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import matplotlib.patches as patches\n",
    "np.set_printoptions(edgeitems=3,infstr='inf',\n",
    "                    linewidth=75, nanstr='nan', precision=8,\n",
    "                    suppress=False, threshold=1000, formatter=None)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "time_str = f'{day_str}_{hour_str}'\n",
    "from config import COLORS\n",
    "\n",
    "colors = 100 * [*COLORS]\n",
    "\n",
    "INFO_STR = None\n",
    "\n",
    "t0 = time.time()\n",
    "for idx, log_dir in enumerate(log_dirs):\n",
    "    io.log(f'log_dir: {log_dir}')\n",
    "    run_dirs = sorted(get_run_dirs(log_dir))[::-1]\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    px = {}\n",
    "    plaqs_diffs = {}\n",
    "    charges = {}\n",
    "\n",
    "    tunneling_rates = {}\n",
    "    tunneling_events = {}\n",
    "    for run_dir in run_dirs:\n",
    "        t1 = time.time()\n",
    "        run_params = load_pkl(os.path.join(run_dir, 'run_params.pkl'))\n",
    "        net_weights = run_params['net_weights']\n",
    "        eps = run_params['eps']\n",
    "        io.log(f'  net_weights: {tuple(net_weights)}')\n",
    "            \n",
    "        px_ = load_pkl(os.path.join(run_dir, 'observables', 'px.pkl'))\n",
    "        px_ = np.squeeze(np.array(px_))\n",
    "        avg_px = np.mean(px_)\n",
    "        if avg_px < 0.1 or tuple(net_weights) not in nw_include:\n",
    "            print(f'  INFO: Skipping {tuple(net_weights)} since <px> = {avg_px}.')\n",
    "            continue\n",
    "        \n",
    "        plaqs = load_pkl(os.path.join(run_dir, 'observables', 'plaqs.pkl'))\n",
    "        dplq = u1_plaq_exact(run_params['beta']) - np.squeeze(np.array(plaqs))\n",
    "        \n",
    "        q = load_pkl(os.path.join(run_dir, 'observables', 'charges.pkl'))\n",
    "        q = np.squeeze(np.array(q))\n",
    "        \n",
    "        px_ = px_[1:]\n",
    "        dplq = dplq[1:]\n",
    "\n",
    "        num_steps = px_.shape[0]\n",
    "        therm_steps = int(0.2 * num_steps)\n",
    "        \n",
    "        q = q[therm_steps:]\n",
    "        px_ = px_[therm_steps:]\n",
    "        dplq = dplq[therm_steps:]\n",
    "\n",
    "        dq, tr = calc_tunneling_rate(q)\n",
    "        dq = dq.T\n",
    "\n",
    "        n_boot = 1000\n",
    "        px_avg, px_err, px_ = bootstrap(px_, n_boot=n_boot)\n",
    "        dplq_avg, dplq_err, dplq_ = bootstrap(dplq, n_boot=n_boot)\n",
    "        dq_avg, dq_err, dq_ = bootstrap(dq, n_boot=n_boot)\n",
    "        \n",
    "        #px_ = px_[:n_boot // 2]\n",
    "        #dplq_ = dplq_[:n_boot // 2]\n",
    "        #dq_ = dq_[:n_boot // 2]\n",
    "\n",
    "        key = tuple(net_weights)\n",
    "        px[key] = px_\n",
    "        plaqs_diffs[key] = dplq_\n",
    "        tunneling_rates[key] = tr\n",
    "        tunneling_events[key] = dq_\n",
    "\n",
    "        data = pd.DataFrame({\n",
    "            'plaqs_diffs': plaqs_diffs[key].flatten(),\n",
    "            'accept_prob': px[key].flatten(),\n",
    "            'tunneling_rate': tunneling_events[key].flatten()\n",
    "        })\n",
    "        g = sns.PairGrid(data)\n",
    "        cmap = sns.dark_palette(colors[idx], as_cmap=True)\n",
    "        try:\n",
    "            g = g.map_diag(sns.kdeplot, shade=True, color=colors[idx], gridsize=100)\n",
    "            g = g.map_lower(sns.kdeplot, shade=False, cmap=cmap, Nchunk=5, gridsize=50)\n",
    "        except:\n",
    "            g = g.map_lower(plt.hist, histtype='step', color=colors[idx], alpha=0.6, ec=colors[idx], density=True)\n",
    "            g = g.map_diag(plt.hist, histtype='step', color=colors[idx], alpha=0.6, ec=colors[idx], density=True)\n",
    "        g = g.map_upper(plt.plot, color=colors[idx], ls='', marker=',', rasterized=True)#, alpha=1.)\n",
    "        #g = g.map_offdiag(plt.plot, color=colors[idx], ls='', marker=',', alpha=0.75)\n",
    "        title_str = (r\"$N_{\\mathrm{LF}} = $\" + f'{lf}, '\n",
    "                     r\"$\\varepsilon = $\"  + f'{eps:.3g}')\n",
    "        if params['clip_value'] > 0:\n",
    "            title_str += f', clip: {clip_value}'\n",
    "        title_str += f', nw: {key}'\n",
    "        g.fig.suptitle(title_str, y=1.02, fontsize='x-large')\n",
    "        \n",
    "        out_dir = os.path.abspath(f'/home/foremans/cooley_figures/pairplots_{time_str}')\n",
    "        if INFO_STR is not None:\n",
    "            out_dir = os.path.join(out_dir, INFO_STR)\n",
    "        io.check_else_make_dir(out_dir)\n",
    "        \n",
    "        nw_str = ''.join((str(i) for i in key))\n",
    "        fname = f'lf{lf}_'\n",
    "        if clip_value > 0:\n",
    "            fname += f'clip{int(clip_value)}_'\n",
    "        fname += f'_{nw_str}'\n",
    "\n",
    "        out_file = os.path.join(out_dir, fname + '.png')\n",
    "        if os.path.isfile(out_file):\n",
    "            out_file = os.path.join(out_dir, fname + '_1.png')\n",
    "        io.log(f'  Saving figure to: {out_file}')\n",
    "        g.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "        \n",
    "        if not os.path.isfile(out_file):\n",
    "            plt.savefig(out_file, dpi=150, bbox_inches='tight')\n",
    "            \n",
    "        print(f'Time spent plotting: {time.time() - t1:.3g}s.\\n')\n",
    "    print(80*'-' + '\\n')\n",
    "            \n",
    "print(80 * '-' + '\\n\\n')\n",
    "print(f'Time to complete: {time.time() - t0:.4g}s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g.fig.axes[0].tick_params.reset=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import bootstrap\n",
    "import shutil\n",
    "import datetime\n",
    "from plotters.plot_utils import load_pkl\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import matplotlib.patches as patches\n",
    "np.set_printoptions(edgeitems=3,infstr='inf',\n",
    "                    linewidth=75, nanstr='nan', precision=8,\n",
    "                    suppress=False, threshold=1000, formatter=None)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "time_str = f'{day_str}_{hour_str}'\n",
    "\n",
    "for log_dir in log_dirs:\n",
    "    io.log(f'log_dir: {log_dir}')\n",
    "    run_dirs = get_run_dirs(log_dir)\n",
    "    plaqs_diffs = get_obs_dict(log_dir, 'plaqs', run_dirs=run_dirs)\n",
    "    px = get_obs_dict(log_dir, 'px', run_dirs=run_dirs)\n",
    "    charges = get_obs_dict(log_dir, 'charges', run_dirs=run_dirs)\n",
    "    px = {k: px[k] for k in nw_include}\n",
    "    charges = {k: charges[k] for k in nw_include}\n",
    "    plaqs_diffs = {k: plaqs_diffs[k] for k in nw_include}\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    lf = params['num_steps']\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "\n",
    "    tunneling_rates = {}\n",
    "    tunneling_events = {}\n",
    "    for key in plaqs_diffs.keys():\n",
    "        io.log(f'  net_weights: {key}')\n",
    "        dplq = np.squeeze(np.array(plaqs_diffs[key]))\n",
    "        px_ = np.squeeze(np.array(px[key]))\n",
    "        q = np.squeeze(np.array(charges[key]))\n",
    "        dq, tr = calc_tunneling_rate(q)\n",
    "        \n",
    "        dq = dq.T\n",
    "        tr = tr[1:]\n",
    "        px_ = px_[1:]\n",
    "        dplq = dplq[1:]\n",
    "\n",
    "        num_steps = px_.shape[0]\n",
    "        therm_steps = int(0.2 * num_steps)\n",
    "        dq = dq[therm_steps:]\n",
    "        tr = tr[therm_steps:]\n",
    "        px_ = px[therm_steps:]\n",
    "        dplq = dplq[therm_steps:]\n",
    "        \n",
    "        px[key] = px_\n",
    "        plaqs_diffs[key] = dplq\n",
    "        tunneling_rates[key] = tr\n",
    "        tunneling_events[key] = dq\n",
    "\n",
    "        #px_avg, px_err, px_ = bootstrap(therm_arr(px[key]), n_boot=1000)\n",
    "        #tr_avg, tr_err, tr_ = bootstrap(therm_arr(tunneling_rates[key]), n_boot=1000)\n",
    "        #dq_avg, dq_err, dq_ = bootstrap(therm_arr(tunneling_events[key]), n_boot=1000)\n",
    "        #plqd_avg, plqd_err, plqd_ = bootstrap(therm_arr(plaqs_diffs[key]), n_boot=1000)\n",
    "\n",
    "        plqd_ = plqd_.flatten()\n",
    "        px_ = px_.flatten()\n",
    "        tr_ = tr_.flatten()\n",
    "        dq_ = dq_.flatten()\n",
    "        data = pd.DataFrame({'plaqs_diffs': plqd_, 'accept_prob': px_, 'tunneling_events': dq_})\n",
    "        try:\n",
    "            g = sns.PairGrid(data)\n",
    "            g = g.map_diag(sns.kde, shade=True, color='C6')\n",
    "            g = g.map_offdiag(plt.plot, color='C6', ls='', marker=',', alpha=0.75)\n",
    "        except:\n",
    "            g = sns.PairGrid(data)\n",
    "            g = g.map_diag(plt.hist, histtype='stepfilled', color='C6')\n",
    "\n",
    "        g = sns.JointGrid(x=plqd_, y=px_, ratio=3) #, space=0)\n",
    "        g = g.plot_joint(plt.plot, color='C0', ls='', marker=',', alpha=0.75)\n",
    "        try:\n",
    "            g = g.plot_marginals(sns.kdeplot, color='C0', shade=True)\n",
    "        except:\n",
    "            g = g.plot_marginals(plt.hist, density=True,\n",
    "                                 histtype='stepfilled',\n",
    "                                 ec='C0', alpha=0.6)\n",
    "\n",
    "        text_str = r\"$N_{\\mathrm{LF}} = $\" + f'{lf}\\n{key}'\n",
    "        if params['clip_value'] > 0:\n",
    "            text_str += f'\\n clip: {clip_value}'\n",
    "\n",
    "\n",
    "        bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.9)\n",
    "        g.fig.text(x=0.19, y=0.15, s=text_str,\n",
    "                   ha='left', va='bottom',\n",
    "                   fontsize='large', bbox=bbox_props)\n",
    "        g.set_axis_labels(xlabel=r\"\"\"$\\delta \\phi_{P}$\"\"\", ylabel=r\"\"\"$A(\\xi|\\xi^{\\prime})$\"\"\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "        #out_dir = os.path.abspath(f'home/foremans/cooley_figures/jointplots_{time_str}')\n",
    "        out_dir = os.path.abspath(f'/home/foremans/cooley_figures/jointplots_{time_str}')\n",
    "        nw_str = ''.join((str(i) for i in key))\n",
    "        io.check_else_make_dir(out_dir)\n",
    "        fname = f'plaqs_diffs_accept_rates_lf{lf}_{nw_str}'\n",
    "        if clip_value > 0:\n",
    "            fname += f'_clip{int(clip_value)}'\n",
    "\n",
    "        out_file = os.path.join(out_dir, fname + '.png')\n",
    "        if os.path.isfile(out_file):\n",
    "            out_file = os.path.join(out_dir, fname + '_1.png')\n",
    "        io.log(f'  Saving figure to: {out_file}')\n",
    "        g.fig.savefig(fname + '.png', dpi=200, bbox_inches='tight')\n",
    "        \n",
    "        g.fig.close()\n",
    "        plt.close('all')\n",
    "        \n",
    "\n",
    "        g = sns.JointGrid(x=plqd_, y=dq_, ratio=3) #, space=0)\n",
    "        g = g.plot_joint(plt.plot, color='C6', ls='', marker=',', alpha=0.75)\n",
    "        try:\n",
    "            g = g.plot_marginals(sns.kdeplot, color='C6', shade=True)\n",
    "        except:\n",
    "            g = g.plot_marginals(sns.distplot, kde=False,\n",
    "                                 density=True,\n",
    "                                 histtype='stepfilled',\n",
    "                                 ec='C6', alpha=0.6)\n",
    "            plt.hist()\n",
    "\n",
    "        g.fig.text(x=0.19, y=0.15, s=text_str,\n",
    "                   ha='left', va='bottom',\n",
    "                   fontsize='large', bbox=bbox_props)\n",
    "        g.set_axis_labels(xlabel=r\"\"\"$\\delta \\phi_{P}$\"\"\", ylabel=r\"\"\"$\\gamma$\"\"\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fname = f'plaqs_diffs_tunneling_rates_lf{lf}_{nw_str}'\n",
    "        if clip_value > 0:\n",
    "            fname += f'_clip{int(clip_value)}'\n",
    "\n",
    "        out_file = os.path.join(out_dir, fname + '.png')\n",
    "        if os.path.isfile(out_file):\n",
    "            out_file = os.path.join(out_dir, fname + '_1.png')\n",
    "        io.log(f'  Saving figure to: {out_file}')\n",
    "        g.fig.savefig(out_file, dpi=200, bbox_inches='tight')\n",
    "        io.log('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = {\n",
    "    'plaqs_diffs': [*plaqs_diffs[(0, 0, 0, 0, 0, 0)].flatten()],\n",
    "    'px': [*px[(0, 0, 0, 0, 0, 0)].flatten()],\n",
    "    'dq': [*tunneling_events[(0, 0, 0, 0, 0, 0)].flatten()],\n",
    "}\n",
    "df = pd.DataFrame(d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df)\n",
    "g.map_diag(sns.kdeplot)\n",
    "g.map_offdiag(sns.kdeplot, n_levels=6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunneling_events[(0, 0, 0, 0, 0, 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key = (1, 1, 1, 1, 1, 1)\n",
    "for key in plaqs_diffs.keys():\n",
    "    print(f'Making jointplot with {key}...')\n",
    "    plqd_avg, plqd_err, plqd_ = bootstrap(therm_arr(plaqs_diffs[key]), n_boot=5000, ci=68)\n",
    "    px_avg, px_err, px_ = bootstrap(therm_arr(px[key]), n_boot=5000)\n",
    "    tr_avg, tr_err, tr_ = bootstrap(therm_arr(tunneling_rates[key]), n_boot=5000)\n",
    "    dq_avg, dq_err, dq_ = bootstrap(therm_arr(tunneling_events[key]), n_boot=5000)\n",
    "\n",
    "    plqd_ = plqd_.flatten()\n",
    "    px_ = px_.flatten()\n",
    "    tr_ = tr_.flatten()\n",
    "    dq_ = dq_.flatten()\n",
    "    #xlim = (plqd_avg - np.min(plqd_), plqd_avg + np.max(plqd_))\n",
    "    #ylim = (px_avg - np.min(px_), px_avg + np.max(px_))\n",
    "\n",
    "    g = sns.JointGrid(x=plqd_, y=dq_, ratio=3) #, space=0)\n",
    "    g = g.plot_joint(plt.scatter, color='C0', alpha=0.75, edgecolor='white')\n",
    "    #g = g.plot_marginals(sns.distplot, kde=True, color='C0')\n",
    "    g = g.plot_marginals(sns.kdeplot, color='C0', shade=True)\n",
    "    g.fig.text(x=0.13, y=0.13, s=f'nw: {key}', fontsize='large')\n",
    "    #g.plot(plt.scatter, sns.kdeplot)\n",
    "    #_ = g.ax_marg_x.hist(px_, color='C6', alpha=0.6,\n",
    "    #                     orientation='horizontal', histtype='stepfilled')\n",
    "    #_ = g.ax_marg_x.hist(plqd_, color='C6', alpha=0.6,\n",
    "    #                     orientation='horizontal', histtype='stepfilled')\n",
    "    g.set_axis_labels(xlabel=r\"\"\"$\\delta \\phi_{P}$\"\"\", ylabel=r\"\"\"$\\gamma$\"\"\")\n",
    "    plt.tight_layout()\n",
    "    #g.fig.suptitle(f'net weights: {key}', y=1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fig.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in plaqs_diffs.keys():\n",
    "    px_ = therm_arr(np.squeeze(px[key]))\n",
    "    dplq_ = therm_arr(np.squeeze(plaqs_diffs[key]))\n",
    "    px_ = np.mean(px_, axis=0)\n",
    "    dplq_ = np.mean(dplq_, axis=0)\n",
    "    \n",
    "    g = sns.jointplot(x=px_,\n",
    "                      y=dplq_)\n",
    "    g = g.plot_joint(plt.scatter, color='gray', edgecolor='white')\n",
    "    _ = g.ax_marg_x.hist(px_, color='C0', alpha=0.6,\n",
    "                         orientation='horizontal', histtype='stepfilled')\n",
    "    _ = g.ax_marg_x.hist(dplq_, color='C1', alpha=0.6,\n",
    "                         orientation='horizontal', histtype='stepfilled')\n",
    "    #g.annotate(key)\n",
    "    \n",
    "    #g = g.plot_marginals(sns.kdeplot, shade=True)\n",
    "\n",
    "    g.set_axis_labels(xlabel=r\"\"\"$\\delta \\phi_{P}$\"\"\", ylabel=r\"\"\"$A(\\xi|\\xi^{\\prime}$\"\"\")\n",
    "    g.fig.suptitle(key, y=1.02)\n",
    "    \n",
    "    #g = sns.jointplot(x=np.array(plaqs_diffs[key]),\n",
    "    #                 y=np.array(tunn_rates[key]))\n",
    "    #g = g.plot_marginals(sns.kdeplot, shade=True)\n",
    "    #g.set_axis_labels(xlabel=r\"\"\"$\\delta \\phi_{P}$\"\"\", ylabel=r\"\"\"$\\gamma$\"\"\")\n",
    "    #g.fig.suptitle(key, y=1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from plotters.plot_utils import load_pkl\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "#plaqs_plot_dir = os.path.join(../g ,'plaqs_plots')\n",
    "#px_plot_dir = os.path.join('.' ,'px_plots')\n",
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "\n",
    "#tunn_rates_plot_dir = os.path.abspath(\n",
    "#    f'../../gauge_logs/tunn_rates_hists_{day_str}_{hour_str}'\n",
    "#)\n",
    "tunn_rates = []\n",
    "plaqs_diffs = []\n",
    "px = []\n",
    "\n",
    "for log_dir in log_dirs:\n",
    "    print(f'Loading from log_dir: \\n  {log_dir}')\n",
    "    run_dirs = get_run_dirs(log_dir, filter_str='steps5000')\n",
    "    try:\n",
    "        tunn_rates_ = get_obs_dict(log_dir, 'tunn_rates', run_dirs)\n",
    "        tunn_rates_ = {k: np.squeeze(np.array(tunn_rates_[k])) for k in nw_include}\n",
    "\n",
    "        plaqs = get_obs_dict(log_dir, 'plaqs', run_dirs)\n",
    "        #plaqs_diffs_  = {\n",
    "        #    k: np.squeeze(np.array(u1_plaq_exact(5.) - plaqs[k])) for k in nw_include\n",
    "        #}\n",
    "        px_ = get_obs_dict(log_dir, 'px', run_dirs)\n",
    "        px_ = {k: np.squeeze(px_[k]) for k in nw_include}\n",
    "        tunn_rates.append(tunn_rates)\n",
    "        plaqs_diffs.append(plaqs_diffs)\n",
    "        px.append(px_)\n",
    "    except KeyError:\n",
    "        continue\n",
    "    #fig, axes = plt.subplots(4, 4)\n",
    "    #axes = axes.flatten()\n",
    "    #for idx, key in plaqs_diffs.keys():\n",
    "    #    ax = axes[idx]\n",
    "    #    plaqs_ = plaqs_diffs[key]\n",
    "    #    px_ = px[key]\n",
    "    #    ax\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def therm_arr(arr, therm_frac=0.2):\n",
    "    step_axis = np.argmax(arr.shape)\n",
    "    num_steps = arr.shape[step_axis]\n",
    "    therm_steps = int(therm_frac * num_steps)\n",
    "    arr = np.delete(arr, np.s_[:therm_steps], axis=step_axis)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "for key in plaqs_diffs.keys():\n",
    "    px_ = therm_arr(np.squeeze(px[key]))\n",
    "    dplq_ = therm_arr(np.squeeze(plaqs_diffs[key]))\n",
    "    px_ = np.mean(px_, axis=0)\n",
    "    dplq_ = np.mean(dplq_, axis=0)\n",
    "    \n",
    "    g = sns.jointplot(x=px_,\n",
    "                      y=dplq_)\n",
    "    g = g.plot_joint(plt.scatter, color='gray', edgecolor='white')\n",
    "    _ = g.ax_marg_x.hist(px_, color='C0', alpha=0.6,\n",
    "                         orientation='horizontal', histtype='stepfilled')\n",
    "    _ = g.ax_marg_x.hist(dplq_, color='C1', alpha=0.6,\n",
    "                         orientation='horizontal', histtype='stepfilled')\n",
    "    #g.annotate(key)\n",
    "    \n",
    "    #g = g.plot_marginals(sns.kdeplot, shade=True)\n",
    "\n",
    "    g.set_axis_labels(xlabel=r\"\"\"$\\delta \\phi_{P}$\"\"\", ylabel=r\"\"\"$A(\\xi|\\xi^{\\prime}$\"\"\")\n",
    "    g.fig.suptitle(key, y=1.02)\n",
    "    \n",
    "    #g = sns.jointplot(x=np.array(plaqs_diffs[key]),\n",
    "    #                 y=np.array(tunn_rates[key]))\n",
    "    #g = g.plot_marginals(sns.kdeplot, shade=True)\n",
    "    #g.set_axis_labels(xlabel=r\"\"\"$\\delta \\phi_{P}$\"\"\", ylabel=r\"\"\"$\\gamma$\"\"\")\n",
    "    #g.fig.suptitle(key, y=1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = log_dirs[0]\n",
    "px_ = np.array(px[0][(1, 1, 1, 1, 1, 1)])\n",
    "px_.shape\n",
    "dplq_ = np.array(plaqs_diffs[0][(1, 1, 1, 1, 1, 1)])\n",
    "dplq_.shape\n",
    "tr_ = np.array(tunn_rates[0][(1, 1, 1, 1, 1, 1)])\n",
    "\n",
    "g = sns.jointplot(px_, dplq_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from plotters.plot_utils import load_pkl\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "#plaqs_plot_dir = os.path.join(../g ,'plaqs_plots')\n",
    "#px_plot_dir = os.path.join('.' ,'px_plots')\n",
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "\n",
    "tunn_rates_plot_dir = os.path.abspath(\n",
    "    f'../../gauge_logs/tunn_rates_hists_{day_str}_{hour_str}'\n",
    ")\n",
    "\n",
    "for log_dir in log_dirs:\n",
    "    run_dirs = get_run_dirs(log_dir, filter_str='steps5000')\n",
    "    tunn_rates = get_obs_dict(log_dir, 'tunn_rates', run_dirs)\n",
    "    tunn_rates = {k: tunn_rates[k] for k in nw_include}\n",
    "\n",
    "    fig, axes = grid_plot(log_dir=log_dir,\n",
    "                          obs_dict=tunn_rates,\n",
    "                          run_dirs=run_dirs,\n",
    "                          out_dir=tunn_rates_plot_dir,\n",
    "                          obs_name='tunneling rate',\n",
    "                          filter_str='steps5000',\n",
    "                          plot_type='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotters.plot_utils import load_pkl\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import scipy\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsOrig)\n",
    "#sns.set()\n",
    "sns.set_context('notebook')\n",
    "mpl.rcParams.update(mpl.rcParamsOrig)\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "sns.set_palette('bright')\n",
    "sns.set_style('ticks')\n",
    "sns.set(mpl.rcParamsOrig)\n",
    "sns.set(mpl.rcParamsDefault)\n",
    "#sns.set_style('whitegrid')\n",
    "\n",
    "sem = scipy.stats.sem\n",
    "tunneling_rates_ = {}\n",
    "plaq_diffs_ = {}\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "day_str = now.strftime('%Y_%m_%d')\n",
    "hour_str = now.strftime('%H%M')\n",
    "\n",
    "data = {}\n",
    "for idx, log_dir in enumerate(log_dirs):\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    run_dirs = sorted(get_run_dirs(log_dir, filter_str='steps5000'))\n",
    "\n",
    "    plaqs_diffs_dict = {}\n",
    "    dq_dict = {}\n",
    "    tunn_rates_dict = {}\n",
    "    run_dirs_dict = {}\n",
    "    tr_arr = []\n",
    "    tr_err = []\n",
    "    dq_arr = []\n",
    "    pld_arr = []\n",
    "    pld_err = []\n",
    "    #for idx, (k ,v) in enumerate(charges.items()):\n",
    "    \n",
    "    for run_dir in run_dirs:\n",
    "        #run_dir = run_dirs[idx]\n",
    "        px = np.squeeze(np.array(load_pkl(os.path.join(run_dir, 'observables', 'px.pkl'))))\n",
    "        if np.mean(px) > 0.1:\n",
    "            run_params = load_pkl(os.path.join(run_dir, 'run_params.pkl'))\n",
    "            nw = tuple(run_params['net_weights'])\n",
    "            plaqs = np.squeeze(np.array(load_pkl(os.path.join(run_dir, 'observables', 'plaqs.pkl'))))\n",
    "            charges = np.squeeze(np.array(load_pkl(os.path.join(run_dir, 'observables', 'charges.pkl'))))\n",
    "            num_steps = plaqs.shape[0]\n",
    "            therm_steps = int(0.2 * num_steps)\n",
    "            plaqs = plaqs[therm_steps:]\n",
    "            charges = charges[therm_steps:]\n",
    "\n",
    "            pld = plaqs - u1_plaq_exact(run_params['beta'])\n",
    "            dq, tr = calc_tunneling_rate(charges)\n",
    "\n",
    "            dq_dict[nw] = dq\n",
    "            tunn_rates_dict[nw] = tr\n",
    "            plaqs_diffs_dict[nw] = pld\n",
    "            run_dirs_dict[nw] = run_dir\n",
    "\n",
    "            tr_arr.append(np.mean(tr))\n",
    "            tr_err.append(np.std(tr))\n",
    "            dq_arr.append(np.mean(dq))\n",
    "            pld_arr.append(np.mean(pld))\n",
    "            pld_err.append(np.std(pld))\n",
    "\n",
    "        '''\n",
    "        out_file = os.path.join(run_dir, 'observables', 'plaqs_diffs.pkl')\n",
    "        #print(f'Saving pld to: {out_file}.')\n",
    "        with open(out_file, 'wb') as f:\n",
    "            pickle.dump(pld, f)\n",
    "\n",
    "        out_file = os.path.join(run_dir, 'observables', 'dq.pkl')\n",
    "        #print(f'Saving dq to: {out_file}.')\n",
    "        with open(out_file, 'wb') as f:\n",
    "            pickle.dump(dq, f)\n",
    "\n",
    "        out_file = os.path.join(run_dir, 'observables', 'tunn_rates.pkl')\n",
    "        #print(f'Saving tr to: {out_file}.')\n",
    "        with open(out_file, 'wb') as f:\n",
    "            pickle.dump(tr, f)\n",
    "        '''\n",
    "            \n",
    "    dq_arr = np.array(dq_arr)\n",
    "    tr_arr = np.array(tr_arr)\n",
    "    tr_err = np.array(tr_err)\n",
    "    pld_arr = np.array(pld_arr)\n",
    "    pld_err = np.array(pld_err)\n",
    "    \n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    lf = params['num_steps']\n",
    "    data[(lf, clip_value)] = {\n",
    "        'dq': dq_dict,\n",
    "        'run_dirs': run_dirs_dict,\n",
    "        'tunn_rates': tunn_rates_dict,\n",
    "        'plaqs_diffs': plaqs_diffs_dict,\n",
    "        'plaqs_diffs_stats': (pld_arr, pld_err),\n",
    "        'tunn_rates_stats': (tr_arr, tr_err),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    label = f\"lf: {params['num_steps']}\"\n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    if clip_value > 0:\n",
    "        label += f'clip: {int(clip_value)}'\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "        \n",
    "    _ = ax.errorbar(pld_arr, tr_arr,\n",
    "                    xerr=pld_err/params['batch_size'],\n",
    "                    yerr=tr_err/params['batch_size'],\n",
    "                    label=label, ls='', alpha=0.5,\n",
    "                    ecolor=colors[idx], color=colors[idx])\n",
    "    _ = ax.scatter(pld_arr, tr_arr, marker='.', color=colors[idx], zorder=10)\n",
    "    \n",
    "    title_str = get_title_str(params, eps=run_params['eps'], \n",
    "                              beta=run_params['beta'], nw_legend=False)\n",
    "    _ = ax.set_title(title_str) #, fontsize='x-large')\n",
    "    #xlabel = (r\"$\\langle\\phi_{\\mathrm{P}}\\rangle \"\n",
    "    #          r\"- \\phi_{\\mathrm{P}}^{*}$\")\n",
    "    xlabel = r\"\"\"$\\delta \\phi_{P}$\"\"\"\n",
    "    _ = ax.set_xlabel(xlabel) #, fontsize=14)\n",
    "    _ = ax.set_ylabel(r\"\"\"$\\gamma$\"\"\") #, fontsize=14)\n",
    "    #_ = ax.figure.autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    log_dir_str = log_dir.split('/')[-1]\n",
    "    gld = os.path.abspath('../../gauge_logs/')\n",
    "    lf_str = f\"lf{params['num_steps']}\"\n",
    "    out_dir = os.path.join(gld, f'tunneling_rates_{day_str}_{hour_str}')\n",
    "    #out_dir = os.path.join(', 'tunneling_rates_vs_plaq_diffs', log_dir_str)\n",
    "    #out_dir = os.path.join(log_dir, 'figures')\n",
    "    io.check_else_make_dir(out_dir)\n",
    "    fname = f\"tunn_rate_vs_bias_lf{params['num_steps']}\"\n",
    "    \n",
    "    clip_value = params.get('clip_value', 0)\n",
    "    if clip_value > 0:\n",
    "        fname += f'_clip{int(clip_value)}'\n",
    "        \n",
    "    #_ = ax.legend(loc='best')\n",
    "        \n",
    "    out_file = os.path.join(out_dir, fname + '.png')\n",
    "    #all_file = os.path.join(out_dir, fname + '_all.png')\n",
    "    print(f'Saving figure to: {out_file}.')\n",
    "    plt.savefig(out_file, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors_dict = {\n",
    "    1: 'C0',\n",
    "    2: 'C1',\n",
    "    3: 'C2',\n",
    "    4: 'C3',\n",
    "    5: 'C4'\n",
    "}\n",
    "for idx, (key, val) in enumerate(data.items()):\n",
    "    lf, clip_value = key\n",
    "    pld_avg, pld_err = val['plaqs_diffs_stats']\n",
    "    tr_avg, tr_err = val['tunn_rates_stats']\n",
    "    tr_avg = np.mean(tr_avg)\n",
    "    tr_err = np.mean(tr_err)\n",
    "    pld_avg = np.mean(pld_avg)\n",
    "    pld_err = np.mean(pld_err)\n",
    "    if clip_value > 0:\n",
    "        label = r\"\"\"$N_{\\mathrm{LF}}^{*} = $\"\"\" + f'{lf}'\n",
    "        marker = 's'\n",
    "        fillstyle='none'\n",
    "    else:\n",
    "        label = r\"\"\"$N_{\\mathrm{LF}} = $\"\"\" + f'{lf}'\n",
    "        marker = 'o'\n",
    "        fillstyle='full'\n",
    "        \n",
    "    _ = ax.errorbar(pld_avg, tr_avg, xerr=pld_err, yerr=tr_err,\n",
    "                    ls='', ecolor=colors_dict[lf], color=colors_dict[lf], alpha=0.5)\n",
    "    _ = ax.plot(pld_avg, tr_avg, label=label, marker=marker,\n",
    "                ls='', fillstyle=fillstyle, color=colors_dict[lf], zorder=10)\n",
    "    \n",
    "    #title_str = get_title_str(params, eps=run_params['eps'], beta=run_params['beta'], nw_legend=False)\n",
    "    #_ = ax.set_title(title_str, fontsize='x-large')\n",
    "    xlabel = (r\"$\\langle\\phi_{\\mathrm{P}}\\rangle \"\n",
    "              r\"- \\phi_{\\mathrm{P}}^{*}$\")\n",
    "    _ = ax.set_xlabel(xlabel, fontsize=14)\n",
    "    _ = ax.set_ylabel('tunneling rate', fontsize=14)\n",
    "    #ylim = ax.get_ylim()\n",
    "    #_ = ax.set_ylim((ylim[0], 0.010))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #log_dir_str = log_dir.split('/')[-1]\n",
    "    out_dir = os.path.join('.', 'tunneling_rates_vs_plaq_diffs')\n",
    "    io.check_else_make_dir(out_dir)\n",
    "    fname = f'tunneling_rate_vs_plaq_diff_all'\n",
    "    \n",
    "    _ = ax.legend(loc='best', ncol=2, fontsize='small')\n",
    "        \n",
    "out_file = os.path.join(out_dir, fname + '.png')\n",
    "#all_file = os.path.join(out_dir, fname + '_all.png')\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "plt.savefig(out_file, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors_dict = {\n",
    "    1: 'C0',\n",
    "    2: 'C1',\n",
    "    3: 'C2',\n",
    "    4: 'C3',\n",
    "    5: 'C4'\n",
    "}\n",
    "for idx, (key, val) in enumerate(data.items()):\n",
    "    lf, clip_value = key\n",
    "    pld_avg, pld_err = val['plaqs_diffs_stats']\n",
    "    tr_avg, tr_err = val['tunn_rates_stats']\n",
    "    tr_avg = np.mean(tr_avg)\n",
    "    tr_err = np.mean(tr_err)\n",
    "    pld_avg = np.mean(pld_avg)\n",
    "    pld_err = np.mean(pld_err)\n",
    "    if clip_value > 0:\n",
    "        label = r\"\"\"$N_{\\mathrm{LF}}^{*} = $\"\"\" + f'{lf}'\n",
    "        marker = 's'\n",
    "        fillstyle='none'\n",
    "    else:\n",
    "        label = r\"\"\"$N_{\\mathrm{LF}} = $\"\"\" + f'{lf}'\n",
    "        marker = 'o'\n",
    "        fillstyle='full'\n",
    "        \n",
    "    _ = ax.errorbar(pld_avg, tr_avg, xerr=pld_err, yerr=tr_err,\n",
    "                    ls='', ecolor=colors_dict[lf], color=colors_dict[lf], alpha=0.5)\n",
    "    _ = ax.plot(pld_avg, tr_avg, label=label, marker=marker,\n",
    "                ls='', fillstyle=fillstyle, color=colors_dict[lf], zorder=10)\n",
    "    \n",
    "    #title_str = get_title_str(params, eps=run_params['eps'], beta=run_params['beta'], nw_legend=False)\n",
    "    #_ = ax.set_title(title_str, fontsize='x-large')\n",
    "    xlabel = (r\"$\\langle\\phi_{\\mathrm{P}}\\rangle \"\n",
    "              r\"- \\phi_{\\mathrm{P}}^{*}$\")\n",
    "    _ = ax.set_xlabel(xlabel, fontsize=14)\n",
    "    _ = ax.set_ylabel('tunneling rate', fontsize=14)\n",
    "    ylim = ax.get_ylim()\n",
    "    _ = ax.set_ylim((ylim[0], 0.010))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #log_dir_str = log_dir.split('/')[-1]\n",
    "    out_dir = os.path.join('.', 'tunneling_rates_vs_plaq_diffs')\n",
    "    io.check_else_make_dir(out_dir)\n",
    "    fname = f'tunneling_rate_vs_plaq_diff_all'\n",
    "    \n",
    "    _ = ax.legend(loc='best', ncol=2, fontsize='small')\n",
    "        \n",
    "out_file = os.path.join(out_dir, fname + '_zoom.png')\n",
    "#all_file = os.path.join(out_dir, fname + '_all.png')\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "plt.savefig(out_file, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6.4 + 0.45, 4.8)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "colors_dict = {\n",
    "    1: 'C0',\n",
    "    2: 'C1',\n",
    "    3: 'C2',\n",
    "    4: 'C3',\n",
    "    5: 'C4'\n",
    "}\n",
    "for idx, (key, val) in enumerate(data.items()):\n",
    "    lf, clip_value = key\n",
    "    pld_avg, pld_err = val['plaqs_diffs_stats']\n",
    "    tr_avg, tr_err = val['tunn_rates_stats']\n",
    "    tr_avg = np.mean(tr_avg)\n",
    "    tr_err = np.mean(tr_err)\n",
    "    pld_avg = np.mean(pld_avg)\n",
    "    pld_err = np.mean(pld_err)\n",
    "    if clip_value > 0:\n",
    "        label = r\"\"\"$N_{\\mathrm{LF}}^{*} = $\"\"\" + f'{lf}'\n",
    "        marker = 's'\n",
    "        fillstyle='none'\n",
    "    else:\n",
    "        label = r\"\"\"$N_{\\mathrm{LF}} = $\"\"\" + f'{lf}'\n",
    "        marker = 'o'\n",
    "        fillstyle='full'\n",
    "        \n",
    "    _ = ax.errorbar(pld_avg, tr_avg, xerr=pld_err, yerr=tr_err,\n",
    "                    ls='', ecolor=colors_dict[lf], color=colors_dict[lf], alpha=0.5)\n",
    "    _ = ax.plot(pld_avg, tr_avg, label=label, marker=marker,\n",
    "                ls='', fillstyle=fillstyle, color=colors_dict[lf], zorder=10)\n",
    "    \n",
    "    #title_str = get_title_str(params, eps=run_params['eps'], beta=run_params['beta'], nw_legend=False)\n",
    "    #_ = ax.set_title(title_str, fontsize='x-large')\n",
    "    xlabel = (r\"$\\langle\\phi_{\\mathrm{P}}\\rangle \"\n",
    "              r\"- \\phi_{\\mathrm{P}}^{*}$\")\n",
    "    _ = ax.set_xlabel(xlabel, fontsize=14)\n",
    "    _ = ax.set_ylabel('tunneling rate', fontsize=14)\n",
    "    ylim = ax.get_ylim()\n",
    "    _ = ax.set_ylim((ylim[0], 0.010))\n",
    "    xlim = ax.get_xlim()\n",
    "    _ = ax.set_xlim((-0.125, 0.04))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #log_dir_str = log_dir.split('/')[-1]\n",
    "    out_dir = os.path.join('.', 'tunneling_rates_vs_plaq_diffs')\n",
    "    io.check_else_make_dir(out_dir)\n",
    "    fname = f'tunneling_rate_vs_plaq_diff_all'\n",
    "    \n",
    "    #_ = ax.legend(fontsize='small',  ncol=1, bbox_to_anchor=(1.4, 1))\n",
    "    _ = ax.legend(loc='best', ncol=2, fontsize='small')\n",
    "        \n",
    "out_file = os.path.join(out_dir, fname + '_zoom1.png')\n",
    "#all_file = os.path.join(out_dir, fname + '_all.png')\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "plt.savefig(out_file, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6.4 + 0.45, 4.8)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize, )\n",
    "for idx, (key, val) in enumerate(data.items()):\n",
    "    lf, clip_value = key\n",
    "    pld_avg, pld_err = val['plaqs_diffs_stats']\n",
    "    tr_avg, tr_err = val['tunn_rates_stats']\n",
    "    tr_avg = np.mean(tr_avg)\n",
    "    tr_err = np.mean(tr_err)\n",
    "    pld_avg = np.mean(pld_avg)\n",
    "    pld_err = np.mean(pld_err)\n",
    "    label = r\"\"\"$N_{\\mathrm{LF}} = $\"\"\" + f'{lf}'\n",
    "    if clip_value > 0:\n",
    "        label += f' clip: {clip_value}'\n",
    "        \n",
    "    _ = ax.errorbar(pld_avg, tr_avg, xerr=pld_err, yerr=tr_err, label=label,\n",
    "                    ls='', ecolor=colors[idx], color=colors[idx], alpha=0.5)\n",
    "    _ = ax.scatter(pld_avg, tr_avg, marker='.', color=colors[idx], zorder=10)\n",
    "    \n",
    "    #title_str = get_title_str(params, eps=run_params['eps'], beta=run_params['beta'], nw_legend=False)\n",
    "    #_ = ax.set_title(title_str, fontsize='x-large')\n",
    "    xlabel = (r\"$\\langle\\phi_{\\mathrm{P}}\\rangle \"\n",
    "              r\"- \\phi_{\\mathrm{P}}^{*}$\")\n",
    "    _ = ax.set_xlabel(xlabel, fontsize=14)\n",
    "    _ = ax.set_ylabel('tunneling rate', fontsize=14)\n",
    "    ylim = ax.get_ylim()\n",
    "    _ = ax.set_ylim((ylim[0], 0.010))\n",
    "    xlim = ax.get_xlim()\n",
    "    _ = ax.set_xlim((-0.125, 0.04))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #log_dir_str = log_dir.split('/')[-1]\n",
    "    out_dir = os.path.join('.', 'tunneling_rates_vs_plaq_diffs')\n",
    "    io.check_else_make_dir(out_dir)\n",
    "    fname = f'tunneling_rate_vs_plaq_diff_all'\n",
    "    \n",
    "    _ = ax.legend(fontsize='small',  ncol=1, bbox_to_anchor=(1.4, 1))\n",
    "        \n",
    "out_file = os.path.join(out_dir, fname + '_zoom1.png')\n",
    "#all_file = os.path.join(out_dir, fname + '_all.png')\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "plt.savefig(out_file, dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_observables import grid_plot, get_obs_dict\n",
    "import utils.file_io as io\n",
    "\n",
    "out_dir = os.path.abspath('../../gauge_logs/figures_2019_12_17/tunneling_rates')\n",
    "#out_dir = os.path.join('.', 'tunneling_rate_plots')\n",
    "io.check_else_make_dir(out_dir)\n",
    "\n",
    "for log_dir in log_dirs:\n",
    "    charges = get_obs_dict(log_dir, 'charges')\n",
    "    qdict = {k: np.array(v)[0] for k, v in charges.items()} \n",
    "    dq_dict = {}\n",
    "    tr_dict = {}\n",
    "    tr_tot_dict = {}\n",
    "\n",
    "    for key, val in qdict.items():\n",
    "        dq, tr = calc_tunneling_rate(val)\n",
    "        dq_dict[key] = dq\n",
    "        tr_dict[key] = tr\n",
    "        tr_tot_dict[key] = dq.sum(axis=1)\n",
    "\n",
    "\n",
    "    grid_plot(log_dir, obs_dict=tr_dict, therm_frac=0, \n",
    "              obs_name='tunneling_rate', axis=1, plot_type='hist', \n",
    "              filter_str='steps5000', stats=False, out_dir=out_dir)\n",
    "\n",
    "    #grid_plot(log_dir, obs_dict=dq_dict, therm_frac=0., \n",
    "    #          obs_name='dq_all', axis=1, plot_type='hist', \n",
    "    #          filter_str='steps5000', stats=False, out_dir=out_dir)\n",
    "\n",
    "    #grid_plot(log_dir, obs_dict=tr_tot_dict, therm_frac=0., \n",
    "    #          obs_name='tr_tot', axis=1, plot_type='hist', \n",
    "    #          filter_str='steps5000', stats=False, out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_observables import grid_plot\n",
    "\n",
    "log_dir = log_dirs[0]\n",
    "charges = get_obs_dict(log_dir, 'charges')\n",
    "qdict = {k: np.array(v)[0] for k, v in charges.items()} \n",
    "dq_dict = {}\n",
    "tr_dict = {}\n",
    "tr_tot_dict = {}\n",
    "\n",
    "for key, val in qdict.items():\n",
    "    dq, tr = calc_tunneling_rate(val)\n",
    "    dq_dict[key] = dq\n",
    "    tr_dict[key] = tr\n",
    "    tr_tot_dict[key] = dq.sum(axis=1)\n",
    "\n",
    "\n",
    "grid_plot(log_dir, obs_dict=tr_dict, therm_frac=0, \n",
    "          obs_name='tr', axis=1, plot_type='hist', \n",
    "          filter_str='steps5000', stats=False, out_dir='./testing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
