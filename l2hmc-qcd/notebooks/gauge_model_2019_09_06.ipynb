{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GaugeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from collections import namedtuple\n",
    "\n",
    "#from models.model import GaugeModel\n",
    "#from models.gauge_model import GaugeModel\n",
    "from loggers.train_logger import TrainLogger\n",
    "from loggers.run_logger import RunLogger\n",
    "from trainers.gauge_model_trainer import GaugeModelTrainer\n",
    "from plotters.gauge_model_plotter import GaugeModelPlotter\n",
    "from plotters.leapfrog_plotters import LeapfrogPlotter\n",
    "from runners.runner import GaugeModelRunner\n",
    "from main import create_config, train_setup\n",
    "from params.gauge_params import GAUGE_PARAMS\n",
    "#from config import PARAMS\n",
    "import utils.file_io as io\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "np.set_printoptions(precision=5)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gauge_model import GaugeModel\n",
    "from loggers.train_logger import TrainLogger\n",
    "from main import create_config\n",
    "from config import NP_FLOAT\n",
    "\n",
    "print(f'GAUGE_PARAMS:\\n')\n",
    "_ = [print(f'  {k}: {v}') for k, v in GAUGE_PARAMS.items()]\n",
    "\n",
    "params, hooks = train_setup(GAUGE_PARAMS, log_file=None)\n",
    "model = GaugeModel(params)\n",
    "\n",
    "train_logger = TrainLogger(model, params['log_dir'],\n",
    "                           logging_steps=10, summaries=params['summaries'])\n",
    "\n",
    "config, params = create_config(params)\n",
    "net_weights_init = [1., 1., 1.]\n",
    "samples_init = np.reshape(np.array(model.lattice.samples, dtype=NP_FLOAT),\n",
    "                          (model.batch_size, model.x_dim))\n",
    "beta_init = model.beta_init\n",
    "\n",
    "checkpoint_dir = os.path.join(model.log_dir, 'checkpoints')\n",
    "io.check_else_make_dir(checkpoint_dir)\n",
    "\n",
    "sess_kwargs = {\n",
    "    'checkpoint_dir': checkpoint_dir,\n",
    "    'hooks': hooks,\n",
    "    'config': config,\n",
    "    'save_summaries_secs': None,\n",
    "    'save_summaries_steps': None,\n",
    "}\n",
    "\n",
    "global_var_init = tf.global_variables_initializer()\n",
    "local_var_init = tf.local_variables_initializer()\n",
    "uninited = tf.report_uninitialized_variables()\n",
    "\n",
    "sess = tf.train.MonitoredTrainingSession(**sess_kwargs)\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "trainer = GaugeModelTrainer(sess, model, logger=train_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.ones(model.x.shape)\n",
    "plaqs_hot = sess.run(model.plaqs_op, feed_dict={model.x: samples})\n",
    "np.mean(plaqs_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {\n",
    "    'samples_np': samples,\n",
    "    'beta_np': beta_init,\n",
    "    'net_weights': net_weights_init,\n",
    "    'print_steps': 1.,\n",
    "}\n",
    "\n",
    "trainer.train(1000, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore trained model and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loggers.run_logger import RunLogger\n",
    "from plotters.gauge_model_plotter import GaugeModelPlotter\n",
    "from runners.runner import GaugeModelRunner\n",
    "from inference.gauge_inference_utils import create_config\n",
    "\n",
    "#ld = ('../../logs/2019_09_16/2019_09_16_0552/'\n",
    "#      'lattice8_batch128_lf10_qw00_aw10_generic_dp00/')\n",
    "ld = '../../gauge_logs/2019_10_11/lattice8_batch128_lf5_qw00_aw10_generic_dp05_1324/'\n",
    "log_dir = os.path.join(*ld.split('/'))\n",
    "params_file = os.path.join(log_dir, 'parameters.pkl')\n",
    "with open(params_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    \n",
    "checkpoint_dir = os.path.join(log_dir, 'checkpoints/')\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.import_meta_graph(f'{checkpoint_file}.meta')\n",
    "saver.restore(sess, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_inference import initialize_uninitialized\n",
    "_ = initialize_uninitialized(sess)\n",
    "run_ops = tf.get_collection('run_ops')\n",
    "inputs = tf.get_collection('inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logger  = RunLogger(params, inputs, run_ops, save_lf_data=False)\n",
    "plotter = GaugeModelPlotter(params, run_logger.figs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in run_logger.run_ops_dict.items():\n",
    "    print(f'{key}: {val}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.gauge_inference_utils import inference_setup\n",
    "kwargs = {\n",
    "    'loop_net_weights': False,\n",
    "    'loop_transl_weights': False,\n",
    "    'beta': 5.,\n",
    "}\n",
    "inference_dict = inference_setup(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = GaugeModelRunner(sess, params, inputs, run_ops, run_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_inference import run_inference\n",
    "\n",
    "x_dim = params['space_size'] * params['time_size'] * params['dim']\n",
    "samples_shape = (params['batch_size'], x_dim)\n",
    "inference_dict['samples_init'] = np.ones(samples_shape)\n",
    "inference_dict['beta'] = 5.\n",
    "run_inference(runner, run_logger, plotter, **inference_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Optimize for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inference import create_config\n",
    "\n",
    "ld1 = ('../../logs/2019_08_27/2019_08_27_0457/'\n",
    "       'lattice8_batch100_lf10_qw00_aw10_generic_dp00')\n",
    "log_dir1 = os.path.join(*ld1.split('/'))\n",
    "\n",
    "params_file = os.path.join(log_dir1, 'parameters.pkl')\n",
    "with open(params_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    \n",
    "checkpoint_dir = os.path.join(log_dir1, 'checkpoints')\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "config, params = create_config(params)\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.import_meta_graph(f'{checkpoint_file}.meta')\n",
    "saver.restore(sess, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_ops = tf.get_collection('run_ops', )\n",
    "inputs = tf.get_collection('inputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_nodes = [node.name for node in tf.get\n",
    "node_names = [node.name for node in tf.get_default_graph().as_graph_def().node]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_node_names = [op for op in run_ops if op in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_op_names = []\n",
    "for op in run_ops:\n",
    "    _name = op.name.split('/')\n",
    "    name = ('/').join(_name[:-1])\n",
    "    run_op_names.append(name)\n",
    "    \n",
    "run_op_names1 = [op.name for op in run_ops]\n",
    "_run_op_names = (', \\n').join(run_op_names)\n",
    "_run_op_names1 = (', \\n').join(run_op_names1)\n",
    "print(_run_op_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(_run_op_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_names = 'sampler/x_update/x_out,sampler/x_update/accept_prob,observables/actions,observables/plaqs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "     checkpoint_file = kwargs.get('checkpoint_file', None)\n",
    "    restore_op_name = kwargs.get('restore_op_name', 'save/restore_all')\n",
    "    filename_tensor = kwargs.get('filename_tensor', 'save/Const:0')\n",
    "\n",
    "    if checkpoint_file is None:\n",
    "        checkpoint_dir = os.path.dirname(input_graph)\n",
    "        checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "    #  freeze_graph.freeze_graph('tensorflowModel.pbtxt', \"\", False,\n",
    "    #                            './tensorflowModel.ckpt', \"output/softmax\",\n",
    "    #                             \"save/restore_all\", \"save/Const:0\",\n",
    "    #                             'frozentensorflowModel.pb', True, \"\")\n",
    "\n",
    "    freeze_graph.freeze_graph(\n",
    "        input_graph=input_graph,\n",
    "        input_saver=\"\",\n",
    "        input_binary=False,  # True: `.pb` file; False: `.pbtxt` file\n",
    "        input_checkpoint=checkpoint_file,\n",
    "        output_node_names=output_node_names,\n",
    "        restore_op_name=restore_op_name,\n",
    "        filename_tensor=filename_tensor,\n",
    "        output_graph=output_graph,\n",
    "        clear_devices=True,\n",
    "        initializer_nodes=\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import optimize_for_inference_lib, freeze_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import optimize_for_inference_lib, freeze_graph\n",
    "\n",
    "input_graph = os.path.join(checkpoint_dir, 'graph.pbtxt')\n",
    "output_graph = os.path.join(checkpoint_dir, 'frozen_graph.pb')\n",
    "\n",
    "restore_op_name = 'save/restore_all'\n",
    "filename_tensor = 'save/Const:0'\n",
    "freeze_graph.freeze_graph(\n",
    "    input_graph=input_graph,\n",
    "    input_saver='',\n",
    "    input_binary=False,\n",
    "    input_checkpoint=checkpoint_file,\n",
    "    output_node_names=_names,\n",
    "    restore_op_name='save/restore_all',\n",
    "    filename_tensor_name='save/Const:0',\n",
    "    output_graph=output_graph,\n",
    "    clear_devices=True,\n",
    "    initializer_nodes=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keys = ['x_out', 'px', 'actions_op', 'plaqs_op', 'avg_plaqs_op', 'charges_op', 'charge_diffs_op', 'eps']\n",
    "_keys = (',').join(keys)\n",
    "node_names = [node.name for node in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "node_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_node_names = [i for i in node_names if '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_names = [op.name for op in inputs]\n",
    "input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "python -m tensorflow.python.tools.freeze_graph --input_graph graph.pb --input_checkpoint test_model --output_graph graph_frozen.pb --output_node_names=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_in_names = (', ').join(input_names)\n",
    "_in_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_graph = os.path.join(checkpoint_dir, 'graph.pbtxt')\n",
    "input_checkpoint = os.path.join(checkpoint_dir, 'model')\n",
    "output_graph = os.path.join(checkpoint_dir, 'graph_frozen.pb')\n",
    "output_node_names = (', ').join(run_op_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%python3 -m tensorflow.python.tools.freeze_graph \\ \n",
    "    --input_graph=input_graph \\\n",
    "    --output_graph=output_graph \\\n",
    "    --output_node_names=output_node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimized_graph = os.path.join(checkpoint_dir, 'optimized_graph.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print((',').join(run_op_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(', \\n').join(input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "    --input input_graph \\\n",
    "    --output_graph optimized_graph \\\n",
    "    --input_names (', ').join(input_names) \\\n",
    "    --output_names (', ').join(run_op_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "python -m tensorflow.python.tools.optimize_for_inference --input graph_frozen.pb --output graph_optimized.pb --input_names=x --output_names=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!spython3 -m tensorflow.python.tools.optimizer_for_inference --input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plot $\\langle \\delta_{\\phi_{P}}\\rangle$ vs. net_weights_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ld1 = ('../../logs/2019_08_27/2019_08_27_0457/'\n",
    "       'lattice8_batch100_lf10_qw00_aw10_generic_dp00')\n",
    "log_dir1 = os.path.join(*ld1.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ld2 = ('../../logs/2019_08_27/2019_08_27_1314/'\n",
    "       'lattice8_batch100_lf16_qw00_aw10_generic_dp00')\n",
    "log_dir2 = os.path.join(*ld2.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ld3 = ('../../logs/cooley_logs/2019_08_28/2019_08_28_0213/'\n",
    "       'lattice8_batch128_lf16_qw00_aw10_generic_dp00')\n",
    "log_dir3 = os.path.join(*ld3.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ld4 = ('../../logs/2019_08_28/2019_08_28_1244/'\n",
    "       'lattice8_batch100_lf16_qw00_aw10_generic_dp00')\n",
    "log_dir4 = os.path.join(*ld4.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig4, ax4 = plot_plaq_diffs_vs_net_weights(log_dir4, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plaq_diff_txt_file = os.path.join(log_dir4, 'plaq_diffs_data.txt')\n",
    "_data = pd.read_csv(plaq_diff_txt_file, header=None)\n",
    "pdd = _data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zero_data = pdd[0]\n",
    "stq_data = pdd[-1]\n",
    "pdd = pdd[1:-1]\n",
    "\n",
    "q_data = pdd[pdd[:, 2] > 0.]\n",
    "t_data = pdd[pdd[:, 1] > 0.]\n",
    "s_data = pdd[pdd[:, 0] > 0.]\n",
    "\n",
    "print(q_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(q_data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from plotters.plot_utils import plot_plaq_diffs_vs_net_weights\n",
    "plt.close('all')\n",
    "kwargs = {'ext': 'png'}\n",
    "fig1, ax1 = plot_plaq_diffs_vs_net_weights(log_dir1, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig2, ax2 = plot_plaq_diffs_vs_net_weights(log_dir2, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig3, ax3 = plot_plaq_diffs_vs_net_weights(log_dir3, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plaq_diff_txt_file = os.path.join(log_dir, 'plaq_diffs_data.txt')\n",
    "pdd = pd.read_csv(plaq_diff_txt_file, header=None)\n",
    "plaq_diff_data = pdd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x[0]\n",
    "x[1:9]\n",
    "x[9:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zero_weights = np.array([0.00, 0.00, 0.00])   # set weights to 0.\n",
    "\n",
    "q_weights = np.array([[0.00, 0.00, 0.10],   # loop over Q weights\n",
    "                      [0.00, 0.00, 0.25],\n",
    "                      [0.00, 0.00, 0.50],\n",
    "                      [0.00, 0.00, 0.75],\n",
    "                      [0.00, 0.00, 1.00],\n",
    "                      [0.00, 0.00, 1.50],\n",
    "                      [0.00, 0.00, 2.00],\n",
    "                      [0.00, 0.00, 5.00]])\n",
    "\n",
    "t_weights = np.array([[0.00, 0.10, 0.00],\n",
    "                      [0.00, 0.25, 0.00],\n",
    "                      [0.00, 0.50, 0.00],\n",
    "                      [0.00, 0.75, 0.00],\n",
    "                      [0.00, 1.00, 0.00],\n",
    "                      [0.00, 1.50, 0.00],\n",
    "                      [0.00, 2.00, 0.00],\n",
    "                      [0.00, 5.00, 0.00]])\n",
    "\n",
    "s_weights = np.array([[0.10, 0.00, 0.00],\n",
    "                      [0.25, 0.00, 0.00],\n",
    "                      [0.50, 0.00, 0.00],\n",
    "                      [0.75, 0.00, 0.00],\n",
    "                      [1.00, 0.00, 0.00],\n",
    "                      [1.50, 0.00, 0.00],\n",
    "                      [2.00, 0.00, 0.00],\n",
    "                      [5.00, 0.00, 0.00]])\n",
    "\n",
    "stq_weights = np.array([1.00, 1.00, 1.00])\n",
    "\n",
    "net_weights_arr = np.array([zero_weights.tolist(),\n",
    "                            *q_weights.tolist(),\n",
    "                            *t_weights.tolist(),\n",
    "                            *s_weights.tolist(),\n",
    "                            stq_weights.tolist()])\n",
    "                   #*list(t_weights), *list(s_weights), list(stq_weights)]\n",
    "net_weights_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s_weights.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zero_weights = [0.00, 0.00, 0.00]   # set weights to 0.\n",
    "\n",
    "q_weights = [[0.00, 0.00, 0.10],   # loop over Q weights\n",
    "             [0.00, 0.00, 0.25],\n",
    "             [0.00, 0.00, 0.50],\n",
    "             [0.00, 0.00, 0.75],\n",
    "             [0.00, 0.00, 1.00],\n",
    "             [0.00, 0.00, 1.50],\n",
    "             [0.00, 0.00, 2.00],\n",
    "             [0.00, 0.00, 5.00]]\n",
    "\n",
    "t_weights = [[0.00, 0.10, 0.00],\n",
    "             [0.00, 0.25, 0.00],\n",
    "             [0.00, 0.50, 0.00],\n",
    "             [0.00, 0.75, 0.00],\n",
    "             [0.00, 1.00, 0.00],\n",
    "             [0.00, 1.50, 0.00],\n",
    "             [0.00, 2.00, 0.00],\n",
    "             [0.00, 5.00, 0.00]]\n",
    "\n",
    "s_weights = [[0.10, 0.00, 0.00],\n",
    "             [0.25, 0.00, 0.00],\n",
    "             [0.50, 0.00, 0.00],\n",
    "             [0.75, 0.00, 0.00],\n",
    "             [1.00, 0.00, 0.00],\n",
    "             [1.50, 0.00, 0.00],\n",
    "             [2.00, 0.00, 0.00],\n",
    "             [5.00, 0.00, 0.00]]\n",
    "\n",
    "stq_weights = [1.00, 1.00, 1.00]\n",
    "\n",
    "net_weights_arr = [zero_weights, *q_weights,\n",
    "                   *t_weights, *s_weights, stq_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net_weights_arr = np.array(net_weights_arr)\n",
    "net_weights_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nw = net_weights_arr\n",
    "zero = nw[0]\n",
    "q = nw[1:9]\n",
    "t = nw[9:17]\n",
    "s = nw[17:25]\n",
    "stq = nw[25]\n",
    "\n",
    "print(zero)\n",
    "print('\\n')\n",
    "print(q)\n",
    "print(len(q))\n",
    "print('\\n')\n",
    "print(t)\n",
    "print(len(t))\n",
    "print('\\n')\n",
    "print(s)\n",
    "print(len(s))\n",
    "print('\\n')\n",
    "print(stq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(plaq_diff_data[11:16])\n",
    "print('\\n')\n",
    "print(plaq_diff_data[16])\n",
    "print('\\n')\n",
    "print(plaq_diff_data[17])\n",
    "print('\\n')\n",
    "print(plaq_diff_data[17:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zero_data = plaq_diff_data[0]\n",
    "q_data = plaq_diff_data[1:6]\n",
    "t_data = plaq_diff_data[6:11]\n",
    "s_data = plaq_diff_data[11:16]\n",
    "tq_data = plaq_diff_data[16]\n",
    "sq_data = plaq_diff_data[17]\n",
    "st_data = plaq_diff_data[18]\n",
    "rand_data = plaq_diff_data[19]\n",
    "stq_data = plaq_diff_data[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "qx, qy = q_data[:, 2], q_data[:, -1]\n",
    "tx, ty = t_data[:, 1], t_data[:, -1]\n",
    "sx, sy = s_data[:, 0], s_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xlabel = 'Net weight'\n",
    "ylabel = 'Avg. plaq. difference'\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(qx, qy, marker='.', label='Transformation (Q) fn')\n",
    "ax.plot(tx, ty, marker='.', label='Translation (T) fn')\n",
    "ax.plot(sx, sy, marker='.', label='Scale (S) fn')\n",
    "ax.plot(0, zero_data[-1], marker='s', label='S, T, Q = 0')\n",
    "ax.plot(1, stq_data[-1], marker='v', label='S, T, Q = 1')\n",
    "ax.set_xlabel(xlabel, fontsize=14)\n",
    "ax.set_ylabel(ylabel, fontsize=14)\n",
    "ax.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "out_file = os.path.join(figs_dir, 'plaq_diff_vs_net_weights.pdf')\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xlabel = 'Net weight'\n",
    "ylabel = 'Avg. plaq. difference'\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(qx, qy, marker='.', label='Transformation (Q) fn')\n",
    "ax.plot(tx, ty, marker='.', label='Translation (T) fn')\n",
    "ax.plot(sx, sy, marker='.', label='Scale (S) fn')\n",
    "ax.plot(0, zero_data[-1], marker='s', label='S, T, Q = 0')\n",
    "ax.plot(1, stq_data[-1], marker='v', label='S, T, Q = 1')\n",
    "ax.set_xlabel(xlabel, fontsize=14)\n",
    "ax.set_ylabel(ylabel, fontsize=14)\n",
    "ax.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "out_file = os.path.join(figs_dir, 'plaq_diff_vs_net_weights.pdf')\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plaq_diff_txt_file = os.path.join(log_dir, 'plaq_diffs_data.txt')\n",
    "net_weights = []\n",
    "avg_plaq_diffs = []\n",
    "with open(plaq_diff_data_file, 'r') as f:\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    line = f.readline()\n",
    "    vals = [float(i) for i in line.split(',')]\n",
    "    net_weights.extend(vals[:2])\n",
    "    avg_plaq_diff.append(vals[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transl_weights = [0., 0.1, 0.25, 0.5, 0.75, 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transl_weights[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transl_weights[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transl_weights = [0., 0.1, 0.25, 0.5, 0.75, 1.]\n",
    "\n",
    "offsets10_17_1036 = [0.00136, -0.00323, -0.00947, -0.01574, -0.01882, -0.02056]\n",
    "diff_dict['lf10_2019_08_17_1036'] = offsets10_17_1036\n",
    "\n",
    "offsets10_19_1946 = [0.00221, -0.00221, -0.00795, -0.01353, -0.01626, -0.01760]\n",
    "diff_dict['lf10_2019_08_19_1946'] = offsets10_19_1946\n",
    "\n",
    "offsets12_19_1713 = [-0.00047, -0.00502, -0.01164, -0.01796, -0.02116, -0.02228]\n",
    "diff_dict['lf12_2019_08_19_1713'] = offsets12_19_1713\n",
    "\n",
    "offsets15_19_2332 = [0.00043, -0.00424, -0.01042, -0.01727, -0.02072, -0.02231]\n",
    "diff_dict['lf15_2019_08_19_2332'] = offsets15_19_2332\n",
    "\n",
    "offsets16_15_1915 = [-0.00180, -0.00452, -0.00811, -0.01249, -0.01485, -0.01638]\n",
    "diff_dict['lf16_2019_08_15_1915'] = offsets16_15_1915\n",
    "\n",
    "offsets16_16_1735 = [-0.00520, -0.00819, -0.01191, -0.01593, -0.01787, -0.01887]\n",
    "diff_dict['lf16_2019_08_16_1735'] = offsets16_16_1735\n",
    "\n",
    "offsets16_17_0745 = [-0.00221, -0.00472, -0.00854, -0.01300, -0.01553, -0.01703]\n",
    "diff_dict['lf16_2019_08_17_0745'] = offsets16_17_0745\n",
    "\n",
    "offsets16_20_0052 = [0.00028, -0.00276, -0.00700, -0.01213, -0.01484, -0.01620]\n",
    "diff_dict['lf16_2019_08_20_0052'] = offsets16_20_0052\n",
    "\n",
    "offsets16_20_0504 = [0.00165, -0.00614, -0.01324, -0.01775, -0.01889, -0.01986]\n",
    "diff_dict['lf16_2019_08_20_0504'] = offsets16_20_0504\n",
    "\n",
    "offsets16_13_1546 = mean_diff_dict['2019_08_13_1546']\n",
    "diff_dict['lf16_2019_08_13_1546'] = mean_diff_dict['2019_08_13_1546']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for key, val in diff_dict.items():\n",
    "    lf_steps = int(key.split('_')[0].lstrip('lf'))\n",
    "    if lf_steps == 16:\n",
    "        ax.plot(transl_weights, val,\n",
    "                label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "        \n",
    "ax.set_xlabel('Translation weight', fontsize=14)\n",
    "ax.set_ylabel(r\"$\\langle\\delta_{\\phi_{P}}^{(\\mathrm{obs})}\\rangle$\",\n",
    "              #r\"- \\delta_{\\phi_{P}}^{(\\mathrm{exp})}$\",\n",
    "              fontsize=14)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(transl_weights, offsets10, marker='s', ls=':', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 10$')\n",
    "ax.plot(transl_weights, offsets12, marker='d', ls='-.', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 12$')\n",
    "ax.plot(transl_weights, offsets15, marker='v', ls='--', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 15$')\n",
    "ax.plot(transl_weights, offsets16, marker='.', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.plot(transl_weights, offsets16_1, marker='>', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.plot(transl_weights, offsets16_2, marker='H', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.plot(transl_weights, offsets16_3, marker='^', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.set_xlabel('Translation weight', fontsize=14)\n",
    "ax.set_ylabel(r\"$\\langle\\delta_{\\phi_{P}}^{(\\mathrm{obs})}\\rangle$\",\n",
    "              #r\"- \\delta_{\\phi_{P}}^{(\\mathrm{exp})}$\",\n",
    "              fontsize=14)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc='best')\n",
    "\n",
    "of = '../../logs/figures/avg_plaq_diff_vs_num_lf2.pdf'\n",
    "out_file = os.path.join(*of.split('/'))\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transl_weights = [0., 0.1, 0.25, 0.5, 0.75, 1.]\n",
    "offsets16 = [0.00028, -0.00276, -0.00700, -0.01213, -0.01484, -0.01620]\n",
    "offsets16_1 = [0.00165, -0.00614, -0.01324, -0.01775, -0.01889, -0.01986]\n",
    "offsets16_2 = [-0.00180, -0.00452, -0.00811, -0.01249, -0.01485, -0.01638]\n",
    "offsets16_3 = [-0.00221, -0.00472, -0.00854, -0.01300, -0.01553, -0.01703]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(transl_weights, offsets16, #marker='.', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.plot(transl_weights, offsets16_1, #marker='>', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.plot(transl_weights, offsets16_2, #marker='H', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.plot(transl_weights, offsets16_3, #marker='^', ls='-', fillstyle='none',\n",
    "        label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.set_xlabel('Translation weight', fontsize=14)\n",
    "ax.set_ylabel(r\"$\\langle\\delta_{\\phi_{P}}^{(\\mathrm{obs})}\\rangle$\",\n",
    "              #r\"- \\delta_{\\phi_{P}}^{(\\mathrm{exp})}$\",\n",
    "              fontsize=14)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc='best')\n",
    "\n",
    "of = '../../logs/figures/avg_plaq_diff_vs_num_lf3.pdf'\n",
    "out_file = os.path.join(*of.split('/'))\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "offsets16 = np.array(\n",
    "    [[0.00028, -0.00276, -0.00700, -0.01213, -0.01484, -0.01620],\n",
    "     [0.00165, -0.00614, -0.01324, -0.01775, -0.01889, -0.01986],\n",
    "     [-0.00180, -0.00452, -0.00811, -0.01249, -0.01485, -0.01638],\n",
    "     [-0.00221, -0.00472, -0.00854, -0.01300, -0.01553, -0.01703]]\n",
    ")\n",
    "avg16 = offsets16.mean(axis=0)\n",
    "err16 = sem(offsets16, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "err16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "\n",
    "transl_weights = [0., 0.1, 0.25, 0.5, 0.75, 1.]\n",
    "offsets10 = [0.00221, -0.00221, -0.00795, -0.01353, -0.01626, -0.01760]\n",
    "offsets12 = [-0.00047, -0.00502, -0.01164, -0.01796, -0.02116, -0.02228]\n",
    "offsets15 = [0.00043, -0.00424, -0.01042, -0.01727, -0.02072, -0.02231]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(transl_weights, offsets10, #marker='s',\n",
    "        ls=':', fillstyle='none', label=r'$N_{\\mathrm{LF}} = 10$')\n",
    "ax.plot(transl_weights, offsets12, #marker='d',\n",
    "        ls='-.', fillstyle='none', label=r'$N_{\\mathrm{LF}} = 12$')\n",
    "ax.plot(transl_weights, offsets15, #marker='v',\n",
    "        ls='--', fillstyle='none', label=r'$N_{\\mathrm{LF}} = 15$')\n",
    "ax.errorbar(transl_weights, avg16, yerr=err16, marker='', ls='-', #fillstyle='none',\n",
    "            #ecolor='k', color='k',\n",
    "            label=r'$N_{\\mathrm{LF}} = 16$')\n",
    "ax.set_xlabel('Translation weight', fontsize=14)\n",
    "ax.set_ylabel(r\"$\\langle\\delta_{\\phi_{P}}^{(\\mathrm{obs})}\\rangle$\",\n",
    "              #r\"- \\delta_{\\phi_{P}}^{(\\mathrm{exp})}$\",\n",
    "              fontsize=14)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc='best')\n",
    "\n",
    "of = '../../logs/figures/avg_plaq_diff_vs_num_lf1.pdf'\n",
    "out_file = os.path.join(*of.split('/'))\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_diff_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dirs = [\n",
    "    ('../../logs/cooley_logs/2019_08_13/2019_08_13_1546/'\n",
    "     'lattice8_batch128_lf16_qw10_aw10_generic_dp05/'),\n",
    "    ('../../logs/cooley_logs/2019_08_15/2019_08_15_1915/'\n",
    "     'lattice8_batch128_lf16_qw10_aw10_generic_dp05/'),\n",
    "    ('../../logs/cooley_logs/2019_08_16/2019_08_16_1735/'\n",
    "     'lattice8_batch128_lf16_qw10_aw10_generic_dp05/'),\n",
    "    ('../../logs/cooley_logs/2019_08_17/2019_08_17_0745/'\n",
    "     'lattice8_batch128_lf16_qw10_aw10_generic_dp05/'),\n",
    "    ('../../logs/cooley_logs/2019_08_17/2019_08_17_1036/'\n",
    "     'lattice8_batch128_lf10_qw10_aw10_generic_dp05/'),\n",
    "    ('../../logs/2019_08_19/2019_08_19_1713/'\n",
    "     'lattice8_batch100_lf12_qw10_aw10_generic_dp05/'),\n",
    "    ('../../logs/2019_08_19/2019_08_19_1946/'\n",
    "     'lattice8_batch100_lf10_qw00_aw10_generic_dp05/'),\n",
    "    ('../../logs/2019_08_19/2019_08_19_2332/'\n",
    "     'lattice8_batch100_lf15_qw00_aw10_generic_dp05/'),\n",
    "    ('../../logs/cooley_logs/2019_08_20/2019_08_20_0052/'\n",
    "     'lattice8_batch128_lf16_qw00_aw10_generic_dp05/'),\n",
    "    ('../../logs/cooley_logs/2019_08_20/2019_08_20_0504/'\n",
    "     'lattice8_batch128_lf16_qw00_aw00_generic_dp05/'),\n",
    "]\n",
    "\n",
    "plaq_diff_dict = {}\n",
    "\n",
    "for ld in log_dirs:\n",
    "    log_dir = os.path.join(*ld.split('/'))\n",
    "    params_file = os.path.join(log_dir, 'parameters.pkl')\n",
    "    with open(params_file, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "\n",
    "    runs_dirs = os.path.join(log_dir, 'runs')\n",
    "    figs_dir = os.path.join(log_dir, 'figures')\n",
    "    run_dirs = [os.path.join(runs_dirs, i) for i in os.listdir(runs_dirs)]\n",
    "    run_strs = [i.split('/')[-1] for i in run_dirs]\n",
    "    \n",
    "    #run_params_files = [os.path.join(i, 'parameters.pkl') for i in run_dirs]\n",
    "    #run_data_files = [os.path.join(i, 'run_data.pkl') for i in run_dirs]\n",
    "    #with open(run_data_files[0], 'rb') as f:\n",
    "    #    run_data = pickle.load(f)\n",
    "    #with open(run_params_files[0], 'rb') as f:\n",
    "    #    run_params = pickle.load(f)\n",
    "        \n",
    "    plotter = GaugeModelPlotter(params, figs_dir)\n",
    "    \n",
    "    mean_diff_arr = []\n",
    "    transl_weights = []\n",
    "    for d, s in zip(run_dirs, run_strs):\n",
    "        run_data_file = os.path.join(d, 'run_data.pkl')\n",
    "        run_params_file = os.path.join(d, 'parameters.pkl')\n",
    "        with open(run_data_file, 'rb') as f:\n",
    "            run_data = pickle.load(f)\n",
    "        with open(run_params_file, 'rb') as f:\n",
    "            run_params = pickle.load(f)\n",
    "\n",
    "        weights = {\n",
    "            'charge_weight': run_params['charge_weight'],\n",
    "            'net_weights': run_params['net_weights']\n",
    "        }\n",
    "        xy_data, kwargs = plotter._plot_setup(run_data, 5., s, weights)\n",
    "        x, y, yerr = xy_data['plaqs_diffs']\n",
    "        mean_diff = np.mean(y)\n",
    "        #mean_diff = plotter._plot_plaqs_diffs(xy_data['plaqs_diffs'], **kwargs)\n",
    "        transl_weights.append(weights['net_weights'][1])\n",
    "        #print(f\"{weights['net_weights']}: {mean_diff}\\n\")\n",
    "        #mean_diff = plotter.plot_observables(run_data, 5., s, weights)\n",
    "        mean_diff_arr.append(mean_diff)\n",
    "\n",
    "    wd_dict = dict(zip(transl_weights, mean_diff_arr))\n",
    "    weights_diffs_dict = OrderedDict(sorted(wd_dict.items(),\n",
    "                                            key=lambda k: k[0]))\n",
    "    \n",
    "    if log_dir[-1] == '/':\n",
    "        log_dir = log_dir.rstrip('/')\n",
    "        \n",
    "    dict_str = log_dir.split('/')[-2]\n",
    "    lf_steps = run_params['num_steps']\n",
    "    plaq_diff_dict_key = f'lf{lf_steps}_' + dict_str\n",
    "    # create key, value pair containing path to log dir\n",
    "    plaq_diff_dict[plaq_diff_dict_key] = {\n",
    "        'data': weights_diffs_dict,\n",
    "        'log_dir': log_dir\n",
    "    }\n",
    "    \n",
    "pd_dict = OrderedDict(sorted(plaq_diff_dict.items(),\n",
    "                             key=lambda k: int(k[0].split('_')[0].lstrip('lf'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lf16_yarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lf16_xarr = []\n",
    "lf10_yarr = []\n",
    "lf12_yarr = []\n",
    "lf15_yarr = []\n",
    "lf16_yarr = []\n",
    "fig, ax = plt.subplots()\n",
    "for key, val in pd_dict.items():\n",
    "    lf_steps = int(key.split('_')[0].lstrip('lf'))\n",
    "    xy_data = val['data']\n",
    "    x = list(xy_data.keys())\n",
    "    y = list(xy_data.values())\n",
    "    if lf_steps == 10:\n",
    "        lf10_yarr.append(y)\n",
    "    if lf_steps == 12:\n",
    "        lf12_yarr.append(y)\n",
    "    if lf_steps == 15:\n",
    "        lf15_yarr.append(y)\n",
    "    if lf_steps == 16:\n",
    "        lf16_yarr.append(y)\n",
    "        \n",
    "# N_lf = 10\n",
    "lf10_yavg = np.mean(np.array(lf10_yarr), axis=0)\n",
    "lf10_yerr = sem(np.array(lf10_yarr), axis=0)\n",
    "ax.errorbar(x, lf10_yavg, yerr=lf10_yerr,  capthick=2., capsize=2., \n",
    "            ls=':', label=r'$N_{\\mathrm{LF}} = $' + '10')\n",
    "\n",
    "# N_lf = 12\n",
    "ax.plot(x, lf12_yarr[0], ls='-.', label=r'$N_{\\mathrm{LF}} = $' + '12')\n",
    "\n",
    "# N_lf = 15\n",
    "ax.plot(x, lf15_yarr[0], ls='--', label=r'$N_{\\mathrm{LF}} = $' + '15')\n",
    "    \n",
    "# N_lf = 16\n",
    "lf16_yavg = np.mean(np.array(lf16_yarr), axis=0)\n",
    "lf16_yerr = sem(np.array(lf16_yarr), axis=0)\n",
    "ax.errorbar(x, lf16_yavg, yerr=lf16_yerr, capthick=1.5, capsize=1.5,\n",
    "            label=r'$N_{\\mathrm{LF}} = $' + '16')\n",
    "        \n",
    "xlabel = 'Translation weight'\n",
    "ylabel = r\"$\\langle\\delta_{\\phi_{P}}^{(\\mathrm{obs})}\\rangle$\"\n",
    "ax.grid(True)\n",
    "ax.set_xlabel(xlabel, fontsize=14)\n",
    "ax.set_ylabel(ylabel, fontsize=14)\n",
    "plt.tight_layout()\n",
    "ax.legend(loc='best')\n",
    "\n",
    "of = '../../logs/figures/avg_plaq_diff_vs_transl_weight_errs.pdf'\n",
    "#of = '../../logs/figures/avg_plaq_diff_vs_transl_weight_lf10_12_15.pdf'\n",
    "#of = '../../logs/figures/avg_plaq_diff_vs_transl_weight_lf16.pdf'\n",
    "out_file = os.path.join(*of.split('/'))\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "        \n",
    "#ax.set_xlabel('Translation weight', fontsize=14)\n",
    "#ax.set_ylabel(r\"$\\langle\\delta_{\\phi_{P}}^{(\\mathrm{obs})}\\rangle$\",\n",
    "#              fontsize=14)\n",
    "#plt.tight_layout()\n",
    "#ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ld = ('../../logs/cooley_logs/2019_08_13/2019_08_13_1546/'\n",
    "      'lattice8_batch128_lf16_qw10_aw10_generic_dp05')\n",
    "log_dir = os.path.join(*ld.split('/'))\n",
    "\n",
    "params_file = os.path.join(log_dir, 'parameters.pkl')\n",
    "with open(params_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    \n",
    "runs_dirs = os.path.join(log_dir, 'runs')\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "run_dirs = [os.path.join(runs_dirs, i) for i in os.listdir(runs_dirs)]\n",
    "run_strs = [i.split('/')[-1] for i in run_dirs]\n",
    "run_strs\n",
    "run_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_params_files = [os.path.join(i, 'parameters.pkl') for i in run_dirs]\n",
    "run_data_files = [os.path.join(i, 'run_data.pkl') for i in run_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(run_data_files[0], 'rb') as f:\n",
    "    run_data = pickle.load(f)\n",
    "with open(run_params_files[0], 'rb') as f:\n",
    "    run_params = pickle.load(f)\n",
    "run_params['net_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotter = GaugeModelPlotter(run_params, figs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict_str = log_dir.split('/')[-2]\n",
    "lf_steps = run_params['num_steps']\n",
    "dict_key = f'lf{lf_steps}_' + dict_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_diff_arr = []\n",
    "transl_weights = []\n",
    "for d, s in zip(run_dirs, run_strs):\n",
    "    run_data_file = os.path.join(d, 'run_data.pkl')\n",
    "    run_params_file = os.path.join(d, 'parameters.pkl')\n",
    "    with open(run_data_file, 'rb') as f:\n",
    "        run_data = pickle.load(f)\n",
    "    with open(run_params_file, 'rb') as f:\n",
    "        run_params = pickle.load(f)\n",
    "        \n",
    "    weights = {\n",
    "        'charge_weight': run_params['charge_weight'],\n",
    "        'net_weights': run_params['net_weights']\n",
    "    }\n",
    "    xy_data, kwargs = plotter._plot_setup(run_data, 5., s, weights)\n",
    "    mean_diff = plotter._plot_plaqs_diffs(xy_data['plaqs_diffs'], **kwargs)\n",
    "    transl_weights.append(weights['net_weights'][1])\n",
    "    #print(f\"{weights['net_weights']}: {mean_diff}\\n\")\n",
    "    #mean_diff = plotter.plot_observables(run_data, 5., s, weights)\n",
    "    mean_diff_arr.append(mean_diff)\n",
    "    \n",
    "wd_dict = dict(zip(transl_weights, mean_diff_arr))\n",
    "weights_diffs_dict = OrderedDict(sorted(weights_diffs_dict.items(),\n",
    "                                        key=lambda k: k[0]))\n",
    "    \n",
    "dict_str = log_dir.split('/')[-2]\n",
    "lf_steps = run_params['num_steps']\n",
    "dict_key = f'lf{lf_steps}_' + dict_str\n",
    "diff_dict[dict_key] = mean_diff_arr\n",
    "#mean_diff_dict[dict_str] = mean_diff_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "#OrderedDict(sorted(d.items(), key=lambda t: t[1]))\n",
    "weights_diffs_dict =  dict(zip(transl_weights, mean_diff_arr))\n",
    "weights_diffs_dict = OrderedDict(sorted(weights_diffs_dict.items(),\n",
    "                                        key=lambda k: k[0]))\n",
    "weights_diffs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transl_weights\n",
    "mean_diff_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotter.plot_observables(run_data, 5., run_strs[0], weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xy_data = plotter._parse_data(run_data, 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'markers': False,\n",
    "    'lines': True,\n",
    "    'alpha': 0.6,\n",
    "    'legend': False,\n",
    "    'ret': False,\n",
    "    'out_file': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotter._plot_plaqs_diffs(xy_data['plaqs_diffs'], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'../args/params.pkl'\n",
    "params_file = os.path.join('..', 'args', 'params.pkl')\n",
    "with open(params_file, 'rb') as f:\n",
    "    params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inference import create_config\n",
    "\n",
    "checkpoint_dir = os.path.join(params['log_dir'], 'checkpoints/')\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "config, params = create_config(params)\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.import_meta_graph(f'{checkpoint_file}.meta')\n",
    "saver.restore(sess, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "autocorrs = np.array(run_data['charges_autocorrs'])\n",
    "autocorrs_avg = np.mean(autocorrs, axis=0)\n",
    "num_steps = autocorrs.shape[1]\n",
    "mid = num_steps // 2\n",
    "lower = int(mid - num_steps * 0.1)\n",
    "upper = int(mid + num_steps * 0.1)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, ncols=1, sharex=False)\n",
    "ax0.plot(np.arange(len(autocorrs_avg)), autocorrs_avg)\n",
    "ax1.plot(np.arange(lower, upper), autocorrs_avg[lower:upper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from plotters.gauge_model_plotter import GaugeModelPlotter\n",
    "import utils.file_io as io\n",
    "\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "run_str = 'steps_10000_beta_50_eps_016_qw_10_0'\n",
    "\n",
    "weights = {\n",
    "    'charge_weight': params['charge_weight'],\n",
    "    'net_weights': [1., 1., 1.]\n",
    "}\n",
    "\n",
    "plotter = GaugeModelPlotter(params, figs_dir)\n",
    "#plotter.plot_observables(run_data, beta=6., run_str=run_str, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xy_data = plotter._parse_data(run_data, beta=6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotter._plot_plaqs(xy_data['plaqs'], beta=6., save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plotter.plot_observables(run_data, beta=6., run_str=run_str, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.errorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.attr_dict import AttrDict\n",
    "#ld = ('../../logs/2019_07_23/2019_07_23_1349/'\n",
    "#      'lattice8_batch128_lf6_qw10_aw10_conv2D_dp00_bn/')\n",
    "#log_dir = os.path.join(*ld.split('/'))\n",
    "#params_file = os.path.join(log_dir, 'parameters.pkl')\n",
    "pf = '../args/params.pkl'\n",
    "params_file = os.path.join(*pf.split('/'))\n",
    "#params_file = os.path.join('..', '', 'params.pkl')\n",
    "with open(params_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "params    \n",
    "params['data_format'] = 'channels_last'\n",
    "\n",
    "#for key, val in params.items():\n",
    "#    FLAGS.__dict__[key] = val\n",
    "    \n",
    "#FLAGS = AttrDict(params.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params['log_dir'] = None\n",
    "\n",
    "import utils.file_io as io\n",
    "log_dir = io.create_log_dir(params)\n",
    "\n",
    "params['log_dir'] = io.create_log_dir(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(params['log_dir'], 'checkpoints/')\n",
    "io.check_else_make_dir(checkpoint_dir)\n",
    "\n",
    "model = GaugeModel(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from variables import TF_FLOAT, NP_FLOAT, GLOBAL_SEED\n",
    "from loggers.train_logger import TrainLogger\n",
    "from inference import create_config\n",
    "\n",
    "train_logger = TrainLogger(model, log_dir, params['summaries'])\n",
    "config, params = create_config(params)\n",
    "\n",
    "charge_weight_init = params['charge_weight']\n",
    "net_weights_init = [1., 1., 1.]\n",
    "samples_init = np.reshape(np.array(model.lattice.samples, dtype=NP_FLOAT),\n",
    "                          (model.num_samples, model.x_dim))\n",
    "beta_init = model.beta_init\n",
    "\n",
    "init_feed_dict = {\n",
    "    model.x: samples_init,\n",
    "    model.beta: beta_init,\n",
    "    model.charge_weight: charge_weight_init,\n",
    "    model.net_weights[0]: net_weights_init[0],  # scale_weight\n",
    "    model.net_weights[1]: net_weights_init[1],  # transformation_weight\n",
    "    model.net_weights[2]: net_weights_init[2],  # translation_weight\n",
    "    model.train_phase: True,\n",
    "}\n",
    "\n",
    "target_collection = []\n",
    "collection = tf.local_variables() + target_collection\n",
    "\n",
    "local_init_op = tf.variables_initializer(collection)\n",
    "ready_for_local_init_op = tf.report_uninitialized_variables(collection)\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "scaffold = tf.train.Scaffold(\n",
    "    init_feed_dict=init_feed_dict,\n",
    "    local_init_op=local_init_op,\n",
    "    ready_for_local_init_op=ready_for_local_init_op\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "#                       TRAINING\n",
    "# ----------------------------------------------------------\n",
    "hooks = []\n",
    "sess_kwargs = {\n",
    "    'checkpoint_dir': checkpoint_dir,\n",
    "    'scaffold': scaffold,\n",
    "    'hooks': hooks,\n",
    "    'config': config,\n",
    "    'save_summaries_secs': None,\n",
    "    'save_summaries_steps': None\n",
    "}\n",
    "\n",
    "sess = tf.train.MonitoredTrainingSession(**sess_kwargs)\n",
    "tf.keras.backend.set_session(sess)\n",
    "sess.run(init_op)\n",
    "\n",
    "trainer = GaugeModelTrainer(sess, model, train_logger)\n",
    "train_kwargs = {\n",
    "    'samples_np': samples_init,\n",
    "    'beta_np': beta_init,\n",
    "    'net_weights': net_weights_init\n",
    "}\n",
    "\n",
    "trainer.train(20, **train_kwargs)\n",
    "\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inference import create_config\n",
    "from loggers.run_logger import RunLogger\n",
    "from plotters.gauge_model_plotter import GaugeModelPlotter\n",
    "\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "config, params = create_config(params)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "saver = tf.train.import_meta_graph(f'{checkpoint_file}.meta')\n",
    "saver.restore(sess, checkpoint_file)\n",
    "\n",
    "run_ops = tf.get_collection('run_ops')\n",
    "inputs = tf.get_collection('inputs')\n",
    "\n",
    "run_logger  = RunLogger(params, inputs, run_ops, save_lf_data=False)\n",
    "plotter = GaugeModelPlotter(params, run_logger.figs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from inference import inference_setup\n",
    "from runners.runner import GaugeModelRunner\n",
    "from inference import run_inference\n",
    "\n",
    "kwargs = {\n",
    "    'run_steps': 100,\n",
    "    'loop_net_weights': True,\n",
    "    'plot_lf': True\n",
    "}\n",
    "params.update(kwargs.items())\n",
    "\n",
    "inference_dict = inference_setup(params)\n",
    "\n",
    "runner = GaugeModelRunner(sess, params, inputs, run_ops, run_logger)\n",
    "run_inference(inference_dict, runner, run_logger, plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "runner.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(params['log_dir'], 'checkpoints')\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "run_logger = RunLogger(model, params['log_dir'], save_lf_data=False)\n",
    "plotter = GaugeModelPlotter(model, run_logger.figs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xnet_x, xnet_v, generic_net = model.dynamics.x_fn.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xconv_x1 = xnet_x.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k, b = xconv_x1.get_weights()\n",
    "k_rand = np.random.randn(*k.shape)\n",
    "b_rand = np.random.randn(*b.shape)\n",
    "\n",
    "xconv_x1.set_weights([k_rand, b_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xconv_x1.set_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xnet = model.dynamics.x_fn\n",
    "vnet = model.dynamics.v_fn\n",
    "\n",
    "for xblock, vblock in zip(xnet.layers, vnet.layers):\n",
    "    for xlayer, vlayer in zip(xblock.layers, vblock.layers):\n",
    "        try:\n",
    "            print(f'xlayer.name: {xlayer.name}')\n",
    "            print(f'vlayer.name: {vlayer.name}')\n",
    "            kx, bx = xlayer.get_weights()\n",
    "            kv, bv = vlayer.get_weights()\n",
    "            kx_rand = np.random.randn(*kx.shape)\n",
    "            bx_rand = np.random.randn(*bx.shape)\n",
    "            kv_rand = np.random.randn(*kv.shape)\n",
    "            bv_rand = np.random.randn(*bv.shape)\n",
    "\n",
    "            xlayer.set_weights([kx, bx])\n",
    "            vlayer.set_weights([kv, bv])\n",
    "        except ValueError:\n",
    "            print(f'Unable to set weights for: {xlayer.name}')\n",
    "            print(f'Unable to set weights for: {vlayer.name}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xconv_x1w, xconv_x1b = xconv_x1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_sample = np.random.randn(*model.lattice.samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_sample = np.array(np.random.randn(*model.lattice.samples.shape), dtype=np.float32)\n",
    "samples_reshaped = tf.reshape(tf.convert_to_tensor(random_sample), (-1, 8, 8, 2))\n",
    "xconv_out1 = model.dynamics.x_fn.x_conv_net.conv1(samples_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xconv_out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for f in range(xconv_out1.shape[-1]):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(sess.run(xconv_out1[0, :, :, f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xconv1w, xconv1b = model.dynamics.x_fn.x_conv_net.conv1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for c in range(xconv1w.shape[2]):\n",
    "    for f in range(xconv1w.shape[-1]):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(xconv1w[:, :, c, f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.dynamics.x_fn.x_conv_net.conv1.get_output_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sess.run(model.dynamics.x_fn.x_conv_net.conv1, feed_dict=init_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_logger = TrainLogger(model, model.log_dir, FLAGS.summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from globals import TF_FLOAT, NP_FLOAT, GLOBAL_SEED\n",
    "\n",
    "charge_weight_init = FLAGS.charge_weight\n",
    "net_weights_init = [1., 1., 1.]\n",
    "samples_init = np.reshape(np.array(model.lattice.samples, dtype=NP_FLOAT),\n",
    "                          (model.num_samples, model.x_dim))\n",
    "beta_init = model.beta_init\n",
    "\n",
    "init_feed_dict = {\n",
    "    model.x: samples_init,\n",
    "    model.beta: beta_init,\n",
    "    model.charge_weight: charge_weight_init,\n",
    "    model.net_weights[0]: net_weights_init[0],  # scale_weight\n",
    "    model.net_weights[1]: net_weights_init[1],  # transformation_weight\n",
    "    model.net_weights[2]: net_weights_init[2],  # translation_weight\n",
    "    model.train_phase: True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_layers_dict = {\n",
    "    (idx, l.name): l for idx, l in enumerate(model.dynamics.x_fn.layers)\n",
    "}\n",
    "\n",
    "xx_conv_layers = {\n",
    "    l.name: l for l in model.dynamics.x_fn.x_conv_block.layers\n",
    "}\n",
    "xv_conv_layers = {\n",
    "    l.name: l for l in model.dynamics.x_fn.v_conv_block.layers\n",
    "}\n",
    "x_generic_layers = {\n",
    "    l.name: l for l in model.dynamics.x_fn.generic_block.layers\n",
    "}\n",
    "xx_conv_layers\n",
    "xv_conv_layers\n",
    "x_generic_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q = tf.reshape(model.x, (-1, *model.lattice.samples.shape[1:], 1))\n",
    "xx_conv_layers['conv1'].compute_output_shape(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q = tf.placeholder(dtype=TF_FLOAT, shape=model.x.shape, name='q')\n",
    "if model.x.shape != model.dynamics.x_fn._input_shape[1:]:\n",
    "    q = tf.reshape(q, (-1, *model.dynamics.x_fn._input_shape[1:]))\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xnet_xlayers = []\n",
    "xnet_vlayers = []\n",
    "for layer in model.dynamics.x_fn.layers:\n",
    "    if 'conv_x' in layer.name:\n",
    "        xnet_xlayers.append(layer)\n",
    "    if 'conv_v' in layer.name:\n",
    "        xnet_vlayers.append(layer)\n",
    "        \n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_net_x_layers = model.dynamics.x_fn.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_collection = []\n",
    "collection = tf.local_variables() + target_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./model.h5', verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "local_init_op = tf.variables_initializer(collection)\n",
    "ready_for_local_init_op = tf.report_uninitialized_variables(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import utils.file_io as io\n",
    "\n",
    "checkpoint_dir = os.path.join(model.log_dir, 'checkpoints')\n",
    "io.check_else_make_dir(checkpoint_dir)\n",
    "\n",
    "scaffold = tf.train.Scaffold(\n",
    "    init_feed_dict=init_feed_dict,\n",
    "    local_init_op=local_init_op,\n",
    "    ready_for_local_init_op=ready_for_local_init_op\n",
    ")\n",
    "\n",
    "sess_kwargs = {\n",
    "    'checkpoint_dir': checkpoint_dir,\n",
    "    'scaffold': scaffold,\n",
    "    'hooks': [],\n",
    "    'config': config,\n",
    "    'save_summaries_secs': None,\n",
    "    'save_summaries_steps': None\n",
    "}\n",
    "\n",
    "sess = tf.train.MonitoredTrainingSession(**sess_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainer = GaugeModelTrainer(sess, model, train_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.set_learning_phase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.learning_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v_rand = tf.random_normal(tf.shape(model.x), seed=GLOBAL_SEED)\n",
    "t = model.dynamics._get_time(0, tile=tf.shape(model.x)[0])\n",
    "\n",
    "mask, mask_inv = model.dynamics._get_mask(0)\n",
    "\n",
    "x_scale, x_translation, x_transformation = model.dynamics.x_fn(\n",
    "    (v_rand, mask * model.x, t), model.train_phase\n",
    ")\n",
    "\n",
    "dynamics_out = model.dynamics(model.x, model.beta, model.net_weights, model.train_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    model.x: samples_init,\n",
    "    model.beta: beta_init,\n",
    "    model.charge_weight: charge_weight_init,\n",
    "    model.net_weights[0]: net_weights_init[0],  # scale_weight\n",
    "    model.net_weights[1]: net_weights_init[1],  # transformation_weight\n",
    "    model.net_weights[2]: net_weights_init[2],  # translation_weight\n",
    "    model.train_phase: True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dynamics_out = model.dynamics(model.x, model.beta, \n",
    "                              model.net_weights, model.train_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from network.network_utils import batch_norm\n",
    "\n",
    "x_reshaped = model.dynamics.x_fn.reshape_5D(model.x)\n",
    "v_reshaped = model.dynamics.v_fn.reshape_5D(v_rand)\n",
    "\n",
    "conv_x1 = model.dynamics.x_fn.conv_x1(x_reshaped)\n",
    "max_pool_x1 = model.dynamics.x_fn.max_pool_x1(conv_x1)\n",
    "conv_x2 = model.dynamics.x_fn.conv_x2(max_pool_x1)\n",
    "bn_x = batch_norm(conv_x2, model.train_phase,\n",
    "                  axis=model.dynamics.x_fn.bn_axis,\n",
    "                  internal_update=True)\n",
    "max_pool_x2 = model.dynamics.x_fn.max_pool_x2(tf.nn.relu(bn_x))\n",
    "\n",
    "conv_v1 = model.dynamics.x_fn.conv_v1(v_reshaped)\n",
    "max_pool_v1 = model.dynamics.x_fn.max_pool_v1(conv_v1)\n",
    "conv_v2 = model.dynamics.x_fn.conv_v2(max_pool_v1)\n",
    "bn_v = batch_norm(conv_v2, model.train_phase,\n",
    "                  axis=model.dynamics.x_fn.bn_axis,\n",
    "                  internal_update=True)\n",
    "max_pool_v2 = model.dynamics.x_fn.max_pool_v2(tf.nn.relu(bn_v))\n",
    "\n",
    "x_flat = model.dynamics.x_fn.flatten(max_pool_x2)\n",
    "v_flat = model.dynamics.x_fn.flatten(max_pool_v2)\n",
    "\n",
    "x_out = tf.nn.relu(model.dynamics.x_fn.x_layer(x_flat))\n",
    "v_out = tf.nn.relu(model.dynamics.x_fn.v_layer(v_flat))\n",
    "t_out = tf.nn.relu(model.dynamics.x_fn.t_layer(t))\n",
    "\n",
    "h1 = tf.nn.relu(x_out + v_out + t_out)\n",
    "h2 = tf.nn.relu(model.dynamics.x_fn.h_layer(h))\n",
    "\n",
    "translation = model.dynamics.x_fn.translation_layer(h)\n",
    "scale = (tf.nn.tanh(model.dynamics.x_fn.scale_layer(h))\n",
    "         * tf.exp(model.dynamics.x_fn.coeff_scale))\n",
    "\n",
    "transformation = (model.dynamics.x_fn.transformation_layer(h)\n",
    "                  * tf.exp(model.dynamics.x_fn.coeff_transformation))\n",
    "\n",
    "layers = {\n",
    "    'conv_x12': conv_x12,\n",
    "    'conv_x1': conv_x1,\n",
    "    'max_pool_x1': max_pool_x1,\n",
    "    'conv_x2': conv_x2,\n",
    "    'bn_x': bn_x,\n",
    "    'max_pool_x2': max_pool_x2,\n",
    "    'x_flat': x_flat,\n",
    "    'x_out': x_out,\n",
    "    't_out': t_out,\n",
    "    'h1': h1,\n",
    "    'h2': h2,\n",
    "}\n",
    "\n",
    "print(f'model.lattice.samples.shape: {model.lattice.samples.shape}\\n')\n",
    "print(f'model.x.shape: {model.x.shape}\\n')\n",
    "print(f'x_reshaped.shape: {x_reshaped.shape}\\n')\n",
    "for name, layer in layers.items():\n",
    "      print(f'{name}: {layer.shape}\\n')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
