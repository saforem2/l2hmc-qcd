{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Distributions for L2HMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Global imports\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow as hvd\n",
    "hvd.init()\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# append parent directory to `sys.path`\n",
    "# to load from modules in `../l2hmc-qcd/`\n",
    "module_path = os.path.join('..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Local imports\n",
    "from utils.attr_dict import AttrDict\n",
    "from utils.training_utils import train_dynamics\n",
    "from dynamics.config import DynamicsConfig\n",
    "from dynamics.base_dynamics import BaseDynamics\n",
    "from dynamics.generic_dynamics import GenericDynamics\n",
    "from network.config import LearningRateConfig\n",
    "from config import (State, NetWeights, MonteCarloStates,\n",
    "                    BASE_DIR, BIN_DIR, TF_FLOAT)\n",
    "\n",
    "from utils.distributions import (plot_samples2D, contour_potential,\n",
    "                                 two_moons_potential, sin_potential,\n",
    "                                 sin_potential1, sin_potential2)\n",
    "\n",
    "#sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\")\n",
    "plt.style.use(\"/Users/saforem2/.config/matplotlib/stylelib/molokai.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 2*np.pi, 0.02)\n",
    "y_arr = [i * np.sin(x) for i in range(9)]\n",
    "fig, ax = plt.subplots()\n",
    "for y in y_arr:\n",
    "    _ = ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.config import NetworkConfig, LearningRateConfig\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def get_dynamics(flags):\n",
    "    \"\"\"Return `GenericDynamics` object, initialized from `flags`.\"\"\"\n",
    "    config = DynamicsConfig(eps=flags.eps,\n",
    "                            num_steps=flags.num_steps,\n",
    "                            aux_weight=flags.aux_weight,\n",
    "                            loss_scale=0.1,\n",
    "                            hmc=flags.hmc,\n",
    "                            eps_fixed=flags.eps_fixed,\n",
    "                            model_type=flags.model_type)\n",
    "\n",
    "\n",
    "    net_config = NetworkConfig(units=flags.units,\n",
    "                               dropout_prob=flags.dropout_prob,\n",
    "                               name=flags.network_name,\n",
    "                               activation_fn=flags.activation_fn)\n",
    "\n",
    "    lr_config = LearningRateConfig(flags.lr_init,\n",
    "                                   decay_steps=flags.decay_steps,\n",
    "                                   decay_rate=flags.decay_rate,\n",
    "                                   warmup_steps=flags.warmup_steps)\n",
    "\n",
    "    dynamics = GenericDynamics(params=flags,\n",
    "                               config=config,\n",
    "                               lr_config=lr_config,\n",
    "                               normalizer=identity,\n",
    "                               network_config=net_config,\n",
    "                               potential_fn=POTENTIAL_FN,\n",
    "                               name=MODEL_TYPE)\n",
    "    \n",
    "    return dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.file_io as io\n",
    "from utils.distributions import contour_potential\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "def plot_chains(dirs, x_arr, potential_fn, label=None, cmap='rainbow'):\n",
    "    figs_dir = os.path.join(dirs.log_dir, 'figures')\n",
    "    io.check_else_make_dir(figs_dir)\n",
    "\n",
    "    x_arr = tf.convert_to_tensor(x_arr).numpy()\n",
    "\n",
    "    for chain in range(4):\n",
    "        fig, ax = plt.subplots()\n",
    "        xy = np.array((x_arr[1000:, chain, 0], x_arr[1000:, chain, 1]))\n",
    "        #sns.kdeplot(*xy, ax=ax)\n",
    "        #grid = xy.reshape(2, -1).T\n",
    "        #Z = np.exp(-POTENTIAL_FN(grid))\n",
    "        #_ = ax.contourf(xy[0], xy[1], Z.reshape(xy[0].shape, xy[1].shape), cmap='inferno')\n",
    "        #xlim = np.abs(np.floor(np.min(xy[0]))) + 1\n",
    "        #ylim = np.abs(np.floor(np.max(xy[1]))) + 1\n",
    "        xlim = 5\n",
    "        ylim = 5\n",
    "        _ = contour_potential(POTENTIAL_FN, ax=ax, cmap=cmap, xlim=xlim, ylim=ylim)\n",
    "        _ = ax.plot(*xy, alpha=0.3, mew=0.9, ls='', marker='+',\n",
    "                    color='white', label='l2hmc samples')\n",
    "        #_ = ax.legend(markerscale=5., loc='best')\n",
    "        _ = ax.set_xlim((-xlim, xlim))\n",
    "        _ = ax.set_ylim((-ylim, ylim))\n",
    "        out_file = os.path.join(figs_dir, f'trained_samples_chain{chain}.png')\n",
    "        print(f'Saving figure to: {out_file}')\n",
    "        _ = plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density_estimation(potential_fn, x_l2hmc, x_hmc,\n",
    "                            title=None, cmap=None, num_plots=5):\n",
    "    def _format_arr(x):\n",
    "        x = np.array(x)\n",
    "        n = x.shape[0]\n",
    "        therm = 2 * n // 10  # Drop first 20% of samples (thermalization)\n",
    "        return x[therm:]\n",
    "    \n",
    "    x_l2hmc = _format_arr(x_l2hmc)\n",
    "    x_hmc = _format_arr(x_hmc)\n",
    "    \n",
    "    for idx in range(num_plots):\n",
    "        fig, axes = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "        _ = contour_potential(potential_fn, title=title, ax=axes[0], cmap=cmap)\n",
    "        _ = sns.kdeplot(x_l2hmc[:, idx, 0], x_l2hmc[:, idx, 1],\n",
    "                        shade=True, cmap=cmap, ax=axes[1])\n",
    "        _ = sns.kdeplot(x_hmc[:, idx, 0], x_hmc[:, idx, 1],\n",
    "                        shade=True, cmap=cmap, ax=axes[2])\n",
    "        _ = axes[1].set_title('L2HMC samples')\n",
    "        _ = axes[2].set_title('HMC samples')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot examples of (toy) target distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "axes = axes.flatten()\n",
    "names = ['two_moons', 'sin', 'sin_hard', 'sin_harder']\n",
    "potentials = [two_moons_potential, sin_potential, sin_potential1, sin_potential2]\n",
    "potentials_and_axes = zip(potentials, axes)\n",
    "potentials_dict = {}\n",
    "for idx, (p_fn, ax) in enumerate(zip(potentials, axes)):\n",
    "    _ = contour_potential(p_fn, ax, title=f'{names[idx]}', cmap='rocket')\n",
    "    ax.facecolor = '#1c1c1c'\n",
    "    fig = plt.gcf()\n",
    "    fig.facecolor = '#1c1c1c'\n",
    "    potentials_dict[names[idx]] = p_fn\n",
    "    \n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.distributions import GaussianFunnel, RoughWell\n",
    "\n",
    "funnel = GaussianFunnel()\n",
    "funnel_potential = funnel.get_energy_function()\n",
    "fig, ax = plt.subplots()\n",
    "_ = contour_potential(funnel_potential, ax=ax, title=f'Gaussian Funnel Potential')\n",
    "plt.show()\n",
    "\n",
    "rough_well = RoughWell(dim=2, eps=0.1, easy=True)\n",
    "rough_well_hard = RoughWell(dim=2, eps=0.1, easy=False)\n",
    "\n",
    "rw_potential = rough_well.get_energy_function()\n",
    "rwh_potential = rough_well_hard.get_energy_function()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes = axes.flatten()\n",
    "ax0 = contour_potential(rw_potential, ax=axes[0], cmap='rocket', title='Rough Well Potential')\n",
    "ax1 = contour_potential(rwh_potential, ax=axes[1], cmap='rocket', title='Rough Well Potential (Hard)')\n",
    "ax0.set_aspect('equal')\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "potentials_dict.update({\n",
    "    'funnel': funnel_potential,\n",
    "    'rough_well': rw_potential,\n",
    "    'rough_well_hard': rwh_potential,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.distributions import GaussianMixtureModel, meshgrid\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "floatx = tf.keras.backend.floatx()\n",
    "\n",
    "\n",
    "def make_gmm_model(mus, sigmas, pis):\n",
    "    def to_tensors(x):\n",
    "        return (tf.convert_to_tensor(i, dtype=floatx) for i in x)\n",
    "    \n",
    "    mus, sigmas, pis = to_tensors([mus, sigmas, pis])\n",
    "    gmm = tfd.Mixture(\n",
    "        cat=tfd.Categorical(probs=pis),\n",
    "        components=[\n",
    "            tfd.MultivariateNormalDiag(loc=m, scale_diag=s)\n",
    "            for m, s in zip(mus, sigmas)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    def potential(x):\n",
    "        return -1. * gmm.log_prob(x)\n",
    "    \n",
    "    #model = GaussianMixtureModel(mus, sigmas, pis) \n",
    "    #potential_fn = lambda x: -1. * model.dist.log_prob(x)\n",
    "    #return model, potential_fn\n",
    "    \n",
    "    return gmm, potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian mixture models:\n",
    "\n",
    " 1. 2-Component mixture: \n",
    " $$x \\sim p(x) \\equiv \\frac{1}{2}\\mathcal{N}(\\vec{x}_{0}, \\Sigma_{0}) + \\frac{1}{2}\\mathcal{N}(\\vec{x}_{1}, \\Sigma_{1})$$\n",
    " 2. $4\\times 4$ Lattice of Gaussians: \n",
    " $$x\\sim\\mathcal{N}(\\vec{x}_{ij}, \\Sigma_{ij})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Mixture of two components\n",
    "mus = [(-1., 0), (1., 0)]\n",
    "sigmas = [0.1 * np.ones(2) for _ in range(len(mus))]\n",
    "pis = len(mus) * [1. / len(mus)]\n",
    "\n",
    "gmm, gmm_potential = make_gmm_model(mus, sigmas, pis)\n",
    "\n",
    "\n",
    "# ==== 4x4 Lattice of Gaussians\n",
    "# xy locations of each component\n",
    "mus = [(-2, -2), (-2, -1), (-2, +0), (-2, +1), (-2, +2),\n",
    "       (-1, -2), (-1, -1), (-1, +0), (-1, +1), (-1, +2),\n",
    "       (+0, -2), (+0, -1), (+0, +0), (+0, +1), (+0, +2),\n",
    "       (+1, -2), (+1, -1), (+1, +0), (+1, +1), (+1, +2),\n",
    "       (+2, -2), (+2, -1), (+2, +0), (+2, +1), (+2, +2)]\n",
    "\n",
    "sigmas = [0.1 * np.ones(2) for _ in range(len(mus))]\n",
    "pis = len(mus) * [1. / len(mus)]\n",
    "\n",
    "gmm_latt, gmm_latt_potential = make_gmm_model(mus, sigmas, pis)\n",
    "\n",
    "\n",
    "potentials_dict.update({\n",
    "    'gmm': gmm_potential,\n",
    "    'lattice_of_gaussians': gmm_latt_potential,\n",
    "})\n",
    "\n",
    "\n",
    "# ==== Plot contours of both potentials\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "axes = axes.flatten()\n",
    "\n",
    "ax0 = contour_potential(gmm_potential, ax=axes[0],\n",
    "                        cmap='rocket', xlim=1.5, ylim=0.5,\n",
    "                        title='Gaussian Mixture Model')\n",
    "\n",
    "ax1 = contour_potential(gmm_latt_potential, ax=axes[1],\n",
    "                        cmap='rocket', xlim=2.7777775, ylim=2.75,\n",
    "                        title='Lattice of Gaussians')\n",
    "    \n",
    "_ = [ax.set_aspect('equal') for ax in axes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters of the model and target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.file_io as io\n",
    "import datetime\n",
    "\n",
    "LOGS_DIR = os.path.abspath('../../logs')\n",
    "\n",
    "# DEFINE THE TARGET DISTRIBUTION\n",
    "MODEL_TYPE = 'two_moons'\n",
    "POTENTIAL_FN = potentials_dict[MODEL_TYPE]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "date_str = now.strftime('%Y-%m-%d')\n",
    "timestamp = now.strftime('%Y-%m-%d-%H%M%S')\n",
    "\n",
    "log_dir = os.path.join(LOGS_DIR, f'{MODEL_TYPE}', date_str)\n",
    "if os.path.isdir(log_dir):\n",
    "    log_dir = os.path.join(log_dir, timestamp)\n",
    "    \n",
    "io.check_else_make_dir(log_dir)\n",
    "\n",
    "\n",
    "flags = AttrDict({\n",
    "    'profiler': False,\n",
    "    'xdim': 2,\n",
    "    'eps': 0.01,\n",
    "    'aux_weight': 0.,\n",
    "    'loss_scale': 0.1,\n",
    "    'batch_size': 256,\n",
    "    'num_steps': 10,\n",
    "    'beta_init': 1.,\n",
    "    'beta_final': 1.,\n",
    "    'compile': True,\n",
    "    'hmc_steps': 0,\n",
    "    'lr_init': 1e-3,\n",
    "    'train_steps': 5000,\n",
    "    'clip_val': 1.0,\n",
    "    'decay_rate': 0.96,\n",
    "    'save_steps': 1000,\n",
    "    'logging_steps': 100,\n",
    "    'warmup_steps': 1000,\n",
    "    'print_steps': 1,\n",
    "    'units': [128, 128],\n",
    "    'hmc': False,\n",
    "    'eps_fixed': False,\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'network_name': 'GenericNetwork',\n",
    "    'dropout_prob': 0.,\n",
    "    'activation_fn': tf.nn.relu,\n",
    "    'log_dir': log_dir,\n",
    "})\n",
    "\n",
    "flags.decay_steps = flags.train_steps // 5\n",
    "#flags.warmup_steps = flags.train_steps // 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Start by training HMC to find optimal step-size $\\varepsilon$ and thermalized config $x_{\\mathrm{therm}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from network.config import NetworkConfig, LearningRateConfig\n",
    "\n",
    "flags.hmc_steps = 1000\n",
    "flags.restore = False\n",
    "\n",
    "x_shape = (flags.batch_size, flags.xdim)\n",
    "x = tf.random.normal(shape=x_shape, dtype=TF_FLOAT)\n",
    "\n",
    "net_config = NetworkConfig(units=flags.units,\n",
    "                           dropout_prob=flags.dropout_prob,\n",
    "                           name=flags.network_name,\n",
    "                           activation_fn=flags.activation_fn)\n",
    "\n",
    "lr_config = LearningRateConfig(flags.lr_init,\n",
    "                     decay_steps=flags.decay_steps,\n",
    "                     decay_rate=flags.decay_rate,\n",
    "                     warmup_steps=flags.warmup_steps)\n",
    "\n",
    "# TRAIN HMC\n",
    "if flags.hmc_steps > 0:\n",
    "    hmc_flags = AttrDict({k: v for k, v in flags.items()})\n",
    "    #hmc_flags.train_steps = hmc_flags.pop('hmc_steps')\n",
    "    hmc_flags.train_steps = 5000\n",
    "    hmc_flags.logging_steps = hmc_flags.train_steps // 20\n",
    "    hmc_flags.beta_final = hmc_flags.beta_init\n",
    "    hmc_flags.compile = True\n",
    "    hmc_config = DynamicsConfig(eps=hmc_flags.eps,\n",
    "                                num_steps=hmc_flags.num_steps,\n",
    "                                hmc=True,\n",
    "                                eps_fixed=flags.eps_fixed,\n",
    "                                model_type=MODEL_TYPE)\n",
    "    hmc_dynamics = GenericDynamics(params=hmc_flags,\n",
    "                                   config=hmc_config,\n",
    "                                   lr_config=lr_config,\n",
    "                                   network_config=net_config,\n",
    "                                   potential_fn=POTENTIAL_FN,\n",
    "                                   name=MODEL_TYPE)\n",
    "    hmc_dirs = io.setup_directories(hmc_flags, 'training_hmc')\n",
    "    x, train_data = train_dynamics(hmc_dynamics, hmc_flags, dirs=hmc_dirs, x=x)\n",
    "    \n",
    "    output_dir = os.path.join(hmc_dirs.train_dir, 'outputs')\n",
    "    train_data.save_data(output_dir)\n",
    "    #flags.eps = hmc_dynamics.eps.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `GenericDynamics` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics = get_dynamics(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dynamics.xnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics.optimizer._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(dynamics.xnet, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train L2HMC sampler using HMC sampler as starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags.restore = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = io.setup_directories(flags)\n",
    "x = tf.random.normal(dynamics.x_shape)\n",
    "flags.train_steps = 2000\n",
    "x, train_data = train_dynamics(dynamics, flags, dirs=dirs, x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamicspath = os.path.join(dirs.log_dir, 'training', 'dynamics.h5')\n",
    "dynamicspath1 = os.path.join(dirs.log_dir, 'training', 'dynamics')\n",
    "#print(f'Saving `dynamics` to: {dynamicspath}')\n",
    "print(f'Saving `dynamics` to: {dynamicspath1}')\n",
    "\n",
    "#dynamics.save(dynamicspath)\n",
    "dynamics.save(dynamicspath1)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnetpath = os.path.join(dirs.log_dir, 'training', 'dynamics_xnet.h5')\n",
    "vnetpath = os.path.join(dirs.log_dir, 'training', 'dynamics_vnet.h5')\n",
    "print(f'Saving `dynamics.xnet` to : {xnetpath}')\n",
    "print(f'Saving `dynamics.vnet` to : {vnetpath}')\n",
    "dynamics.xnet.save(xnetpath)\n",
    "dynamics.vnet.save(vnetpath)\n",
    "\n",
    "\n",
    "xnetpath1 = os.path.join(dirs.log_dir, 'training', 'dynamics_xnet1')\n",
    "vnetpath1 = os.path.join(dirs.log_dir, 'training', 'dynamics_vnet1')\n",
    "print(f'Saving `dynamics.xnet` to : {xnetpath1}')\n",
    "print(f'Saving `dynamics.vnet` to : {vnetpath1}')\n",
    "dynamics.xnet.save(xnetpath1)\n",
    "dynamics.vnet.save(vnetpath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnet_copy = tf.keras.models.load_model(xnetpath)\n",
    "vnet_copy = tf.keras.models.load_model(vnetpath)\n",
    "\n",
    "xnet_copy1 = tf.keras.models.load_model(xnetpath1)\n",
    "vnet_copy1 = tf.keras.models.load_model(vnetpath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = tf.random.normal(dynamics.x_shape)\n",
    "#v = tf.random.normal(dynamics.x_shape)\n",
    "x = tf.ones(dynamics.x_shape)\n",
    "v = tf.ones(dynamics.x_shape)\n",
    "t = dynamics._get_time(0, tile=tf.shape(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1, l2 in zip(dynamics.xnet.layers, xnet_copy.layers):\n",
    "    print(f'{l1.name}, {l2.name}')\n",
    "    if l1.weights != [] and l2.weights != []:\n",
    "        for w1, w2 in zip(l1.weights, l2.weights):\n",
    "            print(f'dw = {tf.reduce_sum(w1 - w2)}')\n",
    "    #print(f'  Original:\\n w = {l1.weights}\\n   copy:\\n w = {l2.weights}\\n')\n",
    "    #print(f'  Original:\\n w = {l1.weights}\\n   copy:\\n w = {l2.weights}\\n')\n",
    "    #print(f'  Original:\\n b = {l1.weights[1].numpy()}\\n   copy:\\n b = {l2.weights[1].numpy()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones(dynamics.x_shape)\n",
    "v = tf.ones(dynamics.x_shape)\n",
    "t = dynamics._get_time(0, tile=tf.shape(x)[0])\n",
    "\n",
    "s, t, q = dynamics.xnet((x, v, t), training=False)\n",
    "s_, t_, q_ = xnet_copy((x, v, t), training=False)\n",
    "s1_, t1_, q1_ = xnet_copy1((x, v, t), training=False)\n",
    "\n",
    "np.allclose(s.numpy(), s_.numpy())\n",
    "np.allclose(s.numpy(), s1_.numpy())\n",
    "np.allclose(s_.numpy(), s1_.numpy())\n",
    "\n",
    "np.allclose(t.numpy(), t_.numpy())\n",
    "np.allclose(t.numpy(), t1_.numpy())\n",
    "np.allclose(t_.numpy(), t1_.numpy())\n",
    "\n",
    "np.allclose(q.numpy(), q_.numpy())\n",
    "np.allclose(q.numpy(), q1_.numpy())\n",
    "np.allclose(q_.numpy(), q1_.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.layers import ScaledTanhLayer\n",
    "\n",
    "\n",
    "stl = ScaledTanhLayer(128, 1., name='scale1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = stl.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.file_io as io\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=dynamics, optimizer=dynamics.optimizer)\n",
    "manager = tf.train.CheckpointManager(ckpt, dirs.ckpt_dir, max_to_keep=5)\n",
    "if manager.latest_checkpoint:\n",
    "    io.log(f'INFO:Checkpoint restored from: {manager.latest_checkpoint}')\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    current_step = dynamics.optimizer.iterations.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.inference_utils import run_dynamics\n",
    "import utils.file_io as io\n",
    "\n",
    "flags.log_dir = dirs.log_dir\n",
    "flags.beta = flags.beta_final\n",
    "\n",
    "summary_dir = os.path.join(flags.log_dir, 'inference', 'summaries')\n",
    "io.check_else_make_dir(summary_dir)\n",
    "writer = tf.summary.create_file_writer(summary_dir)\n",
    "writer.set_as_default()\n",
    "\n",
    "flags.run_steps = 5000\n",
    "run_data, x, x_arr = run_dynamics(dynamics, flags, save_x=True)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dirs.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(dirs.log_dir, 'training'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(keras.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamics.config import DynamicsConfig\n",
    "\n",
    "hmc_flags = AttrDict(dict(flags))\n",
    "hmc_flags.logging_steps = hmc_flags.train_steps // 20\n",
    "hmc_flags.beta_final = hmc_flags.beta_init\n",
    "hmc_flags.compile = True\n",
    "hmc_config = DynamicsConfig(eps=0.15,\n",
    "                            num_steps=hmc_flags.num_steps,\n",
    "                            hmc=True,\n",
    "                            eps_fixed=flags.eps_fixed,\n",
    "                            model_type=MODEL_TYPE)\n",
    "hmc_dynamics = GenericDynamics(params=hmc_flags,\n",
    "                               config=hmc_config,\n",
    "                               lr_config=dynamics.lr_config,\n",
    "                               network_config=dynamics.net_config,\n",
    "                               potential_fn=POTENTIAL_FN,\n",
    "                               name=MODEL_TYPE)\n",
    "hmc_dynamics._parse_net_weights(NetWeights(0., 0., 0., 0., 0., 0.))\n",
    "#hmc_dirs = setup_directories(hmc_flags, 'training_hmc')\n",
    "\n",
    "summary_dir_hmc = os.path.join(hmc_flags.log_dir, 'inference', 'summaries')\n",
    "io.check_else_make_dir(summary_dir_hmc)\n",
    "writer_hmc = tf.summary.create_file_writer(summary_dir_hmc)\n",
    "writer_hmc.set_as_default()\n",
    "hmc_flags.run_steps = 5000\n",
    "x_init = tf.random.normal(x.shape)\n",
    "run_data_hmc, x_hmc, x_arr_hmc = run_dynamics(hmc_dynamics, hmc_flags, save_x=True, x=x_init)\n",
    "    \n",
    "writer_hmc.flush()\n",
    "writer_hmc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density_estimation(dynamics.potential_fn, x_arr, x_arr,\n",
    "                        num_plots=2, title=MODEL_TYPE, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.distributions import contour_potential\n",
    "xl2hmc = np.array(x_arr)\n",
    "xhmc = np.array(x_arr_hmc)\n",
    "\n",
    "for idx in range(5):\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "    _ = contour_potential(POTENTIAL_FN, title='Rough Well (true)', ax=axes[0])\n",
    "    _ = sns.kdeplot(xl2hmc[:, idx, 0], xl2hmc[:, idx, 1],\n",
    "                    shade=True, cmap='inferno', ax=axes[1])\n",
    "    _ = sns.kdeplot(xhmc[:, idx, 0], xhmc[:, idx, 1],\n",
    "                    shade=True, cmap='inferno', ax=axes[2])\n",
    "    _ = axes[1].set_title('L2HMC samples')\n",
    "    _ = axes[2].set_title('HMC samples')\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2] *",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": ""
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
