{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\delta_{\\phi_P}(\\alpha_Q, N_{\\mathrm{LF}}) \\equiv \\langle \\phi_P^{\\mathrm{(obs)}}\\rangle - \\langle{\\phi_{P}^{\\mathrm{(exp)}}}\\rangle \\neq 0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "dataloader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_params = mpl.rcParamsDefault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define `root_log_dir`, containing multiple `model_dirs`: \n",
    "    ```\n",
    "    model_dirs = list_and_join(root_log_dir) \n",
    "               = ['root_log_dir/model_dir1/', 'root_log_dir/model_dir2/', ...]\n",
    "    ```\n",
    "* For each `log_dir` in `model_dirs`, find all the run directories it contains: \n",
    "    ```\n",
    "    log_dirs = list_and_join(model_dirs) \n",
    "             = ['root_log_dir/log_dir1/run_1/', 'root_log_dir/log_dir2/run_1/', ...]\n",
    "    ```\n",
    "* Then, for each `log_dir` in `log_dirs` find and create a list of each `run_dir` in:\n",
    "    ```\n",
    "    runs_dirs = [os.path.join(d, 'runs') for d in log_dirs if 'lattice' in d]\n",
    "    ```\n",
    "    i.e.\n",
    "    ```\n",
    "    run_dirs = [list_and_join(d) for d in runs_dirs]\n",
    "             = [['root_log_dir/log_dir1/run_1/runs/steps100_beta2.0_eps0.1`,\n",
    "                 'root_log_dir/log_dir1/run_1/runs/steps100_beta3.0_eps0.1`, ...],\n",
    "                ['root_log_dir/log_dir2/run_1/runs/steps100_beta2.0_eps0.1`,\n",
    "                 'root_log_dir/log_dir2/run_1/runs/steps100_beta3.0_eps0.1`, ...], ...]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_io import list_and_join\n",
    "\n",
    "rld = '../../logs/charge_weight_test/cooley_logs/2019_5_2/leapfrog7'\n",
    "root_log_dir = os.path.join(*rld.split('/'))\n",
    "model_dirs = list_and_join(root_log_dir)\n",
    "log_dirs = list_and_join(model_dirs)\n",
    "runs_dirs = [os.path.join(d, 'runs') for d in log_dirs if 'lattice' in d]\n",
    "# run_dirs is a list of lists, where each entry in run_dirs is a list\n",
    "# of all the run directories for that individual log_dir.\n",
    "# e.g. log_dirs = ['root_log_dir/log_dir1/run_1/',\n",
    "#                  'root_log_dir/log_dir2/run_1/', ...]\n",
    "# then:\n",
    "#     runs_dirs = ['root_log_dir/log_dir1/run_1/runs/',\n",
    "#                  'root_log_dir/log_dir2/run_1/runs/', ...]\n",
    "# then \n",
    "#     run_dirs = [\n",
    "#         ['root_log_dir/log_dir1/run_1/runs/steps100_beta2.0_eps0.1`,\n",
    "#          'root_log_dir/log_dir1/run_1/runs/steps100_beta3.0_eps0.1`, ...],\n",
    "#         ['root_log_dir/log_dir2/run_1/runs/steps100_beta2.0_eps0.1`,\n",
    "#          'root_log_dir/log_dir2/run_1/runs/steps100_beta3.0_eps0.1`, ...],\n",
    "#         ...\n",
    "#     ]\n",
    "run_dirs = [list_and_join(d) for d in runs_dirs]\n",
    "run_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate `L2HMC` dirs from `HMC` dirs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_run_dirs = []\n",
    "hmc_run_dirs = []\n",
    "for d in run_dirs:\n",
    "    if 'HMC' in d[0]:\n",
    "        hmc_run_dirs.append(d)\n",
    "    else:\n",
    "        l2hmc_run_dirs.append(d)\n",
    "l2hmc_run_dirs; hmc_run_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper method `load_runs_info` to load relevant information from all directories in `run_dirs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils.file_io import get_eps_from_run_history_txt_file\n",
    "from utils.data_loader import DataLoader\n",
    "\n",
    "def get_arr(x):\n",
    "    if isinstance(x, dict):\n",
    "        return np.array(list(x.values()))\n",
    "    return np.array(x)\n",
    "    \n",
    "\n",
    "def load_runs_info(run_dirs):\n",
    "    \"\"\"Create dict. containing info about each dir in run_dirs.\n",
    "    \n",
    "    Args:\n",
    "        run_dirs: List of lists containing paths to individual run directories.\n",
    "        \n",
    "    Returns:\n",
    "        runs_info: Dict. with `run_data` and other \n",
    "            relevant information for each dir in run_dirs.\n",
    "    \"\"\"\n",
    "    data_loader = DataLoader()\n",
    "    runs_info = {}\n",
    "    for i in run_dirs:\n",
    "        parent_dir = os.path.dirname(i[0])\n",
    "        key = parent_dir.split('/')[-3]\n",
    "        print(f'Parent dir: {parent_dir}')\n",
    "        existing = key in list(runs_info.keys())\n",
    "        if key in list(runs_info.keys()):\n",
    "            key += '_1'\n",
    "            if key in list(runs_info.keys()):\n",
    "                num = int(key[-1]) + int(1)\n",
    "                key = key.rstrip(str(num - 1)) + str(num)\n",
    "        runs_info[key] = {}\n",
    "        print(f'  key: {key}')\n",
    "        log_dir = os.path.dirname(parent_dir)\n",
    "        runs_info[key]['log_dir'] = log_dir\n",
    "        runs_info[key]['runs_data'] = {}\n",
    "        for p in i:\n",
    "            print(f'  Loading run_data from: {p}')\n",
    "            rh_txt_file = os.path.join(p, 'run_history.txt')\n",
    "            if os.path.isfile(rh_txt_file):\n",
    "                eps = get_eps_from_run_history_txt_file(rh_txt_file)\n",
    "            run_data_file = os.path.join(p, 'run_data.pkl')\n",
    "            if os.path.isfile(run_data_file):\n",
    "                params = data_loader.load_params(p)\n",
    "                params['eps'] = eps\n",
    "                plaqs =  get_arr(data_loader.load_plaqs(p))\n",
    "                #data_loader.load_observable('plaqs', p)\n",
    "                charges_autocorrs = get_arr(data_loader.load_autocorrs(p))\n",
    "                #data_loader.load_observable('charges_autocorrs', p)\n",
    "                run_data = data_loader.load_run_data(p)\n",
    "                p_split = p.split('_')\n",
    "                beta = float(p_split[-3])\n",
    "                runs_info[key]['runs_data'][beta] = {\n",
    "                    'params': params,\n",
    "                    'run_data': run_data,\n",
    "                    'run_dir': p,\n",
    "                    'eps': eps,\n",
    "                    'charges_autocorrs': charges_autocorrs,\n",
    "                    'plaqs': plaqs,\n",
    "                    #'plaqs': plaqs,\n",
    "                    #'charges_autocorrs': charges_autocorrs\n",
    "                }\n",
    "        \n",
    "    return runs_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "def get_model_params(runs_info):\n",
    "    for key, val in runs_info.items():\n",
    "        split_key = key.split('_')\n",
    "        L = int(split_key[0].lstrip('lattice'))\n",
    "        batch_size = int(split_key[1].lstrip('batch'))\n",
    "        lf = int(split_key[2].lstrip('lf'))\n",
    "        params.append((L, batch_size, lf))\n",
    "    return params \n",
    "\n",
    "model_params = get_model_params(l2hmc_runs_info)\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_runs_info = load_runs_info(l2hmc_run_dirs)\n",
    "hmc_runs_info = load_runs_info(hmc_run_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_observable(runs_info, obs_key):\n",
    "    \"\"\"Extract observable from `run_data['obs_key']`.\"\"\"\n",
    "    observable = {}\n",
    "    eps_dict = {}\n",
    "    for k1, v1 in runs_info.items():\n",
    "        print(f'k1: {k1}')\n",
    "        data = v1['runs_data']\n",
    "        #run_type = 'HMC' if 'HMC' in k1 else 'L2HMC'\n",
    "        for k2, v2 in data.items():\n",
    "            beta = k2\n",
    "            eps = v2['eps']\n",
    "            charge_weight = v2['params']['charge_weight']\n",
    "            num_steps = v2['params']['num_steps']\n",
    "            num_samples = v2['params']['num_samples']\n",
    "            size = v2['params']['space_size']\n",
    "            if 'HMC' in k1:\n",
    "                key = (beta, eps)\n",
    "            else:\n",
    "                key = (charge_weight, beta)\n",
    "            eps_dict[key] = eps\n",
    "            #print(f'{beta}, {eps:.4g}, {charge_weight}')\n",
    "            print(f'  key: {key}')\n",
    "            try:\n",
    "                data = np.array(v2[obs_key])\n",
    "            except KeyError:\n",
    "                print(f\"Unable to extract {obs_key} from data.\")\n",
    "                if obs_key in v2['run_data'].keys():\n",
    "                    data = np.array(v2['run_data'][obs_key])\n",
    "                else:\n",
    "                    print(f\"Unable to extract {obs_key} from `runs_info`.\")\n",
    "                    continue\n",
    "            #try:\n",
    "            #    observable[key].append(data)\n",
    "            #except:\n",
    "            observable[key] = data\n",
    "                  \n",
    "    return observable, eps_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the difference between observed and expected value of the average plaquette: $$\\delta_{\\phi_P}(\\alpha_Q, N_{\\mathrm{LF}}) \\equiv \\langle \\phi_P^{\\mathrm{(obs)}}\\rangle - \\langle{\\phi_{P}^{\\mathrm{(exp)}}}\\rangle \\neq 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_plaqs, l2hmc_eps_dict = extract_observable(l2hmc_runs_info, 'plaqs')\n",
    "hmc_plaqs, hmc_eps_dict = extract_observable(hmc_runs_info, 'plaqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice.lattice import u1_plaq_exact\n",
    "beta_unique = np.unique(np.array(list(l2hmc_plaqs.keys()))[:, 1])\n",
    "\n",
    "plaqs_exact = {k: v for (k, v) in zip(beta_unique, u1_plaq_exact(beta_unique))}\n",
    "plaqs_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "def get_mean_err(x, therm_frac=10):\n",
    "    num_steps = x.shape[0]\n",
    "    therm_steps = int(num_steps // therm_frac)\n",
    "    x = x[therm_steps:, :]\n",
    "    avg = np.mean(x, axis=0)\n",
    "    err = sem(x)\n",
    "    return avg, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_plaq_diffs_stats(plaqs, hmc=False):\n",
    "    if hmc:\n",
    "        idx = 0\n",
    "    else:\n",
    "        idx = 1\n",
    "    plaq_diffs = {\n",
    "        k: np.abs(v - u1_plaq_exact(k[idx])) for (k, v) in plaqs.items()\n",
    "    }\n",
    "    plaq_stats = {\n",
    "        k: get_mean_err(v) for (k, v) in plaq_diffs.items()\n",
    "    }\n",
    "    return plaq_diffs, plaq_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_plaq_diffs, l2hmc_plaq_stats = get_plaq_diffs_stats(l2hmc_plaqs)\n",
    "hmc_plaq_diffs, hmc_plaq_stats = get_plaq_diffs_stats(hmc_plaqs, hmc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.file_io as io\n",
    "\n",
    "mpl.rcdefaults()\n",
    "\n",
    "def plot_plaq_diffs(plaq_diffs, eps_dict, hmc=False, skips=100, xi=100):\n",
    "    out_dir = os.path.join(root_log_dir, 'plaq_diffs_plots')\n",
    "    eps_dir = os.path.join(out_dir, 'eps_plots')\n",
    "    io.check_else_make_dir(out_dir)\n",
    "    io.check_else_make_dir(eps_dir)\n",
    "    if hmc:\n",
    "        betas = np.unique(np.array(list(plaq_diffs.keys()))[:, 0])\n",
    "        keys1 = np.unique(np.array(list(plaq_diffs.keys()))[:, 1])\n",
    "    else:\n",
    "        betas = np.unique(np.array(list(plaq_diffs.keys()))[:, 1])\n",
    "        keys1 = np.unique(np.array(list(plaq_diffs.keys()))[:, 0])\n",
    "    for beta in betas:\n",
    "        fig, ax = plt.subplots()\n",
    "        #for charge_weight in charge_weights:\n",
    "        for key1 in keys1:\n",
    "            if hmc:\n",
    "                eps = key1\n",
    "                key = (beta, eps)\n",
    "                if eps == 0.3:\n",
    "                    continue\n",
    "            else:\n",
    "                charge_weight = key1\n",
    "                key = (charge_weight, beta)\n",
    "                try:\n",
    "                    eps = eps_dict[key]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                \n",
    "            eps_label = r'$\\varepsilon=$' + f'{eps:.4g}'\n",
    "            try:\n",
    "                diff = plaq_diffs[key][xi:][::skips]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            #diff = plaq_diffs[beta][charge_weight][xi:][::skips]\n",
    "            steps = xi + skips * np.arange(len(diff))\n",
    "            if hmc:\n",
    "                label = eps_label\n",
    "            else:\n",
    "                label = (r'$\\alpha_{\\mathrm{Q}}=$' + f'{charge_weight}, '\n",
    "                         + eps_label)\n",
    "            _ = ax.plot(steps, np.mean(diff, axis=1), \n",
    "                        label=label, alpha=0.9)\n",
    "            #except KeyError:\n",
    "            #    continue\n",
    "        labels = [i for i in np.arange(0, steps[-1] + 1000, 2000)]\n",
    "        str_labels = [str(i) for i in labels]\n",
    "        labels[0] = xi\n",
    "        str_labels[0] = str(xi)\n",
    "        _ = plt.xticks(labels, str_labels)\n",
    "        _ = ax.set_xlabel('MD Step', fontsize=14)\n",
    "        _ = ax.set_xlim((50, 10000))\n",
    "        _ = ax.set_ylabel(r'$\\delta_{\\mathrm{plaq}}$', fontsize=14)\n",
    "        L, batch_size, lf = model_params[0]\n",
    "        title_str = (r'$L=$' + f'{L}, ' \n",
    "                     + r'$N_{\\mathrm{samples}}=$' + f'{batch_size}, '\n",
    "                     + r'$N_{\\mathrm{LF}}=$' + f'{lf}, '\n",
    "                     + r'$\\beta=$' + f'{beta}')\n",
    "        _ = ax.set_title(title_str, fontsize=16)\n",
    "        _ = ax.legend(loc='best')\n",
    "        _ = fig.tight_layout()\n",
    "        filename = f'plaq_diff_beta{beta}'\n",
    "        if hmc:\n",
    "            filename += '_HMC'\n",
    "        out_file1 = os.path.join(out_dir, filename + '.png')\n",
    "        out_file2 = os.path.join(eps_dir, filename + '.eps')\n",
    "        print(f'Saving figure to: {out_file1}')\n",
    "        _ = plt.savefig(out_file1, dpi=400, bbox_inches='tight')\n",
    "        print(f'Saving figure to: {out_file2}')\n",
    "        _ = plt.savefig(out_file2, dpi=400, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plaq_diffs(l2hmc_plaq_diffs, l2hmc_eps_dict, skips=100, xi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_plaq_diffs(hmc_plaq_diffs, hmc_eps_dict, hmc=True, skips=100, xi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the autocorrelation of the topological charge $Q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autocorrs_stats(autocorrs):\n",
    "    stats = {\n",
    "        k: get_mean_err(v) for (k, v) in autocorrs.items()\n",
    "    }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2hmc_autocorrs, l2hmc_eps_dict = extract_observable(l2hmc_runs_info,\n",
    "                                                     'charges_autocorrs')\n",
    "\n",
    "hmc_autocorrs, hmc_eps_dict = extract_observable(hmc_runs_info,\n",
    "                                                 'charges_autocorrs')\n",
    "\n",
    "l2hmc_autocorrs_stats = get_autocorrs_stats(l2hmc_autocorrs)\n",
    "hmc_autocorrs_stats = get_autocorrs_stats(hmc_autocorrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmc_charge_weights = np.unique(np.array(list(hmc_autocorrs.keys()))[:, 0])\n",
    "hmc_betas = np.unique(np.array(list(hmc_autocorrs.keys()))[:, 0])\n",
    "hmc_eps_arr = np.unique(np.array(list(hmc_autocorrs.keys()))[:, 1])\n",
    "\n",
    "hmc_autocorrs_dict = {}\n",
    "for beta in hmc_betas:\n",
    "    hmc_autocorrs_dict[beta] = []\n",
    "    #for qw in hmc_charge_weights:\n",
    "    for eps in hmc_eps_arr:\n",
    "        k1 = (beta, eps)\n",
    "        try:\n",
    "            acorr = hmc_autocorrs[k1]\n",
    "            #eps = hmc_eps_dict[k1]\n",
    "            #k2 = (beta, eps)\n",
    "            hmc_autocorrs_dict[beta].append((eps, acorr))\n",
    "        except KeyError:\n",
    "            print(f'Key not found: {k1}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_weights_unique = np.unique(np.array(list(l2hmc_autocorrs.keys()))[:, 0])\n",
    "hmc_eps_unique = np.unique(np.array(list(hmc_autocorrs.keys()))[:, 1])\n",
    "num_l2hmc_colors = len(charge_weights_unique)\n",
    "num_hmc_colors = len(hmc_eps_unique)\n",
    "\n",
    "reds = mpl.cm.get_cmap('Reds', num_l2hmc_colors)\n",
    "blues = mpl.cm.get_cmap('Blues', num_hmc_colors)\n",
    "\n",
    "l2hmc_color_idxs = np.linspace(0.25, 1., num_l2hmc_colors)\n",
    "hmc_color_idxs = np.linspace(0.25, 1., num_hmc_colors)\n",
    "\n",
    "l2hmc_colors = [reds(i) for i in l2hmc_color_idxs]\n",
    "hmc_colors = [blues(i) for i in hmc_color_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9']\n",
    "\n",
    "def plot_autocorrs(l2hmc_data, hmc_data=None, xlims_dict=None):\n",
    "    l2hmc_autocorrs, l2hmc_eps_dict = l2hmc_data\n",
    "    charge_weights = np.unique(np.array(list(l2hmc_autocorrs.keys()))[:, 0])\n",
    "    l2hmc_betas = np.unique(np.array(list(l2hmc_autocorrs.keys()))[:, 1])\n",
    "    \n",
    "    if hmc_data is not None:\n",
    "        hmc_autocorrs, hmc_eps_dict = hmc_data\n",
    "        hmc_betas = np.unique(np.array(list(hmc_autocorrs.keys())))\n",
    "        betas = l2hmc_betas if len(l2hmc_betas) > len(hmc_betas) else hmc_betas\n",
    "    else:\n",
    "        hmc_autocorrs = hmc_eps_dict = None\n",
    "        betas = l2hmc_betas\n",
    "        \n",
    "    for beta in betas:\n",
    "        fig, ax = plt.subplots()\n",
    "        for idx, charge_weight in enumerate(charge_weights):\n",
    "            l2hmc_key = (charge_weight, beta)\n",
    "            try:\n",
    "                l2hmc_autocorr = np.mean(l2hmc_autocorrs[l2hmc_key], axis=0)\n",
    "                l2hmc_autocorr /= np.max(l2hmc_autocorr)\n",
    "                l2hmc_eps = l2hmc_eps_dict[l2hmc_key]\n",
    "                l2hmc_qw_label = (r'$\\alpha_{\\mathrm{Q}}=$' \n",
    "                                  + f'{charge_weight}, ')\n",
    "                l2hmc_eps_label = (r'$\\varepsilon=$' \n",
    "                                   + f'{l2hmc_eps:.3g} (L2HMC)')\n",
    "                l2hmc_label = l2hmc_qw_label + l2hmc_eps_label\n",
    "\n",
    "                _ = ax.plot(l2hmc_autocorr, label=l2hmc_label, ls='-')\n",
    "                        #ls='-', color=l2hmc_colors[idx])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "        if beta in hmc_autocorrs.keys():\n",
    "            for idx, (eps, acorr) in enumerate(hmc_autocorrs[beta]):\n",
    "                hmc_autocorr = np.mean(acorr, axis=0)\n",
    "                hmc_autocorr /= np.max(hmc_autocorr)\n",
    "                hmc_label = r'$\\varepsilon=$' + f'{eps:.2g} (HMC)'\n",
    "                _ = ax.plot(hmc_autocorr, label=hmc_label, ls=':', lw=2.5)\n",
    "                            #ls='--', color=hmc_colors[idx])\n",
    "            \n",
    "        #num_steps = len(l2hmc_autocorr)\n",
    "        \n",
    "        x0, x1 = ax.get_xlim()\n",
    "        if xlims_dict is not None:\n",
    "            x0, x1 = xlims_dict.get(beta, (x0, x1))\n",
    "        _ = ax.set_xlim((x0, x1))\n",
    "        _ = ax.set_xlabel('MD Step', fontsize=14)\n",
    "        _ = ax.set_ylabel('Autocorrelation of ' + r'$Q$', fontsize=14)\n",
    "        L, batch_size, lf = model_params[0]\n",
    "        title_str = (r'$L=$' + f'{L}, ' \n",
    "                     + r'$N_{\\mathrm{samples}}=$' + f'{batch_size}, '\n",
    "                     + r'$N_{\\mathrm{LF}}=$' + f'{lf}, '\n",
    "                     + r'$\\beta=$' + f'{beta}')\n",
    "        _ = ax.set_title(title_str, fontsize=16)\n",
    "        _ = ax.legend(loc='best') #, ncol=2)\n",
    "        _ = fig.tight_layout()\n",
    "        out_dir = os.path.join(root_log_dir, 'charge_autocorr_plots')\n",
    "        eps_dir = os.path.join(out_dir, 'eps_plots')\n",
    "        io.check_else_make_dir(out_dir)\n",
    "        io.check_else_make_dir(eps_dir)\n",
    "        filename = f'charge_autocorr_beta{beta}'\n",
    "        out_file1 = os.path.join(out_dir, filename + '.png')\n",
    "        out_file2 = os.path.join(eps_dir, filename + '.eps')\n",
    "        print(f'Saving figure to: {out_file1}')\n",
    "        _ = plt.savefig(out_file1, dpi=400, bbox_inches='tight')\n",
    "        print(f'Saving figure to: {out_file2}')\n",
    "        _ = plt.savefig(out_file2, dpi=400, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlims_dict = {4.0: (-5, 250), 5.0: (-50, 2000), 6.0: (-50, 10000)}\n",
    "l2hmc_data = (l2hmc_autocorrs, l2hmc_eps_dict)\n",
    "hmc_data = (hmc_autocorrs_dict, hmc_eps_dict)\n",
    "plot_autocorrs(l2hmc_data, hmc_data, xlims_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for beta in betas_unique:\n",
    "    n = 0\n",
    "    fig, ax = plt.subplots()\n",
    "    for rt in rt_unique:\n",
    "        for qw in qw_unique:\n",
    "            for eps in eps_unique:\n",
    "                key = (rt, lx_unique[0], ns_unique[0],\n",
    "                       lf_unique[0], eps, beta, qw)\n",
    "                if key in autocorrs.keys():\n",
    "                    if rt == 'HMC':\n",
    "                        ls = ':'\n",
    "                        _qw = 'N/A'\n",
    "                    else:\n",
    "                        ls = '-'\n",
    "                        _qw = qw\n",
    "                    acorrs = np.array(autocorrs[key])\n",
    "                    if len(acorrs.shape) > 2:\n",
    "                        acorr = np.mean(np.mean(acorrs, axis=1), axis=0)\n",
    "                    else:\n",
    "                        acorr = np.mean(acorrs, axis=0)\n",
    "                    label = ('{:<4}'.format(r'$\\alpha_{\\mathrm{Q}}=$') \n",
    "                             + f'{_qw:<3}, ' \n",
    "                             + '{:>4}'.format(r'$\\varepsilon=$') \n",
    "                             + f'{float(eps):<.4g}, ' + f'{rt:>5}')\n",
    "                    _ = ax.plot(acorr / np.max(acorr), label=label, ls=ls,\n",
    "                                alpha = 1. - (n / 10.))\n",
    "                    title = (f'{LX} x {LX}; ' \n",
    "                             + r'$N_{\\mathrm{LF}} = $ ' + f'{LF}; '\n",
    "                             + r'$\\beta = $ ' + f'{beta}')\n",
    "    #_ = ax.set_xticklabels = np.array([\n",
    "    #    LF * np.array(ax.get_xticklabels(), dtype='float')\n",
    "    #], dtype='str')\n",
    "    n += 1\n",
    "    _ = ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "    _ = ax.set_xlabel('lag', fontsize=14)\n",
    "    _ = ax.set_ylabel('Autocorrelation of ' + r'$Q$', fontsize=14)\n",
    "    _ = ax.set_title(title, fontsize=16)\n",
    "    _ = ax.legend(loc='best', fontsize=11)\n",
    "    _ = ax.set_xlim((-50, 10050))\n",
    "    #if float(beta) == 4.0:\n",
    "    #    _ = ax.set_xlim((-10, 250))\n",
    "    #if float(beta) == 6.0:\n",
    "    #    _ = ax.set_xlim((-50, 1.5e4))\n",
    "    #if float(beta) == 5.0:\n",
    "    #    _ = ax.set_xlim((-50, 0.5e4))\n",
    "    figs_dir = os.path.join(root_log_dir, 'autocorrelation_plots')\n",
    "    eps_dir = os.path.join(figs_dir, 'eps_plots')\n",
    "    io.check_else_make_dir(figs_dir)\n",
    "    io.check_else_make_dir(eps_dir)\n",
    "    out_file = os.path.join(\n",
    "        figs_dir, f'top_charge_autocorr_vs_md_step_beta{beta}_zoomed.png'\n",
    "    )\n",
    "    out_file1 = os.path.join(\n",
    "        eps_dir, f'top_charge_autocorr_vs_md_step_beta{beta}_zoomed.eps'\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    #print(f'Saving figure to: {out_file}.')\n",
    "    #plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    #print(f'Saving figure to: {out_file1}.')\n",
    "    #plt.savefig(out_file1, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaq_diffs = {}\n",
    "plaq_stats = {}\n",
    "for key, val in plaqs.items():\n",
    "    charge_weight, beta = key\n",
    "    plaq_exact = plaqs_exact[beta]\n",
    "    diff = np.abs(val - plaq_exact)\n",
    "    avg, err = get_mean_err(diff)\n",
    "    plaq_diffs[key] = diff\n",
    "    plaq_stats[beta] = {\n",
    "        charge_weight: (avg, err)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaq_diffs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaq_diffs[(0.25, 6.0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaq_stats[4.0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaq_stats[]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
