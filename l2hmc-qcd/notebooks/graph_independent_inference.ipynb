{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imperative Inference (no `TensorFlow`!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#import autograd.numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=3, linewidth=500, edgeitems=15, suppress=True)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('bright')\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "label_size = 9 \n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size \n",
    "\n",
    "mplstyle.use('fast')\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=False)\n",
    "\n",
    "import utils.file_io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from plot_script import get_matching_log_dirs\n",
    "t0 = time.time()\n",
    "root_dir = os.path.abspath('../../gauge_logs/')\n",
    "dates = ['2019_12_15',\n",
    "         '2019_12_16',\n",
    "         '2019_12_17',\n",
    "         '2019_12_18',\n",
    "         '2019_12_19',\n",
    "         '2019_12_20',\n",
    "         '2019_12_21',\n",
    "         '2019_12_22',\n",
    "         '2019_12_23',\n",
    "         '2019_12_24',\n",
    "         '2019_12_25',\n",
    "         '2019_12_26',\n",
    "         '2019_12_27',\n",
    "         '2019_12_28',\n",
    "         '2019_12_29',\n",
    "         '2019_12_30',\n",
    "         '2019_12_31',\n",
    "         '2020_01_02',\n",
    "         '2020_01_03',\n",
    "         '2020_01_04',\n",
    "         '2020_01_05',\n",
    "         '2020_01_06',\n",
    "         '2020_01_07',\n",
    "         '2020_01_08']\n",
    "\n",
    "log_dirs = []\n",
    "for date in dates:\n",
    "    ld = get_matching_log_dirs(date, root_dir=root_dir)\n",
    "    for log_dir in ld:\n",
    "        if 'x011' in log_dir or 'v011' in log_dir:\n",
    "            continue\n",
    "        else:\n",
    "            log_dirs += [log_dir]\n",
    "    #log_dirs += [*ld]\n",
    "    \n",
    "print(len(log_dirs))\n",
    "log_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_inference_np import inference_plots\n",
    "from runners.runner_np import create_dynamics, run_inference_np\n",
    "from utils.file_io import timeit\n",
    "import utils.file_io as io\n",
    "from runners.runner_np import load_pkl\n",
    "from config import NetWeights\n",
    "\n",
    "#log_dir = os.path.abspath('../../gauge_logs/2020_01_07/L8_b64_lf2_v101_f32_0023/')\n",
    "log_dir = log_dirs[-1]\n",
    "#for log_dir in log_dirs:\n",
    "    #if os.path.isfile(os.path.join(log_dir, 'weights.pkl')):\n",
    "try:\n",
    "    dynamics, lattice = create_dynamics(log_dir)\n",
    "    \n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    net_weights = NetWeights(x_scale=1, x_translation=1, x_transformation=1,\n",
    "                             v_scale=1, v_translation=1, v_transformation=1)\n",
    "    rp_l2hmc = {\n",
    "        'beta': 5.,\n",
    "        'eps': dynamics.eps,\n",
    "        'net_weights': net_weights,\n",
    "        'run_steps': 5000,\n",
    "    }\n",
    "\n",
    "    rp_l2hmc, rd_l2hmc, ed_l2hmc = run_inference_np(log_dir, dynamics,\n",
    "                                                    lattice, rp_l2hmc,\n",
    "                                                    init='rand')\n",
    "    #inference_plots(rd_l2hmc, ed_l2hmc, params, rp_l2hmc)\n",
    "except:\n",
    "    io.log(f'Unable to load from `weights.pkl` file in {log_dir}. Skipping!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_inference_np import inference_plots\n",
    "inference_plots(rd_l2hmc, ed_l2hmc, params, rp_l2hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice.lattice import u1_plaq_exact\n",
    "\n",
    "def therm_arr(arr, therm_frac=0.25):\n",
    "    num_steps = arr.shape[0]\n",
    "    therm_steps = int(therm_frac * num_steps)\n",
    "    arr = arr[therm_steps:, :]\n",
    "    steps = np.arange(therm_steps, num_steps)\n",
    "    return arr, steps\n",
    "    \n",
    "rd_dict = {}\n",
    "for key, val in rd_l2hmc.items():\n",
    "    if 'mask' in key:\n",
    "        continue\n",
    "        \n",
    "    arr, steps = therm_arr(np.array(val))\n",
    "    arr = arr.T\n",
    "    \n",
    "    if 'plaqs' in key:\n",
    "        key = 'plaqs_diffs'\n",
    "        arr = u1_plaq_exact(rp_l2hmc['beta']) - arr\n",
    "        \n",
    "    if 'charges' in key:\n",
    "        arr = np.around(arr)\n",
    "        \n",
    "    rd_dict[key] = xr.DataArray(arr,\n",
    "                                dims=['chain', 'draw'],\n",
    "                                coords=[np.arange(arr.shape[0]), steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2hmc = xr.Dataset(rd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(ds_l2hmc, kind='ridgeplot', var_names=['plaqs_diffs'], ridgeplot_alpha=0.4, ridgeplot_overlap=0.1, combined=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(ds_l2hmc, kind='ridgeplot', var_names=['charges'], combined=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2hmc = xr.Dataset(rd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_inference_np import _get_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "axes = az.plot_trace(ds_l2hmc, combined=True, var_names=['plaqs_diffs', 'accept_prob', 'dx', 'charges'])\n",
    "title_str = _get_title(params, rp_l2hmc)\n",
    "#axes[0][0].set_title(title_str, fontsize='x-large')\n",
    "fig = plt.gcf()\n",
    "fig.suptitle(_get_title(params, rp_l2hmc), fontsize='22', y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(ds_l2hmc, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = {}\n",
    "for key, val in rd_dict.items():\n",
    "    ds_dict[key] = xr.DataArray(val, coords=[np.arange(val.shape[0]), steps], dims=['chain', 'draw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2hmc = xr.Dataset(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(ds_l2hmc, var_names=['plaqs_diffs', 'actions', 'accept_prob', 'dx', 'charges'], compact=True, combined=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(rd_dict['plaqs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in ds_dict.items():\n",
    "    az.plot_trace(ds_l2hmc)\n",
    "    \n",
    "    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(rd_dict, var_names=['plaqs', 'accept_prob', 'actions', 'charges', 'dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2hmc = xr.Dataset(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foo = xr.DataArray(data, coords=[times, locs], dims=['time', 'space'])\n",
    "plaqs_da = xr.DataArray(rd_dict['plaqs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l2hmc = pd.DataFrame(rd_dict, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(df_l2hmc, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in rd_l2hmc.items():\n",
    "    \n",
    "    \n",
    "    print(f'{key}: {np.array(val).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dynamics, lattice = create_dynamics(log_dir)\n",
    "    net_weights = NetWeights(x_scale=0, x_translation=0, x_transformation=0,\n",
    "                             v_scale=0, v_translation=0, v_transformation=0)\n",
    "    rp_hmc = {\n",
    "        'beta': 5.,\n",
    "        'eps': dynamics.eps,\n",
    "        'net_weights': net_weights,\n",
    "        'run_steps': 500,\n",
    "    }\n",
    "\n",
    "    rp_hmc, rd_hmc, ed_hmc = run_inference_np(log_dir, dynamics,\n",
    "                                              lattice, rp_hmc,\n",
    "                                              init='rand')\n",
    "    params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "    inference_plots(rd_hmc, ed_hmc, params, rp_hmc)\n",
    "#else:\n",
    "except:\n",
    "    io.log(f'Unable to load from `weights.pkl` file in {log_dir}. Skipping!')\n",
    "    #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runners.runner_np import load_pkl\n",
    "params = load_pkl(os.path.join(log_dir, 'parameters.pkl'))\n",
    "inference_plots(run_data, energy_data, params, run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dx(x1, x2):\n",
    "    return np.mean(1. - np.cos(x1 - x2), axis=-1)\n",
    "\n",
    "def _calc_energies(dynamics, x, v, beta):\n",
    "    pe = dynamics.potential_energy(x, beta)\n",
    "    ke = dynamics.kinetic_energy(v)\n",
    "    h = dynamics.hamiltonian(x, v, beta)\n",
    "    \n",
    "    return pe, ke, h\n",
    "    \n",
    "def calc_energies(dynamics, x_init, outputs, beta):\n",
    "    #x_init = outputs['x_init']\n",
    "    x_prop = outputs['x_proposed']\n",
    "    x_out = outputs['x_out']\n",
    "    v_init = outputs['v_init']\n",
    "    v_prop = outputs['v_proposed']\n",
    "    v_out = outputs['v_out']\n",
    "    \n",
    "    pe_init, ke_init, h_init = _calc_energies(dynamics, x_init, v_init, beta)\n",
    "    pe_prop, ke_prop, h_prop = _calc_energies(dynamics, x_prop, v_prop, beta)\n",
    "    pe_out, ke_out, h_out = _calc_energies(dynamics, x_out, v_out, beta)\n",
    "    \n",
    "    outputs = { \n",
    "        'potential_init': pe_init,\n",
    "        'kinetic_init': ke_init,\n",
    "        'hamiltonian_init': h_init, \n",
    "        'potential_proposed': pe_prop,\n",
    "        'kinetic_proposed': ke_prop,\n",
    "        'hamiltonian_proposed': h_prop, \n",
    "        'potential_out': pe_out,\n",
    "        'kinetic_out': ke_out,\n",
    "        'hamiltonian_out': h_out,\n",
    "    }\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load information about saved model... \n",
    "\n",
    "By loading in the saved weights from the trained model, we can reconstruct the neural network using a pure   \n",
    "numpy implementation which can then be used to run inference without having to reconstruct a tensorflow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lattice(params):\n",
    "    dim = params['dim']\n",
    "    num_steps = params['num_steps']\n",
    "    time_size = params['time_size']\n",
    "    space_size = params['space_size']\n",
    "    batch_size = params['batch_size']\n",
    "    zero_masks = params['zero_masks']\n",
    "    x_dim = (params['time_size']\n",
    "             * params['space_size']\n",
    "             * params['dim'])\n",
    "    \n",
    "    lattice = GaugeLattice(time_size=time_size,\n",
    "                           space_size=space_size,\n",
    "                           dim=dim, link_type='U1',\n",
    "                           batch_size=batch_size)\n",
    "    return lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(log_dir):\n",
    "    run_dirs = get_run_dirs(log_dir)\n",
    "    run_dir = run_dirs[0]\n",
    "    rp_file = os.path.join(run_dir, 'run_params.pkl')\n",
    "    with open(rp_file, 'rb') as f:\n",
    "        run_params = pickle.load(f)\n",
    "        \n",
    "    lattice = create_lattice(params)\n",
    "    potential_fn = lattice.calc_actions_np\n",
    "\n",
    "    eps = run_params['eps']\n",
    "    \n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(params, eps=None, num_steps=None, batch_size=None):\n",
    "    if num_steps is None:\n",
    "        num_steps = params['num_steps']\n",
    "    else:\n",
    "        params['num_steps'] = num_steps\n",
    "        \n",
    "    if batch_size is None:\n",
    "        batch_size = params['batch_size']\n",
    "    else:\n",
    "        params['batch_size'] = batch_size\n",
    "        \n",
    "    if eps is None:\n",
    "        eps = get_eps(log_dir)\n",
    "    else:\n",
    "        params['eps'] = eps\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dynamics(log_dir, eps=None, num_steps=None, batch_size=None):\n",
    "    params_file = os.path.join(log_dir, 'parameters.pkl')\n",
    "    with open(params_file, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "        \n",
    "    params = update_params(params, eps,\n",
    "                           num_steps,\n",
    "                           batch_size)\n",
    "    eps = params['eps']\n",
    "    num_steps = params['num_steps']\n",
    "    batch_size = params['batch_size']\n",
    "    zero_masks = params['zero_masks']\n",
    "\n",
    "    weights_file = os.path.join(log_dir, 'weights.pkl')\n",
    "    with open(weights_file, 'rb') as f:\n",
    "        weights = pickle.load(f)\n",
    "        \n",
    "    lattice = create_lattice(params)\n",
    "    \n",
    "    x_dim = lattice.x_dim\n",
    "    potential_fn = lattice.calc_actions_np\n",
    "    \n",
    "    # Use numpy implementation of the action \n",
    "    # calculation for the potential function\n",
    "    dynamics = DynamicsRunner(potential_fn, weights,\n",
    "                              eps=eps, x_dim=x_dim,\n",
    "                              num_steps=num_steps,\n",
    "                              batch_size=batch_size,\n",
    "                              zero_masks=zero_masks)\n",
    "    return dynamics, lattice, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-construct `GaugeLattice` and build `DynamicsRunner`...\n",
    "\n",
    " - The `GaugeLattice` provides the definition of the `potential_function` and allows   \n",
    "   us to easily calculate lattice observables from our inference samples.\n",
    "\n",
    " - The `DynamicsRunner` is the tensorflow-independent implementation of the `Dynamics`   \n",
    "   engine used for training the L2HMC sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import NetWeights\n",
    "from lattice.lattice import GaugeLattice\n",
    "from plotters.plot_utils import get_run_dirs\n",
    "from dynamics.dynamics_np import DynamicsRunner\n",
    "\n",
    "log_dir = os.path.abspath('/home/foremans/DLHMC/l2hmc-qcd/gauge_logs/'\n",
    "                          '2020_01_08/L8_b64_lf1_f32/')\n",
    "\n",
    "dynamics, lattice = create_dynamics(log_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#lattice = GaugeLattice(time_size=time_size,\n",
    "#                       space_size=space_size,\n",
    "#                       dim=dim, link_type='U1',\n",
    "#                       batch_size=batch_size)\n",
    "#\n",
    "## Use numpy implementation of the action \n",
    "## calculation for the potential function\n",
    "#potential_fn = lattice.calc_actions_np\n",
    "#dynamics = DynamicsRunner(potential_fn, weights,\n",
    "#                          eps=eps, x_dim=x_dim,\n",
    "#                          num_steps=num_steps,\n",
    "#                          batch_size=batch_size,\n",
    "#                          zero_masks=zero_masks)\n",
    "#\n",
    "#beta = 5.\n",
    "#net_weights = NetWeights(1, 1, 1, 1, 1, 1)\n",
    "#samples_init = np.random.randn(params['batch_size'], x_dim)\n",
    "#outputs = dynamics.apply_transition(samples_init, beta, net_weights,\n",
    "#                                    model_type='GaugeModel')\n",
    "#\n",
    "#for key, val in outputs.items():\n",
    "#    print(f'{key}: {val.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import utils.file_io as io\n",
    "\n",
    "def run_inference_np(dynamics, run_params):\n",
    "    run_steps = run_params['run_steps']\n",
    "    beta = run_params['beta']\n",
    "    net_weights = run_params['net_weights']\n",
    "    eps = run_params.get('eps', None)\n",
    "    batch_size = run_params.get('batch_size', None)\n",
    "    if eps is None:\n",
    "        eps = dynamics.eps\n",
    "    if eps != dynamics.eps:\n",
    "        dynamics.eps = eps\n",
    "    if batch_size is None:\n",
    "        batch_size = dynamics.batch_size\n",
    "    if batch_size != dynamics.batch_size:\n",
    "        dynamics.batch_size = batch_size\n",
    "\n",
    "    run_data = {\n",
    "        'plaqs': [],\n",
    "        'actions': [],\n",
    "        'charges': [],\n",
    "        'dxf': [],\n",
    "        'dxb': [],\n",
    "        'dx': [],\n",
    "        'accept_prob': [],\n",
    "        'px': [],\n",
    "        'mask_f': [],\n",
    "        'mask_b': [],\n",
    "    }\n",
    "\n",
    "    energy_data = {\n",
    "        'potential_init': [],\n",
    "        'kinetic_init': [],\n",
    "        'hamiltonian_init': [],\n",
    "        'potential_proposed': [],\n",
    "        'kinetic_proposed': [],\n",
    "        'hamiltonian_proposed': [],\n",
    "        'potential_out': [],\n",
    "        'kinetic_out': [],\n",
    "        'hamiltonian_out': [],\n",
    "    }\n",
    "\n",
    "    h_strf = (\"{:^13s}\" + 7 * \"{:^12s}\").format(\n",
    "        \"STEP\", \"t/STEP\", \"% ACC\", \"∆x\", \"∆xf\", \"∆xb\", \"exp(∆H)\", \"∆ø\"\n",
    "    )\n",
    "\n",
    "    data_strs = []\n",
    "\n",
    "    samples = np.random.randn(batch_size, dynamics.x_dim)\n",
    "    plaq_exact = u1_plaq_exact(beta)\n",
    "\n",
    "    nw_str = ''.join((str(int(i)) for i in net_weights))\n",
    "    beta_str = f'{beta}'.replace('.', '')\n",
    "    eps_str = f'{eps:.3g}'.replace('.', '')\n",
    "    run_str = (f'steps{run_steps}_beta{beta_str}'\n",
    "               f'_eps{eps_str}_nw{nw_str}_rand')\n",
    "\n",
    "    run_params['run_str'] = run_str\n",
    "\n",
    "    runs_dir = os.path.join(log_dir, 'runs_np')\n",
    "    if os.path.isdir(os.path.join(runs_dir, run_str)):\n",
    "        io.log(f'Existing run found! Creating new run_dir...')\n",
    "        run_str += '_1'\n",
    "\n",
    "    run_dir = os.path.join(runs_dir, run_str)\n",
    "    io.check_else_make_dir(run_dir)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for step in range(run_steps):\n",
    "        if step % 100 == 0:\n",
    "            print(len(h_strf) * '-')\n",
    "            print(h_strf)\n",
    "            print(len(h_strf) * '-')\n",
    "        t0 = time.time()\n",
    "        samples_init = np.mod(samples, 2 * np.pi)\n",
    "        output = dynamics.apply_transition(samples, beta, net_weights,\n",
    "                                           model_type='GaugeModel')\n",
    "        dt = time.time() - t0\n",
    "        samples = output['x_out']\n",
    "        samples = np.mod(samples, 2 * np.pi)\n",
    "        obs = lattice.calc_observables_np(samples=samples)\n",
    "        for key, val in obs.items():\n",
    "            run_data[key].append(val)\n",
    "\n",
    "        xf = np.mod(output['xf'], 2 * np.pi) * output['mask_f'][:, None]\n",
    "        xf0 = samples_init * output['mask_f'][:, None]\n",
    "\n",
    "        xb = np.mod(output['xb'], 2 * np.pi) * output['mask_b'][:, None]\n",
    "        xb0 = samples_init * output['mask_b'][:, None]\n",
    "\n",
    "        dxf = calc_dx(xf0, xf)\n",
    "        dxb = calc_dx(xb0, xb)\n",
    "        dx = calc_dx(samples_init, samples)\n",
    "\n",
    "        run_data['dxf'].append(dxf)\n",
    "        run_data['dxb'].append(dxb)\n",
    "        run_data['dx'].append(dx)\n",
    "        run_data['accept_prob'].append(output['accept_prob'])\n",
    "\n",
    "        plaq_diff = plaq_exact - obs['plaqs']\n",
    "\n",
    "        edata = calc_energies(dynamics, samples_init, outputs, beta)\n",
    "        for key, val in edata.items():\n",
    "            energy_data[key].append(val)\n",
    "\n",
    "        exp_dh = np.exp(edata['hamiltonian_init'] - edata['hamiltonian_out'])\n",
    "\n",
    "        px = output['accept_prob']\n",
    "        run_data['px'].append(px)\n",
    "        data_str = (f\"{step:>6g}/{run_steps:<6g} \"\n",
    "                    f\"{dt:^11.4g} \"\n",
    "                    f\"{px.mean():^11.4g} \"\n",
    "                    f\"{dx.mean():^11.4g} \"\n",
    "                    f\"{dxf.mean():^11.4g} \"\n",
    "                    f\"{dxb.mean():^11.4g} \"\n",
    "                    f\"{exp_dh.mean():^11.4g} \"\n",
    "                    f\"{plaq_diff.mean():^11.4g}\")\n",
    "        print(data_str)\n",
    "        data_strs.append(data_str)\n",
    "\n",
    "    print(len(h_strf) * '-')\n",
    "    print(f'Time to complete: {time.time() - start_time:.4g}s')\n",
    "\n",
    "    #io.save_params(run_params, run_dir, name='run_params')\n",
    "    io.save_dict(run_params, run_dir, name='run_params')\n",
    "\n",
    "    run_history_file = os.path.join(run_dir, 'run_history.txt')\n",
    "    io.log(f'Writing run history to: {run_history_file}...')\n",
    "    with open(run_history_file, 'w') as f:\n",
    "        for s in data_strs:\n",
    "            f.write(f'{s}\\n')\n",
    "\n",
    "    run_data_file = os.path.join(run_dir, 'run_data.pkl')\n",
    "    io.log(f'Saving run_data to {run_data_file}...')\n",
    "    with open(run_data_file, 'wb') as f:\n",
    "        pickle.dump(run_data, f)\n",
    "\n",
    "    energy_data_file = os.path.join(run_dir, 'energy_data.pkl')\n",
    "    io.log(f'Saving energy_data to {energy_data_file}...')\n",
    "    with open(energy_data_file, 'wb') as f:\n",
    "        pickle.dump(energy_data, f)\n",
    "\n",
    "    observables_dir = os.path.join(run_dir, 'observables')\n",
    "    io.check_else_make_dir(observables_dir)\n",
    "    for key, val in run_data.items():\n",
    "        out_file = os.path.join(observables_dir, f'{key}.pkl')\n",
    "        io.log(f'Saving {key} to {out_file}...')\n",
    "        with open(out_file, 'wb') as f:\n",
    "            pickle.dump(np.array(val), f)\n",
    "            \n",
    "    return run_params, run_data, energy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\n",
    "    'run_steps': 10000,\n",
    "    'beta': 5.,\n",
    "    'net_weights': NetWeights(1, 1, 1, 1, 1, 1),\n",
    "    'eps': dynamics.eps,\n",
    "    'batch_size': dynamics.batch_size,\n",
    "}\n",
    "run_params_l2hmc, run_data_l2hmc, energy_data_l2hmc = run_inference_np(dynamics, run_params)\n",
    "#run_params_l2hmc, run_data_l2hmc, energy_data_l2hmc = run_inference_np(run_steps=20000, beta=5., net_weights=nw_l2hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\n",
    "    'run_steps': 10000,\n",
    "    'beta': 5.,\n",
    "    'net_weights': NetWeights(0, 0, 0, 0, 0, 0),\n",
    "    'eps': dynamics.eps,\n",
    "    'batch_size': dynamics.batch_size,\n",
    "}\n",
    "run_params_hmc, run_data_hmc, energy_data_hmc = run_inference_np(dynamics, run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_l2hmc = os.path.join(runs_dir, 'steps2000_beta50_eps00402_nw111111_rand_1')\n",
    "obs_dir_l2hmc = os.path.join(rd_l2hmc, 'observables')\n",
    "plaqs_file_l2hmc = os.path.join(obs_dir_l2hmc, 'plaqs.pkl')\n",
    "with open(plaqs_file_l2hmc, 'rb') as f:\n",
    "    plaqs_l2hmc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaqs_l2hmc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plaq_exact = u1_plaq_exact(beta)\n",
    "y1 = plaq_exact - plaqs_l2hmc[1000:, :].flatten()\n",
    "y2 = plaq_exact - np.array(run_data['plaqs'])[1000:, :].flatten()\n",
    "sns.kdeplot(y1, shade=True, ax=ax, label='nw: (1, 1, 1, 1, 1, 1)')\n",
    "sns.kdeplot(y2, shade=True, ax=ax, label='nw: (0, 0, 0, 0, 0, 0)')\n",
    "xlim = ax.get_xlim()\n",
    "ax.set_xlim(xlim[0], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(plaq_exact - plaqs_l2hmc[1000:, :].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(plaq_exact - np.array(run_data['plaqs'])[1000:, :].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dict['x_init'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dict['x_proposed'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dict['x_out'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = os.path.join(log_dir ,'runs', 'steps20000_beta50_eps00402_x000_v000_random/')\n",
    "od = os.path.join(rd, 'observables')\n",
    "rdata = {}\n",
    "files = [os.path.join(od, f'{i}') for i in os.listdir(od) if i.endswith('.pkl')]\n",
    "for f in files:\n",
    "    name = f.split('/')[-1].rstrip('.pkl')\n",
    "    with open(f, 'rb') as ff:\n",
    "        rdata[name] = pickle.load(ff)\n",
    "         \n",
    "\n",
    "rdata = {}\n",
    "files = [os.path.join(observables_dir, f'{i}') for i in os.listdir(observables_dir) if i.endswith('.pkl')]\n",
    "for f in files:\n",
    "    name = f.split('/')[-1].rstrip('.pkl')\n",
    "    with open(f, 'rb') as ff:\n",
    "        rdata[name] = pickle.load(ff)\n",
    "\n",
    "energy_data_file = os.path.join(rd, 'energy_data_tf.pkl')\n",
    "with open(energy_data_file, 'rb') as f:\n",
    "    energy_data = pickle.load(f)\n",
    "\n",
    "for key, val in energy_data.items():\n",
    "    print(f'{key}: {np.array(val).shape}\\n')\n",
    "\n",
    "for key, val in run_data.items():\n",
    "    print(f'{key}: {np.array(val).shape}\\n')\n",
    "\n",
    "for key, val in rdata.items():\n",
    "    print(f'{key}: {np.array(val).shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice.lattice import u1_plaq_exact\n",
    "\n",
    "run_data_hmc = {\n",
    "    'dxf': [],\n",
    "    'dxb': [],\n",
    "    'accept_prob': [],\n",
    "}\n",
    "observables_hmc = {\n",
    "    'plaqs': [],\n",
    "    'actions': [],\n",
    "    'charges': [],\n",
    "}\n",
    "\n",
    "beta = 5.\n",
    "x_dim = time_size * space_size * dim\n",
    "samples = np.random.randn(batch_size, x_dim)\n",
    "net_weights = NetWeights(0, 0, 0, 0, 0, 0)\n",
    "\n",
    "plaq_exact = u1_plaq_exact(beta)\n",
    "\n",
    "run_steps = 5000\n",
    "for step in range(run_steps):\n",
    "    output = dynamics.apply_transition(samples, beta, net_weights,\n",
    "                                       model_type='GaugeModel')\n",
    "    samples = output['x_out']\n",
    "    \n",
    "    \n",
    "    samples = np.mod(samples, 2 * np.pi)\n",
    "    obs = lattice.calc_observables_np(samples=samples)\n",
    "    for key, val in obs.items():\n",
    "        observables_hmc[key].append(val)\n",
    "        \n",
    "    dxf = calc_dx(output['x_init'], output['xf'])\n",
    "    dxb = calc_dx(output['x_init'], output['xb'])\n",
    "    \n",
    "    run_data_hmc['dxf'].append(dxf)\n",
    "    run_data_hmc['dxb'].append(dxb)\n",
    "    run_data_hmc['accept_prob'].append(output['accept_prob'])\n",
    "    \n",
    "    plaq_diff = plaq_exact - obs['plaqs']\n",
    "    \n",
    "    px = np.mean(output['accept_prob'])\n",
    "    print(f'step: {step}/{run_steps},  '\n",
    "          f'accept_prob: {px:.3g},  '\n",
    "          f'dxf: {dxf.mean():.3g},  '\n",
    "          f'dxb: {dxb.mean():.3g},  '\n",
    "          f'plaq_diff: {plaq_diff.mean():.4g} +/- {plaq_diff.std():.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in observables.items():\n",
    "    observables[key] = np.array(val).flatten()\n",
    "    \n",
    "observables['accept_prob'] = np.array(run_data['accept_prob']).flatten()\n",
    "\n",
    "observables_df = pd.DataFrame(observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in observables_hmc.items():\n",
    "    observables_hmc[key] = np.array(val).flatten()\n",
    "    \n",
    "observables['accept_prob'] = np.array(run_data_hmc['accept_prob']).flatten()\n",
    "observables_hmc_df = pd.DataFrame(observables_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import bootstrap\n",
    "def get_stats(arr, axis=0):\n",
    "    avg, err, arr_ = bootstrap(arr, n_boot=n_boot)\n",
    "    return arr_.mean(axis=axis).flatten(), arr_.std(axis=axis).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boot = 2000\n",
    "\n",
    "observables_bs = {}\n",
    "for key, val in observables.items():\n",
    "    val = val.reshape(run_steps, -1)\n",
    "    avg, err = get_stats(val, n_boot) \n",
    "    \n",
    "    avg_key = f'{key}_avg'\n",
    "    err_key = f'{key}_err'\n",
    "    observables_bs[avg_key] = avg\n",
    "    observables_bs[err_key] = err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables_df['plaqs_diffs'] = u1_plaq_exact(beta) - observables_df['plaqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables_hmc_df['plaqs_diffs'] = u1_plaq_exact(beta) - observables_hmc_df['plaqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data.dx < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "y1 = observables_df[observables_df.plaqs_diffs <= 0.2]['plaqs_diffs']\n",
    "y2 = observables_hmc_df[observables_hmc_df.plaqs_diffs <= 0.2]['plaqs_diffs']\n",
    "sns.kdeplot(y1, shade=True, ax=ax, label='nw: (1, 1, 1, 1, 1, 1)')\n",
    "sns.kdeplot(y2, shade=True, ax=ax, label='nw: (0, 0, 0, 0, 0, 0)')\n",
    "xlim = ax.get_xlim()\n",
    "ax.set_xlim(xlim[0], 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaqs_diffs = u1_plaq_exact(beta) - np.array(observables['plaqs'])\n",
    "sns.kdeplot(plaqs_diffs, shade=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables['plaqs'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaq_sums = lattice.calc_plaq_sums(samples)\n",
    "print(f'samples.shape: {samples.shape}\\n')\n",
    "print(f'plaq_sums.shape: {plaq_sums.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(outputs['accept_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(1. - np.cos(outputs['x_init'] - outputs['x_out']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['accept_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_file = os.path.abspath('/home/foremans/figures_2020_01_08/dynamics_mask.pkl')\n",
    "with open(masks_file, 'rb') as f:\n",
    "    masks = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['masks_inv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['masks_inv'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
