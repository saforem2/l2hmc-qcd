{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import config\n",
    "\n",
    "# USE DOUBLE PRECISION FLOATING POINT: `tf.float64`\n",
    "#config.TF_FLOAT = tf.float64\n",
    "#config.TF_INT = tf.int64\n",
    "#config.NP_FLOAT = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loggers.train_logger import TrainLogger\n",
    "from loggers.run_logger import RunLogger\n",
    "import utils.file_io as io\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "np.set_printoptions(precision=5)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from utils.distributions import GMM, gen_ring\n",
    "from dynamics.dynamics import Dynamics\n",
    "\n",
    "from models.gmm_model import GaussianMixtureModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session(config, checkpoint_dir, monitored=False):\n",
    "    if monitored:\n",
    "        sess_kwargs = {\n",
    "            'checkpoint_dir': checkpoint_dir,\n",
    "            'hooks': [],\n",
    "            'config': config,\n",
    "            'save_summaries_secs': None,\n",
    "            'save_summaries_steps': None,\n",
    "        }\n",
    "        return tf.train.MonitoredTrainingSession(**sess_kwargs)\n",
    "    \n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(\n",
    "            Ellipse(position, nsig * width, nsig * height, angle, **kwargs)\n",
    "        )\n",
    "        \n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covars_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, alpha=w * w_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inference_data(samples, px, out_dir, type_str='l2hmc'):\n",
    "    px = np.array(px)\n",
    "    samples = np.array(samples)\n",
    "    all_samples = samples.reshape((-1, 2))\n",
    "    x, y = all_samples.T\n",
    "    xmean, ymean = x.mean(), y.mean()\n",
    "    \n",
    "    type_str = type_str.upper()\n",
    "    shape_str = f'{type_str} samples.shape: {samples.shape}\\n'\n",
    "    _str = f'{type_str} Averages (x_avg, y_avg): ({xmean:.5g}, {ymean:.5g})'\n",
    "    print(shape_str + _str)\n",
    "    \n",
    "    samples_out_file = os.path.join(out_dir, f'{type_str}_inference_samples.pkl')\n",
    "    px_out_file = os.path.join(out_dir, f'{type_str}_inference_probs.pkl')\n",
    "    \n",
    "    print(f'Saving samples to: {samples_out_file}')\n",
    "    with open(samples_out_file, 'wb') as f:\n",
    "        pickle.dump(samples, f)\n",
    "        \n",
    "    print(f'Saving probs to: {px_out_file}')\n",
    "    with open(px_out_file, 'wb') as f:\n",
    "        pickle.dump(px, f)\n",
    "        \n",
    "    means_file = os.path.join(out_dir, f'{type_str}_inference_means.txt')\n",
    "    with open(means_file, 'w') as f:\n",
    "        _ = f.write(shape_str)\n",
    "        _ = f.write(_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup paramters for `GaussianMixtureModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params.gmm_params import GMM_PARAMS\n",
    "from loggers.train_logger import TrainLogger\n",
    "from main import train_setup, create_config\n",
    "from update import set_precision\n",
    "\n",
    "params = GMM_PARAMS\n",
    "#params['float64'] = True\n",
    "#set_precision('float64')\n",
    "\n",
    "root_dir = 'gmm_logs'\n",
    "params, hooks = train_setup(params, log_file=None,\n",
    "                            root_dir=root_dir,\n",
    "                            run_str=False)\n",
    "params['beta_init'] = 1. / 20.\n",
    "params['diag'] = True\n",
    "params['center'] = 1.5\n",
    "params['sigma1'] = 0.02\n",
    "params['sigma2'] = 0.06\n",
    "params['num_steps'] = 10\n",
    "params['eps'] = 0.2\n",
    "params['batch_size'] = 128\n",
    "\n",
    "# Whether or not to use Gaussian loss instead of the usual ESJD loss\n",
    "params['use_gaussian_loss'] = False\n",
    "params['loss_scale'] = 1.\n",
    "\n",
    "_ = params.pop('sigma')\n",
    "_ = params.pop('zero_translation')\n",
    "_ = [print(f'{k}: {v}') for k, v in params.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build `GaussianMixtureModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianMixtureModel(params)\n",
    "target_samples = model.distribution.get_samples(int(2e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import _gmm_plot\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "out_file = os.path.join(figs_dir, 'target_distribution.pdf')\n",
    "\n",
    "kwargs = {\n",
    "    'out_file': out_file,\n",
    "    'fill': False,\n",
    "    'ellipse': False,\n",
    "    'title': 'Target distribution of GMM',\n",
    "    'ls': '',\n",
    "    'axis_scale': 'scaled',\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "ax = _gmm_plot(model.distribution, target_samples, **kwargs)\n",
    "xlim_ = ax.get_xlim()\n",
    "xmin, xmax = -0.7, 2.1\n",
    "ymin, ymax = -0.5, 2.1\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "_samples = target_samples[:10000]\n",
    "#xlims, ylims = get_lims(_samples)\n",
    "#xmin, xmax = -0.8, 2.75\n",
    "#ymin, ymax = -0.8, 2.75\n",
    "#xmin, xmax = -0.75, 1.5\n",
    "#ymin, ymax = -0.5, 1.5\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "\n",
    "x = _samples[:, 0]\n",
    "y = _samples[:, 1]\n",
    "\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "values = np.vstack([x, y])\n",
    "kernel = st.gaussian_kde(values)\n",
    "f = np.reshape(kernel(positions).T, xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'coolwarm'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(xx, yy, f, rstride=1, cstride=1,\n",
    "                       cmap=cmap, edgecolor='none', alpha=0.6)\n",
    "# Plot projections of the contours for each dimension.  By choosing offsets\n",
    "# that match the appropriate axes limits, the projected contours will sit on\n",
    "# the 'walls' of the graph\n",
    "cset = ax.contour(xx, yy, f, zdir='z', offset=-0.1, cmap=cmap)\n",
    "cset = ax.contour(xx, yy, f, zdir='x', offset=xmin, cmap=cmap)\n",
    "cset = ax.contour(xx, yy, f, zdir='y', offset=ymax, cmap=cmap)\n",
    "#_ = ax.axis('equal')\n",
    "xlim = [xmin, xmax]\n",
    "ylim = [ymin, ymax]\n",
    "_ = ax.set_xlim(xlim)\n",
    "_ = ax.set_ylim(ylim)\n",
    "_ = ax.set_xlabel('x')\n",
    "_ = ax.set_ylabel('y')\n",
    "\n",
    "z_lim = ax.get_zlim()\n",
    "_ = ax.set_zlim((-0.1, z_lim[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the \"average\" mean using samples drawn from target distribution\n",
    "\n",
    "\\begin{align*}\n",
    "\\vec{\\mu}_{p} &= \\sum_{i} \\vec{x}_{i},\\\\ \n",
    "    \\mathrm{where:}\\quad \\vec{x} &\\sim \\pi_{1}\\, \\mathcal{N}\\left(\\vec{\\mu}_{1}, \\vec{\\Sigma}_{2}\\right) \n",
    "        + \\pi_2\\, \\mathcal{N}\\left(\\vec{\\mu}_{2}, \\vec{\\Sigma}_{2}\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "samples_avg = target_samples.mean(axis=0) # get average (x, y) for each chain\n",
    "_x, _y = samples_avg.T\n",
    "\n",
    "target_samples_shape_str = f'target_samples.shape: {target_samples.shape}\\n'\n",
    "target_samples_str = f'(x_avg, y_avg): ({_x.mean():.6g}, {_y.mean():.6g})\\n'\n",
    "\n",
    "print(target_samples_shape_str + target_samples_str)\n",
    "\n",
    "target_means_file = os.path.join(model.log_dir, 'means.txt')\n",
    "with open(target_means_file, 'w') as f:\n",
    "    _ = f.write(target_samples_shape_str + target_samples_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create session and `train_logger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logger = TrainLogger(model, params['log_dir'],\n",
    "                           logging_steps=10, summaries=params['summaries'])\n",
    "\n",
    "config, params = create_config(params)\n",
    "\n",
    "checkpoint_dir = os.path.join(model.log_dir, 'checkpoints')\n",
    "io.check_else_make_dir(checkpoint_dir)\n",
    "\n",
    "sess = create_session(config, checkpoint_dir, monitored=True)\n",
    "tf.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reversibility check\n",
    "Check reversibility using `model._check_reversibility()` method and compute the difference between `(x_init, v_init)` and `backward(forward(x_init, v_init))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Check reversibility using `model._check_reversibility()` method\n",
    "# -------------------------------------------------------------------\n",
    "samples_init = np.random.randn(*model.x.shape)\n",
    "feed_dict = {\n",
    "    model.x: samples_init,\n",
    "    model.beta: 1.,\n",
    "    model.net_weights[0]: 1.,\n",
    "    model.net_weights[1]: 1.,\n",
    "    model.net_weights[2]: 1.,\n",
    "    model.train_phase: False\n",
    "}\n",
    "\n",
    "x_diff, v_diff = sess.run([model.x_diff, model.v_diff], feed_dict=feed_dict)\n",
    "x_diff, v_diff\n",
    "# (3.9827573e-06, 0.00016799556)\n",
    "# (2.4846453e-05, 0.00034340395)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Train `GaussianMixtureModel` using `GaussianMixtureModelTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from trainers.gmm_trainer import GaussianMixtureModelTrainer\n",
    "trainer = GaussianMixtureModelTrainer(sess, model, logger=train_logger)\n",
    "\n",
    "train_kwargs = {\n",
    "    'samples_np': np.random.randn(*model.x.shape),\n",
    "    'beta_np': model.beta_init,\n",
    "    'net_weights': [1., 1., 1.],\n",
    "    'print_steps': 1.,\n",
    "}\n",
    "\n",
    "trainer.train(5000, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Load and restore a trained model for running inference, using `GaussianMixtureModelRunner` and `RunLogger` for generating summaries and saving statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(model.log_dir, 'checkpoints')\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.import_meta_graph(f'{checkpoint_file}.meta')\n",
    "saver.restore(sess, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loggers.run_logger import RunLogger\n",
    "from runners.gmm_runner import GaussianMixtureModelRunner\n",
    "\n",
    "run_ops = tf.get_collection('run_ops')\n",
    "inputs = tf.get_collection('inputs')\n",
    "\n",
    "run_logger = RunLogger(params, inputs, run_ops,\n",
    "                       save_lf_data=False,\n",
    "                       model_type='gmm_model')\n",
    "\n",
    "runner = GaussianMixtureModelRunner(sess, params, inputs,\n",
    "                                    run_ops, logger=run_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run L2HMC inference using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'run_steps': 10000,\n",
    "    'beta': 1.,\n",
    "    'net_weights': [1., 1., 1.],\n",
    "    'eps': runner.eps,\n",
    "}\n",
    "run_str = run_logger._get_run_str(**kwargs)\n",
    "kwargs['run_str'] = run_str\n",
    "\n",
    "run_logger.reset(**kwargs)\n",
    "runner.run(**kwargs)\n",
    "\n",
    "samples_out = np.array(run_logger.samples_arr)\n",
    "samples_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'run_steps': 10000,\n",
    "    'beta': 1.,\n",
    "    'net_weights': [1., 1., 1.],\n",
    "    'eps': runner.eps,\n",
    "}\n",
    "run_str = run_logger._get_run_str(**kwargs)\n",
    "kwargs['run_str'] = run_str\n",
    "\n",
    "run_logger.reset(**kwargs)\n",
    "runner.run(**kwargs)\n",
    "\n",
    "samples_out1 = np.array(run_logger.samples_arr)\n",
    "samples_out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_out = np.array(run_logger.samples_arr)\n",
    "px_out = np.array(run_logger.px_arr)\n",
    "out_dir = run_logger.run_dir\n",
    "save_inference_data(samples_out, px_out, out_dir, type_str='L2HMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import _gmm_plot, get_lims\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "out_file = os.path.join(figs_dir, 'single_l2hmc_chain.pdf')\n",
    "\n",
    "kwargs = {\n",
    "    'out_file': out_file,\n",
    "    'fill': False,\n",
    "    'ellipse': False,\n",
    "    'title': 'Single L2HMC chain',\n",
    "    'ls': '-',\n",
    "    'axis_scale': 'scaled',\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "ax = _gmm_plot(model.distribution, samples_out[:, 42], **kwargs)\n",
    "xlim, ylim = get_lims(model.distribution.get_samples(500))\n",
    "#xlim_ = ax.get_xlim()\n",
    "#xmin, xmax = -0.7, 2.1\n",
    "#ymin, ymax = -0.5, 2.1\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.array([0., 2 * np.pi, - np.pi, 3 * np.pi])\n",
    "coords = [(np.cos(x), np.sin(x)) for x in angles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_angles(angles):\n",
    "    x, y = np.cos(angles), np.sin(angles)\n",
    "    angles = np.arctan2(x, y)\n",
    "    \n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_out = wrap_angles(samples_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = get_lims(model.distribution.get_samples(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = samples_out.reshape((-1, 2))\n",
    "\n",
    "X, Y = all_samples[:, 0], all_samples[:, 1]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrs = block_resampling(X, 64)\n",
    "Xrs_ = np.array(Xrs)\n",
    "Xrs_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_avg, X_err = calc_avg_vals_errors(X, num_blocks=64)\n",
    "Y_avg, Y_err = calc_avg_vals_errors(Y, num_blocks=64)\n",
    "\n",
    "print(f'({X_avg}, {Y_avg}) +/- ({X_err}, {Y_err})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'({X_avg}, {Y_avg}) +/- ({X_err}, {Y_err})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_outT = samples_out.transpose((1, 0, 2))\n",
    "samples_outT.shape\n",
    "\n",
    "xT, yT = samples_outT[:, :, 0], samples_outT[:, :, 1]\n",
    "xT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xT_rs = np.array([block_resampling(xx, 20) for xx in xT])\n",
    "xT_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rs = np.array([\n",
    "    block_resampling(samples_out[:, idx, 0], 20) for idx in samples_out.shape[1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_out_rs = block_resampling(samples_out[:, 0, 0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_out_rs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(samples_out_rs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmu = samples_out[:, :, 0].mean(axis=0)\n",
    "xmu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import (block_resampling, jackknife, jackknife_err,\n",
    "                              jackknife_var, calc_avg_vals_errors)\n",
    "\n",
    "ymu = samples_out[:, :, 1].mean(axis=0)\n",
    "_x_avg, _x_err = calc_avg_vals_errors(xmu, num_blocks=64)\n",
    "_y_avg, _y_err = calc_avg_vals_errors(ymu, num_blocks=64)\n",
    "\n",
    "print(f'Mean +/- err:\\n ({_x_avg}, {_y_avg}) +/- ({_x_err}, {_y_err})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import gmm_plot\n",
    "gaussian_loss = model.use_gaussian_loss\n",
    "if gaussian_loss:\n",
    "    _loss_type = 'Gaussian'\n",
    "else:\n",
    "    _loss_type = 'Original'\n",
    "\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "\n",
    "samples_out = np.array(samples_out)\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 2500,\n",
    "    'ellipse': False,\n",
    "    'title': f'L2HMC ({_loss_type} loss)',\n",
    "    'out_file': os.path.join(figs_dir, 'inference_plot.pdf'),\n",
    "    'axis_scale': 'equal',\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution, samples_out, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(os.path.join(figs_dir, 'inference_plot1,.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "l2hmc_samples = samples_out.reshape((-1, 2))\n",
    "_samples = l2hmc_samples[:10000]\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "\n",
    "x = _samples[:, 0]\n",
    "y = _samples[:, 1]\n",
    "\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "values = np.vstack([x, y])\n",
    "kernel = st.gaussian_kde(values)\n",
    "f = np.reshape(kernel(positions).T, xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'coolwarm'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(xx, yy, f, rstride=1, cstride=1,\n",
    "                       cmap=cmap, alpha=0.8)  # edgecolor='none')\n",
    "# Plot projections of the contours for each dimension.  By choosing offsets\n",
    "# that match the appropriate axes limits, the projected contours will sit on\n",
    "# the 'walls' of the graph\n",
    "cset = ax.contour(xx, yy, f, zdir='z', offset=-0.2, cmap=cmap)\n",
    "cset = ax.contour(xx, yy, f, zdir='x', offset=xmin, cmap=cmap)\n",
    "cset = ax.contour(xx, yy, f, zdir='y', offset=ymax, cmap=cmap)\n",
    "#_ = ax.axis('equal')\n",
    "xlim = [xmin, xmax]\n",
    "ylim = [ymin-0.05, ymax+0.05]\n",
    "_ = ax.set_xlim(xlim)\n",
    "_ = ax.set_ylim(ylim)\n",
    "_ = ax.set_xlabel('x')\n",
    "_ = ax.set_ylabel('y')\n",
    "\n",
    "z_lim = ax.get_zlim()\n",
    "_ = ax.set_zlim((-0.1, z_lim[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN GENERIC HMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_kwargs = {\n",
    "    'run_steps': 5000,\n",
    "    'beta': 1.,\n",
    "    'net_weights': [0., 0., 0.],\n",
    "    'eps': runner.eps,\n",
    "}\n",
    "\n",
    "run_str = run_logger._get_run_str(**hmc_kwargs)\n",
    "hmc_kwargs['run_str'] = run_str\n",
    "\n",
    "run_logger.reset(**hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.run(**hmc_kwargs)\n",
    "\n",
    "samples_out_hmc = np.array(run_logger.samples_arr)\n",
    "px_out_hmc = np.array(run_logger.px_arr)\n",
    "\n",
    "inference_dir = os.path.join(model.log_dir, 'inference')\n",
    "io.check_else_make_dir(inference_dir)\n",
    "save_inference_data(samples_out_hmc, px_out_hmc, inference_dir, type_str='HMC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import gmm_plot\n",
    "\n",
    "\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "\n",
    "hmc_plt_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 5000,\n",
    "    'ellipse': False,\n",
    "    'title': 'HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(figs_dir, 'hmc_inference_plot.pdf')\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution,\n",
    "                     samples_out_hmc,\n",
    "                     **hmc_plt_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "hmc_samples = samples_out_hmc.reshape((-1, 2))\n",
    "_samples = hmc_samples[:10000]\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "\n",
    "x = _samples[:, 0]\n",
    "y = _samples[:, 1]\n",
    "\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "values = np.vstack([x, y])\n",
    "kernel = st.gaussian_kde(values)\n",
    "f = np.reshape(kernel(positions).T, xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'coolwarm'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(xx, yy, f, rstride=1, cstride=1,\n",
    "                       cmap=cmap, edgecolor='none', alpha=0.8)\n",
    "# Plot projections of the contours for each dimension.  By choosing offsets\n",
    "# that match the appropriate axes limits, the projected contours will sit on\n",
    "# the 'walls' of the graph\n",
    "cset = ax.contour(xx, yy, f, zdir='z', offset=-0.1, cmap=cmap)\n",
    "cset = ax.contour(xx, yy, f, zdir='x', offset=xmin, cmap=cmap)\n",
    "cset = ax.contour(xx, yy, f, zdir='y', offset=ymax, cmap=cmap)\n",
    "#_ = ax.axis('equal')\n",
    "#xlim = [xmin, xmax]\n",
    "#ylim = [ymin-0.05, ymax+0.05]\n",
    "#_ = ax.set_xlim(xlim)\n",
    "#_ = ax.set_ylim(ylim)\n",
    "_ = ax.set_xlabel('x')\n",
    "_ = ax.set_ylabel('y')\n",
    "\n",
    "z_lim = ax.get_zlim()\n",
    "_ = ax.set_zlim((-0.1, z_lim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loggers.run_logger import RunLogger\n",
    "from runners.gmm_runner import GaussianMixtureModelRunner\n",
    "\n",
    "run_ops = tf.get_collection('run_ops')\n",
    "inputs = tf.get_collection('inputs')\n",
    "\n",
    "run_logger = RunLogger(params, inputs, run_ops,\n",
    "                       save_lf_data=False,\n",
    "                       model_type='gmm_model')\n",
    "runner = GaussianMixtureModelRunner(sess, params, inputs,\n",
    "                                    run_ops, logger=run_logger)\n",
    "kwargs = {\n",
    "    'run_steps': 5000,\n",
    "    'beta': 1.,\n",
    "    'net_weights': [1., 1., 1.],\n",
    "}\n",
    "runner.run(**kwargs)\n",
    "\n",
    "samples_out = np.array(run_logger.samples_arr)\n",
    "samples_out.shape\n",
    "\n",
    "from plotters.plot_utils import gmm_plot\n",
    "\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 250,\n",
    "    'ellipse': False,\n",
    "    'title': 'L2HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(figs_dir, 'inference_plot.pdf')\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution, samples_out, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     13
    ]
   },
   "outputs": [],
   "source": [
    "samples_out = []\n",
    "px_out = []\n",
    "\n",
    "feed_dict = {\n",
    "    model.x: None,\n",
    "    model.beta: 1.,\n",
    "    model.net_weights[0]: 1.,\n",
    "    model.net_weights[1]: 1.,\n",
    "    model.net_weights[2]: 1.,\n",
    "    model.train_phase: False\n",
    "}\n",
    "samples = np.random.randn(*model.x.shape)\n",
    "num_steps = 5000\n",
    "for i in range(num_steps):\n",
    "    t0 = time.time()\n",
    "    feed_dict.update({\n",
    "        model.x: samples,\n",
    "    })\n",
    "    samples, px = sess.run([model.x_out, model.px], feed_dict=feed_dict)\n",
    "    _px = np.mean(px)\n",
    "    samples_out.append(samples)\n",
    "    px_out.append(_px)\n",
    "    print(f'{i}/{num_steps}, px: {_px:^.4g}, t/step: {time.time() - t0:^.4g}')\n",
    "\n",
    "samples_out = np.array(samples_out)\n",
    "all_samples = samples_out.reshape((-1, 2))\n",
    "x_, y_ = all_samples.T\n",
    "xmean, ymean = x_.mean(), y_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     13
    ]
   },
   "outputs": [],
   "source": [
    "samples_out_hmc = []\n",
    "px_out_hmc = []\n",
    "\n",
    "feed_dict = {\n",
    "    model.x: None,\n",
    "    model.beta: 1.,\n",
    "    model.net_weights[0]: 0.,\n",
    "    model.net_weights[1]: 0.,\n",
    "    model.net_weights[2]: 0.,\n",
    "    model.train_phase: False\n",
    "}\n",
    "samples = np.random.randn(*model.x.shape)\n",
    "num_steps = 5000\n",
    "for i in range(num_steps):\n",
    "    t0 = time.time()\n",
    "    feed_dict.update({\n",
    "        model.x: samples,\n",
    "    })\n",
    "    samples, px = sess.run([model.x_out, model.px], feed_dict=feed_dict)\n",
    "    _px = np.mean(px)\n",
    "    samples_out_hmc.append(samples)\n",
    "    px_out_hmc.append(_px)\n",
    "    print(f'{i}/{num_steps}, px: {_px:^.4g}, t/step: {time.time() - t0:^.4g}')\n",
    "    \n",
    "samples_out_hmc = np.array(samples_out_hmc)\n",
    "all_samples_hmc = samples_out_hmc.reshape((-1, 2))\n",
    "x_hmc, y_hmc = all_samples_hmc.T\n",
    "xmean_hmc, ymean_hmc = x_hmc.mean(), y_hmc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "inference_dir = os.path.join(model.log_dir, 'inference')\n",
    "io.check_else_make_dir(inference_dir)\n",
    "\n",
    "l2hmc_shape_str = f'L2HMC samples.shape: {samples_out.shape}\\n'\n",
    "hmc_shape_str = f'HMC samples.shape: {samples_out_hmc.shape}\\n'\n",
    "l2hmc_str = f'L2HMC Averages (x_avg, y_avg): ({xmean:.5g}, {ymean:.5g})\\n'\n",
    "hmc_str = f'HMC Averages (x_avg, y_avg): ({xmean_hmc:.5g}, {ymean_hmc:.5g})\\n'\n",
    "\n",
    "print(l2hmc_shape_str + l2hmc_str)\n",
    "print('\\n')\n",
    "print(hmc_shape_str + hmc_str)\n",
    "\n",
    "samples_out_file = os.path.join(inference_dir, 'inference_samples.pkl')\n",
    "px_out_file = os.path.join(inference_dir, 'inference_probs.pkl')\n",
    "with open(samples_out_file, 'wb') as f:\n",
    "    pickle.dump(samples_out, f)\n",
    "with open(px_out_file, 'wb') as f:\n",
    "    pickle.dump(px_out, f)\n",
    "    \n",
    "samples_out_file_hmc = os.path.join(inference_dir, 'hmc_samples.pkl')\n",
    "px_out_file_hmc = os.path.join(inference_dir, 'hmc_probs.pkl')\n",
    "with open(samples_out_file_hmc, 'wb') as f:\n",
    "    pickle.dump(samples_out_hmc, f)\n",
    "with open(px_out_file_hmc, 'wb') as f:\n",
    "    pickle.dump(px_out_hmc, f)\n",
    "\n",
    "inference_means_file = os.path.join(inference_dir, 'inference_means.txt')\n",
    "with open(inference_means_file, 'w') as f:\n",
    "    _ = f.write(l2hmc_shape_str)\n",
    "    _ = f.write(l2hmc_str)\n",
    "    _ = f.write(20 * '-' + '\\n')\n",
    "    _ = f.write(hmc_shape_str)\n",
    "    _ = f.write(hmc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import _gmm_plot\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "ax = _gmm_plot(model.distribution, all_samples[:10000], ellipse=True)\n",
    "_ = ax.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_out_r = samples_out[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import gmm_plot\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 5,\n",
    "    'ncols': 4,\n",
    "    'num_points': 5000,\n",
    "    'title': 'L2HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(figs_dir, 'inference_plot.pdf'),\n",
    "    'ellipse': True,\n",
    "    'num_contours': 4,\n",
    "    'cmap': None,\n",
    "    'fill': True,\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution, samples_out_r, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#_samples = samples_out_r[:5000, 0]\n",
    "_samples = all_samples[:10000]\n",
    "#xlims, ylims = get_lims(_samples)\n",
    "xmin, xmax = [-1., 3.]\n",
    "ymin, ymax = [-1., 3.]\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "\n",
    "x = _samples[:, 0]\n",
    "y = _samples[:, 1]\n",
    "\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "values = np.vstack([x, y])\n",
    "kernel = st.gaussian_kde(values)\n",
    "z = np.reshape(kernel(positions).T, xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(xx, yy, z, rstride=1, cstride=1,\n",
    "                       cmap='coolwarm', edgecolor='none', alpha=0.5)\n",
    "# Plot projections of the contours for each dimension.  By choosing offsets\n",
    "# that match the appropriate axes limits, the projected contours will sit on\n",
    "# the 'walls' of the graph\n",
    "cset = ax.contour(xx, yy, z, zdir='z', offset=-0.1, cmap='coolwarm')\n",
    "cset = ax.contour(xx, yy, z, zdir='x', offset=xmin, cmap='coolwarm')\n",
    "cset = ax.contour(xx, yy, z, zdir='y', offset=ymax, cmap='coolwarm')\n",
    "#_ = ax.axis('equal')\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "z_lim = ax.get_zlim()\n",
    "ax.set_zlim((-0.1, z_lim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_utils import gmm_plot\n",
    "\n",
    "hmc_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 500,\n",
    "    'title': 'HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(figs_dir, 'hmc_plot.pdf'),\n",
    "    'ellipse': False,\n",
    "    'num_contours': 4,\n",
    "    'cmap': None,\n",
    "    'fill': True,\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution, samples_out_hmc, **hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "xlims, ylims = get_lims(samples_out[:, 0])\n",
    "xmin, xmax = xlims\n",
    "ymin, ymax = ylims\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "\n",
    "x = samples_out[:, 0, 0]\n",
    "y = samples_out[:, 0, 1]\n",
    "\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "values = np.vstack([x, y])\n",
    "kernel = st.gaussian_kde(values)\n",
    "f = np.reshape(kernel(positions).T, xx.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "surf = ax.plot_surface(xx, yy, f, rstride=1, cstride=1,\n",
    "                       cmap='coolwarm', edgecolor='none')#alpha=0.3)\n",
    "#ax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3)\n",
    "\n",
    "# Plot projections of the contours for each dimension.  By choosing offsets\n",
    "# that match the appropriate axes limits, the projected contours will sit on\n",
    "# the 'walls' of the graph\n",
    "#cset = ax.contour(xx, yy, f, zdir='z', offset=-1, cmap='coolwarm')\n",
    "#cset = ax.contour(xx, yy, f, zdir='x', offset=-2, cmap='coolwarm')\n",
    "#cset = ax.contour(xx, yy, f, zdir='y', offset=-2, cmap='coolwarm')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('PDF')\n",
    "#ax.set_title('Surface plot of Gaussian 2D KDE')\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5) # add color bar indicating the PDF\n",
    "ax.view_init(60, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.colormaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "from plotters.plot_utils import draw_ellipse\n",
    "#target_samples = model.distribution.get_samples(5000)\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "#y_lims = 1. * np.array([-0.7, 1.35])\n",
    "nrows = ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols)#, sharex=True, sharey=True)\n",
    "#x_lims=[-0.5, 1.6]\n",
    "#y_lims=[-1., 1.45]\n",
    "mus = model.distribution.mus\n",
    "sigmas = model.distribution.sigmas\n",
    "pis = model.distribution.pis\n",
    "#xmin = ymin = np.min(mus) - 4 * np.max(sigmas)\n",
    "#xmax = ymax = np.max(mus) + 4 * np.max(sigmas)\n",
    "#xlims = [xmin, xmax]\n",
    "#ylims = [ymin, ymax]\n",
    "#  xmin = - np.min(mus) - 5 * np.max(sigmas)\n",
    "\n",
    "#xlims = [-2, 2]\n",
    "#ylims = [-2, 2]\n",
    "#plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "_idx = 0\n",
    "for idx in range(nrows):\n",
    "    for jdx in range(ncols):\n",
    "        #_ = plot_gaussian_contours(mus, covs,\n",
    "        #                           xlims=xlims,\n",
    "        #                           ylims=ylims,\n",
    "        #                           res=200,\n",
    "        #                           ax=axes[idx, jdx])\n",
    "        w_factor = 0.2 / np.max(pis)\n",
    "        for pos, covar, w in zip(mus, sigmas, pis):\n",
    "            _ = draw_ellipse(pos, covar,\n",
    "                             ax=axes[idx, jdx],\n",
    "                             #alpha = 1.,\n",
    "                             alpha=w * w_factor,\n",
    "                             fill=True, lw=1.5)\n",
    "\n",
    "        #xlims, ylims = get_lims(samples_out[:, _idx])\n",
    "        #_ = plot_gaussian_contours(mus, sigmas, ax=axes[idx, jdx],\n",
    "        #                           xlims=xlims, ylims=ylims)\n",
    "        \n",
    "        _ = axes[idx, jdx].plot(samples_out[:100, _idx, 0],\n",
    "                                samples_out[:100, _idx, 1],\n",
    "                                marker=',', color='gray', alpha=0.4, ls='-',\n",
    "                                zorder=2)\n",
    "        _ = axes[idx, jdx].plot(samples_out[:50, _idx, 0],\n",
    "                                samples_out[:50, _idx, 1],\n",
    "                                marker=',', color='k', alpha=0.6, ls='',\n",
    "                                zorder=2)\n",
    "        _ = axes[idx, jdx].axis('equal')\n",
    "        #_ = axes[idx, jdx].set_xlim(xlims)\n",
    "        #_ = axes[idx, jdx].set_ylim(ylims)\n",
    "        _ = axes[idx, jdx].set_xticks([])\n",
    "        _ = axes[idx, jdx].set_yticks([])\n",
    "        #_ = axes[idx, jdx].autoscale()\n",
    "        _idx += 1\n",
    "        \n",
    "_ = axes[0, 0].set_yticks(model.distribution.mus[0])\n",
    "_ = axes[0, 0].set_yticklabels([str(i) for i in model.distribution.mus[0]])\n",
    "_ = axes[-1, -1].set_xticks(model.distribution.mus[1])\n",
    "_ = axes[-1, -1].set_xticklabels([str(i) for i in model.distribution.mus[1]])\n",
    "_ = fig.suptitle('L2HMC Chains (ESJD loss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mpl.cm.viridis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idxs = np.linspace(0.1, 0.75, 4)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax.add_patch(Ellipse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y_true = make_blobs(n_samples=400, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "X = X[:, ::-1] # flip axes for better plotting\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gmm = mixture.GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sklearn.mixture.GaussianMixture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gmm = mixture.GMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax.set_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from plotters.plot_utils import gmm_plot\n",
    "\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "xlims = [-1, 2]\n",
    "ylims = [-0.5, 2]\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 500,\n",
    "    'out_file': None,\n",
    "    'title': 'L2HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(figs_dir, 'inference_plot.pdf'),\n",
    "    'xlims': xlims,\n",
    "    'ylims': ylims\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution, samples_out, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.contour()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RESTORE FROM CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(model.log_dir, 'checkpoints')\n",
    "checkpoint_file = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.import_meta_graph(f'{checkpoint_file}.meta')\n",
    "saver.restore(sess, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_ops = tf.get_collection('run_ops')\n",
    "inputs = tf.get_collection('inputs')\n",
    "\n",
    "from loggers.run_logger import RunLogger\n",
    "run_logger = RunLogger(params, inputs, run_ops,\n",
    "                       save_lf_data=False, model_type='gmm_model')\n",
    "\n",
    "from runners.gmm_runner import GaussianMixtureModelRunner\n",
    "runner = GaussianMixtureModelRunner(sess, params, inputs,\n",
    "                                    run_ops, logger=run_logger)\n",
    "\n",
    "kwargs = {\n",
    "    'run_steps': 5000,\n",
    "    'beta': 1.,\n",
    "    'net_weights': [1., 1., 1.],\n",
    "}\n",
    "runner.run(**kwargs)\n",
    "\n",
    "samples_out = np.array(run_logger.samples_arr)\n",
    "samples_out.shape\n",
    "\n",
    "from plotters.plot_utils import gmm_plot\n",
    "\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 250,\n",
    "    'ellipse': False,\n",
    "    'title': 'L2HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(figs_dir, 'inference_plot.pdf')\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution, samples_out, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_logger.run_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    run_logger.inputs_dict['x']: np.random.randn(*(params['batch_size'], params['x_dim'])),\n",
    "    run_logger.inputs_dict['beta']: 1.,\n",
    "    run_logger.inputs_dict['net_weights'][0]: 1.,\n",
    "    run_logger.inputs_dict['net_weights'][1]: 1.,\n",
    "    run_logger.inputs_dict['net_weights'][2]: 1.,\n",
    "    run_logger.inputs_dict['train_phase']: False,\n",
    "}\n",
    "l2hmc_fns_f = sess.run(run_logger.run_ops_dict['fns_out_f'], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_l2hmc_fns(fns):\n",
    "    fnsT = np.transpose(fns, axes=[2, 1, 0, 3, 4])\n",
    "\n",
    "    out_fns = {}\n",
    "    names = ['scale', 'translation', 'transformation']\n",
    "    subnames = ['v1', 'x1', 'x2', 'v2']\n",
    "    for idx, name in enumerate(names):\n",
    "        out_fns[name] = {}\n",
    "        for subidx, subname in enumerate(subnames):\n",
    "            out_fns[name][subname] = fnsT[idx][subidx]\n",
    "\n",
    "    return out_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l2hmc_fns_f_dict = extract_l2hmc_fns(l2hmc_fns_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l2hmc_fns_f_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scale_fns_f = l2hmc_fns_f_dict['scale']\n",
    "scale_fns_f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "translation_fns_f = l2hmc_fns_f_dict['translation']\n",
    "transformation_fns_f = l2hmc_fns_f_dict['transformation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "translation_fns_f['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scale_fns_f['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_out = []\n",
    "px_out = []\n",
    "\n",
    "feed_dict = {\n",
    "    x: None,\n",
    "    beta: 1.,\n",
    "    net_weights[0]: 1.,\n",
    "    net_weights[1]: 1.,\n",
    "    net_weights[2]: 1.,\n",
    "    train_phase: False\n",
    "}\n",
    "#samples = model.distribution.get_samples(model.num_samples)\n",
    "samples = np.random.randn(*model.x.shape)\n",
    "num_steps = 5000\n",
    "for i in range(num_steps):\n",
    "    t0 = time.time()\n",
    "    feed_dict.update({\n",
    "        x: samples,\n",
    "    })\n",
    "    samples, px_ = sess.run([x_out, px], feed_dict=feed_dict)\n",
    "    _px = np.mean(px_)\n",
    "    samples_out.append(samples)\n",
    "    px_out.append(_px)\n",
    "    print(f'{i}/{num_steps}, px: {_px:^.4g}, t/step: {time.time() - t0:^.4g}')\n",
    "\n",
    "samples_out = np.array(samples_out)\n",
    "all_samples = samples_out.reshape((-1, 2))\n",
    "x_, y_ = all_samples.T\n",
    "xmean, ymean = x_.mean(), y_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     13
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_out_hmc = []\n",
    "px_out_hmc = []\n",
    "\n",
    "feed_dict = {\n",
    "    model.x: None,\n",
    "    model.beta: 1.,\n",
    "    model.net_weights[0]: 0.,\n",
    "    model.net_weights[1]: 0.,\n",
    "    model.net_weights[2]: 0.,\n",
    "    model.train_phase: False\n",
    "}\n",
    "samples = model.distribution.get_samples(model.num_samples)\n",
    "num_steps = 5000\n",
    "for i in range(num_steps):\n",
    "    t0 = time.time()\n",
    "    feed_dict.update({\n",
    "        model.x: samples,\n",
    "    })\n",
    "    samples, px = sess.run([model.x_out, model.px], feed_dict=feed_dict)\n",
    "    _px = np.mean(px)\n",
    "    samples_out_hmc.append(samples)\n",
    "    px_out_hmc.append(_px)\n",
    "    print(f'{i}/{num_steps}, px: {_px:^.4g}, t/step: {time.time() - t0:^.4g}')\n",
    "    \n",
    "samples_out_hmc = np.array(samples_out_hmc)\n",
    "all_samples_hmc = samples_out_hmc.reshape((-1, 2))\n",
    "x_hmc, y_hmc = all_samples_hmc.T\n",
    "xmean_hmc, ymean_hmc = x_hmc.mean(), y_hmc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inference_dir = os.path.join(model.log_dir, 'inference')\n",
    "io.check_else_make_dir(inference_dir)\n",
    "\n",
    "l2hmc_shape_str = f'L2HMC samples.shape: {samples_out.shape}\\n'\n",
    "hmc_shape_str = f'HMC samples.shape: {samples_out_hmc.shape}\\n'\n",
    "l2hmc_str = f'L2HMC Averages (x_avg, y_avg): ({xmean:.5g}, {ymean:.5g})\\n'\n",
    "hmc_str = f'HMC Averages (x_avg, y_avg): ({xmean_hmc:.5g}, {ymean_hmc:.5g})\\n'\n",
    "\n",
    "print(l2hmc_shape_str + l2hmc_str)\n",
    "print('\\n')\n",
    "print(hmc_shape_str + hmc_str)\n",
    "\n",
    "samples_out_file = os.path.join(inference_dir, 'inference_samples.pkl')\n",
    "px_out_file = os.path.join(inference_dir, 'inference_probs.pkl')\n",
    "with open(samples_out_file, 'wb') as f:\n",
    "    pickle.dump(samples_out_file, f)\n",
    "with open(px_out_file, 'wb') as f:\n",
    "    pickle.dump(px_out, f)\n",
    "    \n",
    "samples_out_file_hmc = os.path.join(inference_dir, 'hmc_samples.pkl')\n",
    "px_out_file_hmc = os.path.join(inference_dir, 'hmc_probs.pkl')\n",
    "with open(samples_out_file_hmc, 'wb') as f:\n",
    "    pickle.dump(samples_out_hmc, f)\n",
    "with open(px_out_file_hmc, 'wb') as f:\n",
    "    pickle.dump(px_out_hmc, f)\n",
    "\n",
    "inference_means_file = os.path.join(inference_dir, 'inference_means.txt')\n",
    "with open(inference_means_file, 'w') as f:\n",
    "    _ = f.write(l2hmc_shape_str)\n",
    "    _ = f.write(l2hmc_str)\n",
    "    _ = f.write(20 * '-' + '\\n')\n",
    "    _ = f.write(hmc_shape_str)\n",
    "    _ = f.write(hmc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from plotters.plot_utils import gmm_plot\n",
    "\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 4,\n",
    "    'ncols': 4,\n",
    "    'num_points': 500,\n",
    "    'out_file': None,\n",
    "    'title': 'L2HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(figs_dir, 'inference_plot.pdf')\n",
    "}\n",
    "fig, axes = gmm_plot(model.distribution, samples_out, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "axes[0, 0].set_yticks(model.distribution.mus[:, 1])\n",
    "axes[0, 0].set_yticks(model.distribution.mus[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l2hmc_kwargs = {\n",
    "    'nrows': 4,\n",
    "    'ncols': 4,\n",
    "    'num_points': 500,\n",
    "    'out_file': None,\n",
    "    'title': 'L2HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(gaussian_dir, 'figures',\n",
    "                             'l2hmc_chains_5000_eps0144.pdf')\n",
    "    \n",
    "}\n",
    "fig_g, axes_g = inference_plot(model, samples_out_g, **l2hmc_kwargs)\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 500,\n",
    "    'out_file': None,\n",
    "    'title': 'L2HMC (ESJD losss)'\n",
    "}\n",
    "fig, axes = inference_plot(model, samples_out, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#target_samples = model.distribution.get_samples(5000)\n",
    "samples_out = np.array(samples_out)\n",
    "all_samples = samples_out.reshape((-1, 2))\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "#x_lims = 1.5 * np.array([-0.275, 1.52])\n",
    "#y_lims = 1.5 * np.array([-0.7, 1.35])\n",
    "nrows = ncols = 4\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols)#, sharex=True, sharey=True)\n",
    "#x_lims=[-0.5, 1.6]\n",
    "#y_lims=[-1., 1.45]\n",
    "#plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "xmin = ymin = -1.5\n",
    "xmax = ymax = 2.0\n",
    "x_lims = [xmin, xmax]\n",
    "y_lims = [ymin, ymax]\n",
    "\n",
    "_idx = 0\n",
    "for idx in range(nrows):\n",
    "    for jdx in range(ncols):\n",
    "        _ = plot_gaussian_contours(mus, covs,\n",
    "                                   x_lims=x_lims,\n",
    "                                   y_lims=y_lims,\n",
    "                                   res=200,\n",
    "                                   ax=axes[idx, jdx])\n",
    "        _ = axes[idx, jdx].plot(samples_out[-1000:, _idx, 0],\n",
    "                                samples_out[-1000:, _idx, 1],\n",
    "                                marker=',', color='gray', alpha=0.4, ls='-')\n",
    "        _ = axes[idx, jdx].plot(samples_out[-1000:, _idx, 0],\n",
    "                                samples_out[-1000:, _idx, 1],\n",
    "                                marker=',', color='k', alpha=0.6, ls='')\n",
    "        _ = axes[idx, jdx].axis('equal')\n",
    "        _ = axes[idx, jdx].set_xticks([])\n",
    "        _ = axes[idx, jdx].set_yticks([])\n",
    "        _idx += 1\n",
    "        \n",
    "_ = axes[0, 0].set_yticks(model.distribution.mus[0])\n",
    "_ = axes[0, 0].set_yticklabels([str(i) for i in model.distribution.mus[0]])\n",
    "_ = axes[-1, -1].set_xticks(model.distribution.mus[1])\n",
    "_ = axes[-1, -1].set_xticklabels([str(i) for i in model.distribution.mus[1]])\n",
    "_ = fig.suptitle('L2HMC Chains (standard loss)')\n",
    "        \n",
    "N = samples_out_hmc.shape[0]\n",
    "eps_np = sess.run(model.dynamics.eps)\n",
    "eps_str = f'{eps_np:.3g}'.replace('.', '')\n",
    "out_file = os.path.join(figs_dir, f'l2hmc_chains_{N}_eps{eps_str}.pdf')\n",
    "io.log(f'Saving figure to: {out_file}.') \n",
    "fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#target_samples = model.distribution.get_samples(5000)\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "x_lims = 1.5 * np.array([-0.275, 1.52])\n",
    "y_lims = 1.5 * np.array([-0.7, 1.35])\n",
    "#x_lims=[-0.35, 1.55]\n",
    "#y_lims=[-0.7, 1.35]\n",
    "nrows = ncols = 4\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols)#, sharex=True, sharey=True)\n",
    "#_ = plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "_idx = 0\n",
    "for idx in range(nrows):\n",
    "    for jdx in range(ncols):\n",
    "        _ = plot_gaussian_contours(mus, covs,\n",
    "                                   x_lims=x_lims,\n",
    "                                   y_lims=y_lims,\n",
    "                                   res=200,\n",
    "                                   ax=axes[idx, jdx])\n",
    "        _ = axes[idx, jdx].plot(samples_out_hmc[-1000:, _idx, 0],\n",
    "                                samples_out_hmc[-1000:, _idx, 1],\n",
    "                                marker=',', color='gray', alpha=0.4, ls='-')\n",
    "        _ = axes[idx, jdx].plot(samples_out_hmc[-1000:, _idx, 0],\n",
    "                                samples_out_hmc[-1000:, _idx, 1],\n",
    "                                marker=',', color='k', alpha=0.6, ls='')\n",
    "        _ = axes[idx, jdx].axis('equal')\n",
    "        _ = axes[idx, jdx].set_xticks([])\n",
    "        _ = axes[idx, jdx].set_yticks([])\n",
    "        _idx += 1\n",
    "        \n",
    "_ = axes[0, 0].set_yticks(model.distribution.mus[0])\n",
    "_ = axes[0, 0].set_yticklabels([str(i) for i in model.distribution.mus[0]])\n",
    "_ = axes[-1, -1].set_xticks(model.distribution.mus[1])\n",
    "_ = axes[-1, -1].set_xticklabels([str(i) for i in model.distribution.mus[1]])\n",
    "_ = fig.suptitle('HMC Chains (standard loss)')\n",
    "# _ = fig.tight_layout()\n",
    "\n",
    "N = samples_out_hmc.shape[0]\n",
    "eps_np = sess.run(model.dynamics.eps)\n",
    "eps_str = f'{eps_np:.3g}'.replace('.', '')\n",
    "out_file = os.path.join(figs_dir, f'hmc_chains_{N}_eps{eps_str}.pdf')\n",
    "io.log(f'Saving figure to: {out_file}.') \n",
    "_ = fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g_dir = '../../gmm_logs/2019_09_12/2019_09_12_1743_gaussian_loss/'\n",
    "gaussian_dir = os.path.join(*g_dir.split('/'))\n",
    "px_out_file_g = os.path.join(gaussian_dir, 'px_out.pkl')\n",
    "samples_out_file_g = os.path.join(gaussian_dir, 'samples_out.pkl')\n",
    "\n",
    "with open(px_out_file_g, 'rb') as f:\n",
    "    px_out_g = pickle.load(f)\n",
    "    \n",
    "with open(samples_out_file_g, 'rb') as f:\n",
    "    samples_out_g = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "px_out_g  = np.array(px_out_g)\n",
    "samples_out_g = np.array(samples_out_g)\n",
    "px_out_g.shape\n",
    "samples_out_g.shape\n",
    "\n",
    "print(f'GAUSSIAN LOSS:\\n')\n",
    "print(f' accept_prob:\\n ')\n",
    "print(f'  {px_out_g[:50]}\\n')\n",
    "print(f' avg. accept_prob:\\n')\n",
    "print(f'  {np.mean(px_out_g):.5g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'GAUSSIAN LOSS:\\n')\n",
    "print(f' accept_prob:\\n ')\n",
    "print(f'  {px_out_g[:50]}\\n')\n",
    "print(f' avg. accept_prob:\\n')\n",
    "print(f'  {np.mean(px_out_g):.5g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f' accept_prob:\\n ')\n",
    "print(f'  {px_out[:50]}\\n')\n",
    "print(f' avg. accept_prob:  {np.mean(px_out):.5g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'accept_prob (gaussian_loss):\\n {px_out_g[:50]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'accept_prob (standard loss):\\n {px_out[:50]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_out_file = os.path.join(model.log_dir, 'samples_out.pkl')\n",
    "samples_out_hmc_file = os.path.join(model.log_dir, 'samples_out_hmc.pkl')\n",
    "px_out_file = os.path.join(model.log_dir, 'px_out.pkl')\n",
    "px_out_hmc_file = os.path.join(model.log_dir, 'px_out_hmc.pkl')\n",
    "\n",
    "with open(samples_out_file, 'wb') as f:\n",
    "    pickle.dump(samples_out, f)\n",
    "with open(px_out_file, 'wb') as f:\n",
    "    pickle.dump(px_out, f)\n",
    "    \n",
    "with open(samples_out_hmc_file, 'wb') as f:\n",
    "    pickle.dump(samples_out_hmc, f)\n",
    "with open(px_out_hmc_file, 'wb') as f:\n",
    "    pickle.dump(px_out_hmc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open(samples_out_file, 'rb') as f:\n",
    "    samples_in = pickle.load(f)\n",
    "with open(px_out_file, 'rb') as f:\n",
    "    px_in = pickle.load(f)\n",
    "    \n",
    "with open(samples_out_hmc_file, 'rb') as f:\n",
    "    samples_in_hmc = pickle.load(f)\n",
    "with open(px_out_hmc_file, 'rb') as f:\n",
    "    px_in_hmc = pickle.load(f)\n",
    "   \n",
    "np.allclose(samples_out, samples_in)\n",
    "np.allclose(px_out, px_in)\n",
    "\n",
    "np.allclose(samples_out_hmc, samples_in_hmc)\n",
    "np.allclose(px_in_hmc, px_out_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#target_samples = model.distribution.get_samples(5000)\n",
    "samples_out = np.array(samples_out)\n",
    "all_samples = samples_out.reshape((-1, 2))\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "x_lims = 1.5 * np.array([-0.275, 1.52])\n",
    "y_lims = 1.5 * np.array([-0.7, 1.35])\n",
    "nrows = ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols)#, sharex=True, sharey=True)\n",
    "#x_lims=[-0.5, 1.6]\n",
    "#y_lims=[-1., 1.45]\n",
    "#plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "_idx = 0\n",
    "for idx in range(nrows):\n",
    "    for jdx in range(ncols):\n",
    "        _ = plot_gaussian_contours(mus, covs,\n",
    "                                   x_lims=x_lims,\n",
    "                                   y_lims=y_lims,\n",
    "                                   res=200,\n",
    "                                   ax=axes[idx, jdx])\n",
    "        _ = axes[idx, jdx].plot(samples_out[:50, _idx, 0],\n",
    "                                samples_out[:50, _idx, 1],\n",
    "                                marker=',', color='gray', alpha=0.4, ls='-')\n",
    "        _ = axes[idx, jdx].plot(samples_out[:50, _idx, 0],\n",
    "                                samples_out[:50, _idx, 1],\n",
    "                                marker=',', color='k', alpha=0.6, ls='')\n",
    "        _ = axes[idx, jdx].axis('equal')\n",
    "        _ = axes[idx, jdx].set_xticks([])\n",
    "        _ = axes[idx, jdx].set_yticks([])\n",
    "        _idx += 1\n",
    "        \n",
    "_ = axes[0, 0].set_yticks(model.distribution.mus[0])\n",
    "_ = axes[0, 0].set_yticklabels([str(i) for i in model.distribution.mus[0]])\n",
    "_ = axes[-1, -1].set_xticks(model.distribution.mus[1])\n",
    "_ = axes[-1, -1].set_xticklabels([str(i) for i in model.distribution.mus[1]])\n",
    "_ = fig.suptitle('L2HMC Chains (ESJD loss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import logsumexp\n",
    "\n",
    "\n",
    "def quadratic_gaussian_np(x, mu, S):\n",
    "    try:\n",
    "        return np.diag(0.5 * np.matmul(\n",
    "            np.matmul(x - mu, S),\n",
    "            np.transpose(x - mu)\n",
    "        ))\n",
    "    except:\n",
    "        return np.\n",
    "\n",
    "\n",
    "def minus_log_likelihood_np(distribution, x):\n",
    "    V = np.concatenate([np.expand_dims(\n",
    "        -quadratic_gaussian_np(x, distribution.mus[i],\n",
    "                               distribution.i_sigmas[i])\n",
    "        + np.log(distribution.constants[i]), axis=1\n",
    "    ) for i in range(distribution.nb_mixtures)], axis=1)\n",
    "\n",
    "    return - logsumexp(V, axis=1), V  # using scipy.misc.logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rand_samps = model.distribution.get_samples(10)\n",
    "rand_samps[:5]\n",
    "XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_lims = 1.5 * np.array([-0.35, 1.60])\n",
    "y_lims = 1.5 * np.array([-0.60, 1.35])\n",
    "\n",
    "\n",
    "x = np.linspace(x_lims[0], x_lims[1], 30)\n",
    "y = np.linspace(y_lims[0], y_lims[1], 30)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rand_samps[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Z = minus_log_likelihood_np(model.distribution, (X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "XY = np.array([X, Y])\n",
    "XY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Z = minus_log_likelihood_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X[:5], X.shape\n",
    "Y[:5], Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return np.sin(np.sqrt(x ** 2 + y ** 2))\n",
    "\n",
    "x = np.linspace(-6, 6, 30)\n",
    "y = np.linspace(-6, 6, 30)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def U(distribution, x, y):\n",
    "    c0 = distribution.constants[0]\n",
    "    gauss0 = \n",
    "    - np.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gaussian_np(x, mu, S):\n",
    "def U(x, y):\n",
    "    return np.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q = rand_samps[0].dot(rand_samps[0].T)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gauss_np = quadratic_gaussian_np(rand_samps[0],\n",
    "                                 model.distribution.mus[0],\n",
    "                                 model.distribution.i_sigmas[0])\n",
    "gauss_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X, Y, Z, 50, cmap='binary')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#target_samples = model.distribution.get_samples(5000)\n",
    "figs_dir = os.path.join(model.log_dir, 'figures')\n",
    "io.check_else_make_dir(figs_dir)\n",
    "x_lims = 1.5 * np.array([-0.275, 1.52])\n",
    "y_lims = 1.5 * np.array([-0.7, 1.35])\n",
    "#x_lims=[-0.35, 1.55]\n",
    "#y_lims=[-0.7, 1.35]\n",
    "nrows = ncols = 2\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols)#, sharex=True, sharey=True)\n",
    "#_ = plt.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "_idx = 0\n",
    "for idx in range(nrows):\n",
    "    for jdx in range(ncols):\n",
    "        _ = plot_gaussian_contours(mus, covs,\n",
    "                                   x_lims=x_lims,\n",
    "                                   y_lims=y_lims,\n",
    "                                   res=200,\n",
    "                                   ax=axes[idx, jdx])\n",
    "        _ = axes[idx, jdx].plot(samples_out_hmc[:100, _idx, 0],\n",
    "                                samples_out_hmc[:100, _idx, 1],\n",
    "                                marker=',', color='gray', alpha=0.4, ls='-')\n",
    "        _ = axes[idx, jdx].plot(samples_out_hmc[:100, _idx, 0],\n",
    "                                samples_out_hmc[:100, _idx, 1],\n",
    "                                marker=',', color='k', alpha=0.6, ls='')\n",
    "        _ = axes[idx, jdx].axis('equal')\n",
    "        _ = axes[idx, jdx].set_xticks([])\n",
    "        _ = axes[idx, jdx].set_yticks([])\n",
    "        _idx += 1\n",
    "        \n",
    "_ = axes[0, 0].set_yticks(model.distribution.mus[0])\n",
    "_ = axes[0, 0].set_yticklabels([str(i) for i in model.distribution.mus[0]])\n",
    "_ = axes[-1, -1].set_xticks(model.distribution.mus[1])\n",
    "_ = axes[-1, -1].set_xticklabels([str(i) for i in model.distribution.mus[1]])\n",
    "_ = fig.suptitle('HMC Chains (ESJD loss)')\n",
    "# _ = fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def inference_plot(model, samples, **kwargs):\n",
    "    nrows = kwargs.get('nrows', 3)\n",
    "    ncols = kwargs.get('ncols', 3)\n",
    "    out_file = kwargs.get('out_file', None)\n",
    "    title = kwargs.get('title', None)\n",
    "    num_points = kwargs.get('num_points', 2000)\n",
    "    \n",
    "    mus = model.distribution.mus\n",
    "    sigmas = model.distribution.sigmas\n",
    "    \n",
    "    \n",
    "    #cov_max = np.max(model.distribution.sigmas)\n",
    "    #x_min = np.min(np.min(model.distribution.mus[:, 0])) - 4 * cov_max\n",
    "    #x_max = np.max(np.max(model.distribution.mus[:, 0])) + 4 * cov_max\n",
    "    #y_min = np.min(np.min(model.distribution.mus[:, 1])) - 4 * cov_max\n",
    "    #y_max = np.max(np.max(model.distribution.mus[:, 1])) + 4 * cov_max\n",
    "    \n",
    "    #x_lims = np.array([x_min, x_max])\n",
    "    #y_lims = np.array([y_min, y_max])\n",
    "    \n",
    "    x_lims = 1.5 * np.array([-0.275, 1.52])\n",
    "    y_lims = 1.5 * np.array([-0.7, 1.35])\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    _idx = 0\n",
    "    for idx in range(nrows):\n",
    "        for jdx in range(ncols):\n",
    "            ax = axes[idx, jdx]\n",
    "            _ = plot_gaussian_contours(mus, sigmas,\n",
    "                                       x_lims=x_lims,\n",
    "                                       y_lims=y_lims,\n",
    "                                       res=200,\n",
    "                                       ax=ax)\n",
    "            _ = ax.plot(samples[:num_points, _idx, 0],\n",
    "                        samples[:num_points, _idx, 1],\n",
    "                        marker=',', ls='-',  color='gray', alpha=0.4)\n",
    "            _ = ax.plot(samples[:num_points, _idx, 0],\n",
    "                        samples[:num_points, _idx, 1],\n",
    "                        marker=',', ls='', color='k', alpha=0.6)\n",
    "            _ = axes[idx, jdx].axis('equal')\n",
    "            _ = axes[idx, jdx].set_xticks([])\n",
    "            _ = axes[idx, jdx].set_yticks([])\n",
    "            _idx += 1\n",
    "\n",
    "    _ = axes[0, 0].set_yticks(mus[0])\n",
    "    _ = axes[0, 0].set_yticklabels([str(i) for i in mus[0]])\n",
    "    _ = axes[-1, -1].set_xticks(mus[1])\n",
    "    _ = axes[-1, -1].set_xticklabels([str(i) for i in mus[1]])\n",
    "    if title is not None:\n",
    "        _ = fig.suptitle(title)\n",
    "    if out_file is not None:\n",
    "        print(f'Saving figure to: {out_file}.')\n",
    "        plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "        \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l2hmc_kwargs = {\n",
    "    'nrows': 4,\n",
    "    'ncols': 4,\n",
    "    'num_points': 500,\n",
    "    'out_file': None,\n",
    "    'title': 'L2HMC (Gaussian losss)',\n",
    "    'out_file': os.path.join(gaussian_dir, 'figures',\n",
    "                             'l2hmc_chains_5000_eps0144.pdf')\n",
    "    \n",
    "}\n",
    "fig_g, axes_g = inference_plot(model, samples_out_g, **l2hmc_kwargs)\n",
    "\n",
    "l2hmc_kwargs = {\n",
    "    'nrows': 3,\n",
    "    'ncols': 3,\n",
    "    'num_points': 500,\n",
    "    'out_file': None,\n",
    "    'title': 'L2HMC (ESJD losss)'\n",
    "}\n",
    "fig, axes = inference_plot(model, samples_out, **l2hmc_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "def esjd(x1, x2, prob):\n",
    "    \"\"\"Expected squared jump distance (ESJD).\"\"\"\n",
    "    return prob * np.sum(np.square(x1 - x2), axis=1) + 1e-4\n",
    "\n",
    "\n",
    "x_dynamics = model._apply_transition(model.x, model.beta,\n",
    "                                    model.net_weights,\n",
    "                                    model.train_phase,\n",
    "                                    save_lf=model.save_lf)\n",
    "\n",
    "z_dynamics = model._apply_transition(model.z, model.beta,\n",
    "                                    model.net_weights,\n",
    "                                    model.train_phase,\n",
    "                                    save_lf=model.save_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_dynamics_, z_dynamics_ = sess.run([x_dynamics, z_dynamics],\n",
    "                                    feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = getattr(model, 'loss_scale', 0.1)\n",
    "\n",
    "esjd_x = esjd(x_dynamics_['x_in'],\n",
    "              x_dynamics_['x_proposed'],\n",
    "              x_dynamics_['accept_prob'])\n",
    "esjd_z = esjd(z_dynamics_['x_in'],\n",
    "              z_dynamics_['x_proposed'],\n",
    "              z_dynamics_['accept_prob'])\n",
    "\n",
    "x_loss = ls * np.mean(1. / esjd_x) - np.mean(esjd_x) / ls\n",
    "z_loss = ls * np.mean(1. / esjd_z) - np.mean(esjd_z) / ls\n",
    "loss = x_loss + z_loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_esjd = (np.mean(esjd_x) + np.mean(esjd_z)) / 2\n",
    "avg_esjd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eps_np = sess.run(model.dynamics.eps)\n",
    "md_dist = eps_np * model.num_steps\n",
    "md_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "esjd_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_gaussian = np.exp(-0.5 * (esjd_x - md_dist)**2) / np.sqrt(2*np.pi) + 1e-4\n",
    "z_gaussian = np.exp(-0.5 * (esjd_z - md_dist)**2) / np.sqrt(2*np.pi) + 1e-4\n",
    "\n",
    "x_gauss_loss = - ls * np.mean(1. / x_gaussian) + np.mean(x_gaussian) / ls\n",
    "z_gauss_loss = - ls * np.mean(1. / z_gaussian) + np.mean(z_gaussian) / ls\n",
    "gauss_loss = x_gauss_loss + z_gauss_loss\n",
    "gauss_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "esjd_diff = esjd_x - md_dist\n",
    "esjd_diff[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_gaussian = np.exp(-(esjd_diff**2) / 2) / np.sqrt(2*np.pi)\n",
    "x_gaussian[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_x_ = avg_diff_np(xdyn_['x_in'],\n",
    "                        xdyn_['x_proposed'],\n",
    "                        xdyn_['accept_prob'])\n",
    "qg_x_ = np.exp(np.square(lambda_x_) / 2)\n",
    "xl_ = np.mean(qg_x_) / ls\n",
    "xl_inv_ = np.mean(1. / qg_x_) * ls\n",
    "x_loss_ = xl_inv_ - xl_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "qg_x = tf.exp(tf.square(lambda_x) / 2)\n",
    "xl = tf.reduce_mean(qg_x) / ls\n",
    "xl_inv = tf.reduce_mean(1. / qg_x) * ls\n",
    "x_loss = xl_inv - xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.distributions import quadratic_gaussian\n",
    "\n",
    "def avg_diff(x1, x2, prob):\n",
    "    return prob * tf.reduce_sum(model.metric_fn(x1, x2), axis=1) + 1e-4\n",
    "\n",
    "\n",
    "_shape = model.distribution.i_sigmas[0].shape\n",
    "S = np.ones(_shape) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_x = avg_diff(x_data.x_in, x_data.x_proposed, x_data.prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = getattr(model, 'loss_scale', 0.1)\n",
    "\n",
    "qg_x = tf.exp(tf.square(lambda_x) / 2)\n",
    "xl = tf.reduce_mean(qg_x) / ls\n",
    "xl_inv = tf.reduce_mean(1. / qg_x) * ls\n",
    "x_loss = xl_inv - xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_init = np.random.randn(*model.x.shape)\n",
    "feed_dict = {\n",
    "    model.x: samples_init,\n",
    "    model.beta: 1.,\n",
    "    model.net_weights[0]: 1.,\n",
    "    model.net_weights[1]: 1.,\n",
    "    model.net_weights[2]: 1.,\n",
    "    model.train_phase: False\n",
    "}\n",
    "\n",
    "ops = [\n",
    "    lambda_x,\n",
    "    qg_x,\n",
    "    xl,\n",
    "    xl_inv,\n",
    "    x_loss\n",
    "]\n",
    "\n",
    "outputs = sess.run(ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_x_, qg_x_, xl_, xl_inv_, x_loss_ = ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_z = avg_diff(z_data.x_in, z_data.x_proposed, z_data.prob)\n",
    "qg_z = quadratic_gaussian(lambda_z,\n",
    "                          mu=np.zeros(lambda_x.shape),\n",
    "                          S=np.ones(lambda_x.shape))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_shape = model.distribution.i_sigmas[0].shape\n",
    "_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "S = np.ones(_shape)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.distribution.i_sigmas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.distribution.mus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "# NOTE: samples_out.shape = (chain_length, num_chains, 2)\n",
    "#    Where chain_length = number of configurations output \n",
    "#    from MH Accept/Reject (using the trained sampler)\n",
    "print(f'samples_out.shape: {samples_out.shape}\\n\\n')\n",
    "samples_avg = samples_out.mean(axis=0) # get average (x, y) for each chain\n",
    "\n",
    "# Avg `x`, `y` coordinates for each\n",
    "# of the `num_chains` chains ran in parallel\n",
    "_x, _y = samples_avg.T\n",
    "\n",
    "# standard error of the mean\n",
    "_x_err = sem(_x)  \n",
    "_y_err =sem(_y)\n",
    "\n",
    "print(f'avg_x: {_x.mean():.4g} +/- {_x_err:.4g}')\n",
    "print(f'avg_y: {_y.mean():.4g} +/- {_y_err:.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_obs = np.array([_x.mean(), _y.mean()])\n",
    "mean_true = np.array([0.5, 0.5])\n",
    "np.linalg.norm(mean_obs - mean_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_in = tf.random_normal(model.x.shape, dtype=TF_FLOAT, seed=GLOBAL_SEED,\n",
    "                        name='x_reverse_check')\n",
    "v_in = tf.random_normal(model.x.shape, dtype=TF_FLOAT, seed=GLOBAL_SEED,\n",
    "                        name='v_reverse_check')\n",
    "\n",
    "dynamics_check = model.dynamics._check_reversibility(x_in,\n",
    "                                                     v_in,\n",
    "                                                     model.beta,\n",
    "                                                     model.net_weights,\n",
    "                                                     model.train_phase)\n",
    "xf = dynamics_check['xf']\n",
    "vf = dynamics_check['vf']\n",
    "xb = dynamics_check['xb']\n",
    "vb = dynamics_check['vb']\n",
    "\n",
    "feed_dict = {\n",
    "    model.beta: 1.,\n",
    "    model.net_weights[0]: 1.,\n",
    "    model.net_weights[1]: 1.,\n",
    "    model.net_weights[2]: 1.,\n",
    "    model.train_phase: False\n",
    "}\n",
    "\n",
    "xf_, vf_, xb_, vb_, x_in_, v_in_ = sess.run([xf, vf, xb, vb, x_in, v_in],\n",
    "                                            feed_dict=feed_dict)\n",
    "\n",
    "# backward(forward(x_in)) ~ x_in\n",
    "x_diff = np.sum((x_in_ - xb_).T.dot(x_in_ - xb_))\n",
    "v_diff = np.sum((v_in_ - vb_).T.dot(v_in_ - vb_))\n",
    "\n",
    "x_diff, v_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chain_length, num_chains, _ = samples_out.shape\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(target_samples[:, 0], target_samples[:, 1], marker='.', alpha=0.4, ls='', color='lightgray')\n",
    "_ = ax.plot(samples_out[-200:, idx, 0], samples_out[-200:, idx, 1], marker='.', alpha=0.4, ls='--', color='gray')\n",
    "_ = ax.plot(_x.mean(), _y.mean(), marker='.', markersize=10, ls='', color='r', label=f'Avg. over {num_chains} ran for {chain_length} steps')\n",
    "_ = ax.plot(0.5, 0.5, marker='s', markersize=10, ls='', color='blue', label=f'True avg.', fillstyle='none')\n",
    "_ = ax.legend(loc='best')\n",
    "\n",
    "#print(f'<x> = {_x.mean():.3g} +/- {_x_err:.3g}')\n",
    "#print(f'<y> = {_y.mean():.3g} +/- {_y_err:.3g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_x, _y = samples_avg0.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(samples_avg0[:, 0], samples_avg0[:, 1], marker='.', ls='', color='k')\n",
    "ax.plot(_x.mean(), _y.mean(), marker='X', ls='', color='r', markersize=5.)\n",
    "ax.set_xlim((0, 1))\n",
    "ax.set_ylim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_x.mean(), _y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gmm_model.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_x, target_y = gmm_model.means.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_x.mean(), target_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "#data = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 3]], 200)\n",
    "data = samples_out[:, sample_idx]\n",
    "x, y = data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 3]], 200)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "means1, means2 = gmm_model.means\n",
    "means1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gmm_model.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a figure with 6 plot areas\n",
    "from scipy.stats import kde\n",
    "\n",
    "means1, means2 = gmm_model.means\n",
    "    \n",
    "def make_2d_density_plots(chain, name='', out_file=None):\n",
    "    print(f'Chain: {name}')\n",
    "    x, y = chain.T\n",
    "    #data = samples_out[:, idx]\n",
    "    #x, y = data.T\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=6, nrows=1, figsize=(21, 5))\n",
    "\n",
    "    # Everything sarts with a Scatterplot\n",
    "    _ = axes[0].set_title('Scatterplot')\n",
    "    _ = axes[0].plot(x, y, 'ko')\n",
    "    _ = axes[0].plot(means1[0], means1[1], marker='x', markersize=5., color='red')\n",
    "    _ = axes[0].plot(means2[0], means2[1], marker='x', markersize=5., color='red')\n",
    "    # As you can see there is a lot of overplottin here!\n",
    "\n",
    "    # Thus we can cut the plotting window in several hexbins\n",
    "    nbins = 20\n",
    "    _ = axes[1].set_title('Hexbin')\n",
    "    _ = axes[1].hexbin(x, y, gridsize=nbins, cmap=plt.cm.BuGn_r)\n",
    "    _ = axes[1].plot(means1[0], means1[1], marker='x', markersize=5., color='red')\n",
    "    _ = axes[1].plot(means2[0], means2[1], marker='x', markersize=5., color='red')\n",
    "\n",
    "    # 2D Histogram\n",
    "    _ = axes[2].set_title('2D Histogram')\n",
    "    _ = axes[2].hist2d(x, y, bins=nbins, cmap=plt.cm.BuGn_r)\n",
    "    _ = axes[2].plot(means1[0], means1[1], marker='x', markersize=5., color='red')\n",
    "    _ = axes[2].plot(means2[0], means2[1], marker='x', markersize=5., color='red')\n",
    "\n",
    "    # Evaluate a gaussian kde on a regular grid of nbins x nbins over data extents\n",
    "    k = kde.gaussian_kde(chain.T)\n",
    "    xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "    zi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\n",
    "    # plot a density\n",
    "    _ = axes[3].set_title('Calculate Gaussian KDE')\n",
    "    _ = axes[3].pcolormesh(xi, yi, zi.reshape(xi.shape), cmap=plt.cm.BuGn_r)\n",
    "    _ = axes[3].plot(means1[0], means1[1], marker='x', markersize=5., color='red')\n",
    "    _ = axes[3].plot(means2[0], means2[1], marker='x', markersize=5., color='red')\n",
    "\n",
    "    # add shading\n",
    "    _ = axes[4].set_title('2D Density with shading')\n",
    "    _ = axes[4].pcolormesh(xi, yi, zi.reshape(xi.shape), shading='gouraud', cmap=plt.cm.BuGn_r)\n",
    "    _ = axes[4].plot(means1[0], means1[1], marker='x', markersize=5., color='red')\n",
    "    _ = axes[4].plot(means2[0], means2[1], marker='x', markersize=5., color='red')\n",
    "\n",
    "    # contour\n",
    "    _ = axes[5].set_title('Contour')\n",
    "    _ = axes[5].pcolormesh(xi, yi, zi.reshape(xi.shape), shading='gouraud', cmap=plt.cm.BuGn_r)\n",
    "    _ = axes[5].contour(xi, yi, zi.reshape(xi.shape) )\n",
    "    _ = axes[5].plot(means1[0], means1[1], marker='x', markersize=5., color='red')\n",
    "    _ = axes[5].plot(means2[0], means2[1], marker='x', markersize=5., color='red')\n",
    "    _ = plt.suptitle(f'chain.shape: {chain.shape}', fontsize=16)\n",
    "    \n",
    "    if out_file is not None:\n",
    "        print(f'Saving figure to: {out_file}')\n",
    "        plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_samples = samples_out.reshape(-1, 2)\n",
    "all_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_dir = '../figures/gmm_figures/'\n",
    "for idx in range(5):\n",
    "    out_file = os.path.join(*out_dir.split('/'), f'gmm_density_plots_{idx}.pdf')\n",
    "    _ = make_2d_density_plots(samples_out[:, idx], name=f'{idx} idx', out_file=out_file)\n",
    "    \n",
    "all_file = os.path.join(*out_dir.split('/'), 'gmm_density_plots_all_chains.pdf')\n",
    "_ = make_2d_density_plots(all_samples, name='all chains', out_file=all_file)\n",
    "\n",
    "target_file = os.path.join(*out_dir.split('/'), f'gmm_density_plots_target_dist.pdf')\n",
    "_ = make_2d_density_plots(target_samples, name='target distribution', out_file=target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_file = os.path.join(*out_dir.split('/'), 'gmm_density_plots_all_chains2.pdf')\n",
    "_ = make_2d_density_plots(all_samples[-20000:], name='all chains2', out_file=all_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models.gmm_model import distribution_arr\n",
    "\n",
    "x_dim = 2\n",
    "sigma = 0.02\n",
    "centers = 1\n",
    "means = np.zeros((x_dim, x_dim), dtype=np.float32)\n",
    "for i in range(x_dim):\n",
    "    means[i::x_dim, i] = centers\n",
    "cov_mtx = sigma * np.eye(x_dim).astype(np.float32)\n",
    "covs = np.array([cov_mtx] * x_dim).astype(np.float32)\n",
    "dist_arr = distribution_arr(x_dim, 2)\n",
    "gmm_dist = GMM(means, covs, dist_arr)\n",
    "\n",
    "gmm_mus = np.array(gmm_dist.mus)\n",
    "gmm_diffs = gmm_mus[1:] - gmm_mus[:-1, :]\n",
    "gmm_distances = [np.sqrt(np.dot(d, d.T)) for d in gmm_diffs]\n",
    "gmm_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "gmm_samples = gmm_dist.get_samples(500)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gmm_samples[:,0], gmm_samples[:,1], marker='o', ls='', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xi.shape"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "10",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
