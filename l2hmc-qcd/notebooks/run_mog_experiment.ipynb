{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from models.mog_model import *\n",
    "from utils.distributions import *\n",
    "\n",
    "#plt.style.use('/Users/saforem2/.config/matplotlib/stylelib/dark_jupyter.mplstyle')\n",
    "#plt.rcParams['figure.facecolor'] = '#474747'\n",
    "\n",
    "%matplotlib notebook\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_legends(axes):\n",
    "    if isinstance(axes, (np.ndarray, list)):\n",
    "        legends = [ax.get_legend() for ax in axes]\n",
    "        for leg in legends:\n",
    "            leg.texts[0].set_color('w')\n",
    "    else:\n",
    "        legend = axes.get_legend()\n",
    "        for idx in range(len(legend.texts)):\n",
    "            legend.texts[idx].set_color('w')\n",
    "    return axes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vline(axes, x, **kwargs):\n",
    "    if isinstance(axes, (np.ndarray, list)):\n",
    "        for ax in axes:\n",
    "            ax.axvline(x, **kwargs)\n",
    "                       #, color='C3', ls=':', lw=2.)\n",
    "    else:\n",
    "        axes.axvline(x, **kwargs)\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ticks(axes):\n",
    "    if isinstance(axes, (np.ndarray, list)):\n",
    "        for idx in range(len(axes)):\n",
    "            axes[idx].tick_params(which='both', \n",
    "                                  color='#474747', \n",
    "                                  labelcolor='k')\n",
    "    else:\n",
    "        axes.tick_params(which='both', color='#474747', labelcolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'x_dim': 2,\n",
    "          'num_distributions': 2,\n",
    "          'eps': 0.1,\n",
    "          'scale': 0.1,\n",
    "          'num_samples': 100,\n",
    "          'means': None,\n",
    "          'sigma': 0.05,\n",
    "          'small_pi': 2E-16,\n",
    "          'lr_init': 1e-2,\n",
    "          'temp_init': 10,\n",
    "          'annealing_steps': 200,\n",
    "          'annealing_factor': 0.98,\n",
    "          'num_training_steps': 20000,\n",
    "          'tunneling_rate_steps': 1000,\n",
    "          'save_steps': 1000,\n",
    "          'lr_decay_steps': 2500,\n",
    "          'lr_decay_rate': 0.96,\n",
    "          'logging_steps': 100,\n",
    "          'arrangement': 'single_axis'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussians separated along $x$-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 2\n",
    "sigma = 0.05\n",
    "centers = 1\n",
    "means = np.zeros((x_dim, x_dim), dtype=np.float32)\n",
    "means[::2, 0] = centers\n",
    "means[1::2, 0] = -centers\n",
    "arrangement='single_axis'\n",
    "#for i in range(x_dim):\n",
    "#    means[i::x_dim, i] = centers\n",
    "cov_mtx = sigma * np.eye(x_dim).astype(np.float32)\n",
    "covs = np.array([cov_mtx] * x_dim).astype(np.float32)\n",
    "dist_arr = distribution_arr(x_dim, 2)\n",
    "gmm_dist = GMM(means, covs, dist_arr)\n",
    "params['means'] = gmm_dist.mus\n",
    "params['x_dim'] = x_dim\n",
    "params['sigma'] = sigma\n",
    "params['arrangement'] = arrangement\n",
    "#gmm_mus = np.array(gmm_dist.mus)\n",
    "#gmm_diffs = gmm_mus[1:] - gmm_mus[:-1, :]\n",
    "#gmm_distances = [np.sqrt(np.dot(d, d.T)) for d in gmm_diffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_samples = gmm_dist.get_samples(500)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gmm_samples[:,0], gmm_samples[:,1],\n",
    "        marker='o', ls='', alpha=0.75, label='Target distribution')\n",
    "ax.legend(loc='best')\n",
    "#_ = fix_legends(ax)\n",
    "#_ = fix_ticks(ax)\n",
    "fig.savefig('/Users/saforem2/ANL/l2hmc/new_mog_logs/target_distribution.pdf', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 2\n",
    "num_distributions = 6\n",
    "sigma = 0.01\n",
    "\n",
    "#MEANS = np.zeros((X_DIM, X_DIM), dtype=np.float32)\n",
    "#CENTERS = np.sqrt(2)  # center of Gaussian\n",
    "#for i in range(NUM_DISTRIBUTIONS):\n",
    "#    MEANS[i::NUM_DISTRIBUTIONS, i] = CENTERS\n",
    "\n",
    "covs, distribution = gen_ring(r=1., var=sigma, nb_mixtures=num_distributions)\n",
    "mus = np.array(distribution.mus)\n",
    "diffs = mus[1:] - mus[:-1, :]\n",
    "distances = [np.sqrt(np.dot(d, d.T)) for d in diffs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Lattice of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_dim = 2\n",
    "num_distributions = 16\n",
    "var = 0.01\n",
    "L = int(np.sqrt(num_distributions))\n",
    "means = np.array([(i, j) for i in range(L) for j in range(L)])\n",
    "_sigmas = np.array([var * np.eye(x_dim) for _ in range(num_distributions)])\n",
    "pis = [1. / num_distributions] * num_distributions \n",
    "pis[0] += 1 - sum(pis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distribution = GMM(means, _sigmas, pis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot samples from distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "samples = distribution.get_samples(500)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(samples[:,0], samples[:,1], marker='o', ls='', alpha=0.75)\n",
    "plt.show()\n",
    "#plt.savefig('../log_mog_tf/run_326/figures/target_distribution.pdf', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM separated along diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 2\n",
    "sigma = 0.02\n",
    "centers = 1\n",
    "means = np.zeros((x_dim, x_dim), dtype=np.float32)\n",
    "for i in range(x_dim):\n",
    "    means[i::x_dim, i] = centers\n",
    "cov_mtx = sigma * np.eye(x_dim).astype(np.float32)\n",
    "covs = np.array([cov_mtx] * x_dim).astype(np.float32)\n",
    "dist_arr = distribution_arr(x_dim, 2)\n",
    "gmm_dist = GMM(means, covs, dist_arr)\n",
    "\n",
    "gmm_mus = np.array(gmm_dist.mus)\n",
    "gmm_diffs = gmm_mus[1:] - gmm_mus[:-1, :]\n",
    "gmm_distances = [np.sqrt(np.dot(d, d.T)) for d in gmm_diffs]\n",
    "gmm_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_samples = gmm_dist.get_samples(500)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(gmm_samples[:,0], gmm_samples[:,1], marker='o', ls='', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create GMM model for training with L2HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#x_dim = 2\n",
    "#num_distributions = 6\n",
    "#sigma = 0.005\n",
    "\n",
    "#MEANS = np.zeros((X_DIM, X_DIM), dtype=np.float32)\n",
    "#CENTERS = np.sqrt(2)  # center of Gaussian\n",
    "#for i in range(NUM_DISTRIBUTIONS):\n",
    "#    MEANS[i::NUM_DISTRIBUTIONS, i] = CENTERS\n",
    "\n",
    "#covs, distribution = gen_ring(r=1.0, var=sigma, nb_mixtures=num_distributions)\n",
    "#means = distribution.mus\n",
    "\n",
    "params = {                          # default parameter values\n",
    "    'x_dim': x_dim,\n",
    "    'num_distributions': num_distributions,\n",
    "    'means': means,\n",
    "    'sigma': 0.05,\n",
    "    'small_pi': 2E-16,\n",
    "    'scale': 0.1,\n",
    "    'num_samples': 200,\n",
    "    'lr_init': 1e-3,\n",
    "    'lr_decay_steps': 1000,\n",
    "    'lr_decay_rate': 0.96, 'eps': 0.5,\n",
    "    'temp_init': 20,\n",
    "    'annealing_steps': 200,\n",
    "    'annealing_rate': 0.98,\n",
    "    #'train_trajectory_length': 15,\n",
    "    #'test_trajectory_length': 2000,\n",
    "    'num_training_steps': 30000,\n",
    "    'tunneling_rate_steps': 1000,\n",
    "    'save_steps': 1000,\n",
    "    'logging_steps': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build / Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pdb\n",
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#kwargs = {'radius': 1.0, 'sigma': 0.01, 'num_distributions': 6}\n",
    "#params = {}\n",
    "model = GaussianMixtureModel(params, \n",
    "                             config=config,\n",
    "                             log_dir='../../new_mog_logs/run_4',\n",
    "                             covs=covs,\n",
    "                             distribution=gmm_dist)\n",
    "                             #**kwargs)\n",
    "                             #log_dir='../log_mog_tf/run_22_diag_271/')\n",
    "                             #log_dir='../log_mog_tf/run64/')\n",
    "model.means = gmm_dist.mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._restore_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_samples = model.distribution.get_samples(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, losses, px = model.generate_trajectories(temp=1., \n",
    "                                                       num_samples=10, \n",
    "                                                       num_steps=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idxs = [rand_traj(trajectories) for _ in range(5)]\n",
    "colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']\n",
    "idxs = np.arange(7)\n",
    "nums = np.arange(len(idxs))\n",
    "labels = ['trajectory ' + str(i) for i in nums]\n",
    "for num, idx in enumerate(idxs):\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(target_samples[:,0], target_samples[:,1], \n",
    "                marker='o', ls='', alpha=0.75, color='slategrey')\n",
    "    #for i in range(3):\n",
    "    #for num, idx in enumerate(idxs):\n",
    "    _ = ax.plot(trajectories[:, idx, 0], trajectories[:, idx, 1], \n",
    "                marker='.', ls='-', alpha=0.5, color=colors[num])#, label=labels[num], color=colors[num])\n",
    "    #_ = ax.plot(trajectories[:, idxs[0], 0], trajectories[:, idxs[0], 1], marker='.', ls='-', alpha=0.5)#, label=labels[num], color=colors[num])\n",
    "    #ax.legend(loc='lower left')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig(f'../log_mog_tf/run_327/figures/trajectory_{num}.pdf', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "t = model.dynamics._format_time(step, tile=tf.shape(model.x)[0])\n",
    "grad1 = model.dynamics.grad_energy(model.x, aux=None)\n",
    "S1 = model.dynamics.VNet([model.x, grad1, t, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv1 = 0.5 * model.dynamics.eps * S1[0]\n",
    "tv1 = S1[1]\n",
    "fv1 = model.dynamics.eps * S1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dynamics import safe_exp\n",
    "prod_sv1 = tf.multiply(model.z, safe_exp(sv1, name='sv1F'))\n",
    "prod_fv1 = tf.multiply(safe_exp(fv1, name='fv1F'), grad1)\n",
    "v_h = prod_sv1 + 0.5 * model.dynamics.eps * (-prod_fv1 + tv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.run(v_h, feed_dict={model.x: samples, model.dynamics.temperature: 1.}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.run(vnet, feed_dict={model.x: samples, model.dynamics.temperature: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._restore_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories, loss_arr, accept_arr = model.generate_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajectories[:, 0, :]\n",
    "trajectories[:20,0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_samples = model.distribution.get_samples(600)\n",
    "trajectories = []\n",
    "for step in range(100):\n",
    "    _samples = model.distribution.get_samples(200)\n",
    "    trajectories.append(np.copy(_samples))\n",
    "    feed_dict = {model.x: _samples,\n",
    "                 model.dynamics.temperature: 1.}\n",
    "    _samples, px = model.sess.run([\n",
    "        #model.loss,\n",
    "        model.output[0],\n",
    "        model.px,\n",
    "    ], feed_dict=feed_dict)\n",
    "\n",
    "#  _, loss_, model.samples, px_, lr_, = model.sess.run([\n",
    "#_, loss_, _samples, px_, lr_, = model.sess.run([\n",
    "#    model.train_op,\n",
    "#    model.loss,\n",
    "#    model.output[0],\n",
    "#    model.px,\n",
    "#    model.learning_rate\n",
    "#], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_samples = model.distribution.get_samples(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = np.array(trajectories)\n",
    "np.array(trajectories).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories[:20, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notebook_utils import get_hmc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.randn(200, 2)\n",
    "hmc_samples = get_hmc_samples(2, 0.1, gmm_dist.get_energy_function(),\n",
    "                              model.sess, trajectory_length=10., steps=500, \n",
    "                              samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(10):\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(_samples[:,0], _samples[:,1], ls='', marker='.', alpha=0.75)\n",
    "ax.plot(trajectories[:50, 8, 0], trajectories[:50, 8, 1], \n",
    "        ls='-', marker='', alpha=0.6, label='L2HMC Chain')\n",
    "ax.plot(hmc_samples[:50, 0, 0], trajectories[:50, 0, 1], \n",
    "        ls='-', marker='', alpha=0.6, color='C3', label='HMC Chain')\n",
    "ax.legend(loc='best')\n",
    "plt.savefig('../../new_mog_logs/l2hmc_vs_hmc_trajectories.pdf', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.global_step.eval(model.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.arrangement = 'axes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._generate_plots(model.global_step.eval(model.sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_samples1 = model.sess.run([\n",
    "    model.output[0]\n",
    "], feed_dict={model.x: _samples, model.dynamics.temperature: 1.})\n",
    "#_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_samples1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Less old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in model.tunneling_rates_highT.keys():\n",
    "    #print(f'Step num: {key[0]}')\n",
    "    #print(f'Temp: {key[1]}')\n",
    "    model.steps_arr.append(key[0])\n",
    "    model.temp_arr.append(key[1])\n",
    "    #model.temp_arr.append(key[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(model.steps_arr)):\n",
    "    model.steps_arr[idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.steps_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, val in model.tunneling_rates.items():\n",
    "    model.tunneling_rates_avg.append(val[0])\n",
    "    model.tunneling_rates_err.append(val[1])\n",
    "for key, val in model.tunneling_rates_highT.items():\n",
    "    model.tunneling_rates_avg_highT.append(val[0])\n",
    "    model.tunneling_rates_err_highT.append(val[1])\n",
    "    \n",
    "for key, val in model.acceptance_rates.items():\n",
    "    model.acceptance_rates_avg.append(val[0])\n",
    "    model.acceptance_rates_err.append(val[1])\n",
    "for key, val in model.acceptance_rates_highT.items():\n",
    "    model.acceptance_rates_avg_highT.append(val[0])\n",
    "    model.acceptance_rates_err_highT.append(val[1])\n",
    "    \n",
    "for key, val in model.distances.items():\n",
    "    model.distances_avg.append(val[0])\n",
    "    model.distances_err.append(val[1])\n",
    "for key, val in model.distances_highT.items():\n",
    "    model.distances_avg_highT.append(val[0])\n",
    "    model.distances_err_highT.append(val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model._save_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model._init_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model._load_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.steps_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.tunneling_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_vals_as_arr = lambda _dict: np.array(list(_dict.values()))\n",
    "tr = get_vals_as_arr(model.tunneling_rates)\n",
    "ar = get_vals_as_arr(model.acceptance_rates)\n",
    "dr = get_vals_as_arr(model.distances)\n",
    "#np.array(list(model.tunneling_rates.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in model.attrs_dict.keys():\n",
    "    in_file = model.info_dir + key + '.npy'\n",
    "    if os.path.isfile(in_file):\n",
    "        setattr(model, key, np.load(in_file))\n",
    "        print(f'Set model.{key} to values read in from: {in_file}')\n",
    "        #print(model.key == np.load(in_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attrs_dict = model.attrs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attrs_dict['steps_arr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.train(params['num_training_steps'], plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#trajectories, loss_arr, px_arr = model.generate_trajectories(num_samples=100, num_steps=100, temperature=1.)\n",
    "\n",
    "#config = tf.ConfigProto(log_device_placement=True)\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#model.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calc_avg_distance1(trajectories):\n",
    "    distances_arr = []\n",
    "    for trajectory in trajectories:\n",
    "        distance_arr = []\n",
    "        for idx in range(1, len(trajectory)):\n",
    "            diff = trajectory[idx] - trajectory[idx-1]\n",
    "            dist = np.sqrt(np.dot(diff, diff.T))\n",
    "            distance_arr.append(dist)\n",
    "        distances_arr.append(sum(distance_arr))\n",
    "    return np.mean(distances_arr)\n",
    "\n",
    "def calc_avg_distance2(trajectories):\n",
    "    dist = lambda d: np.sqrt(np.dot(d, d.T))\n",
    "    #distances_arr = np.mean([[dist(d) for d in [t[:-1, :] - t[1:, :] for t in trajectories]]\n",
    "    #for trajectory in trajectories:\n",
    "        diff = trajectory[:-1, :] - trajectory[1:, :]\n",
    "        distance = sum([np.sqrt(np.dot(d, d.T)) for d in diff])\n",
    "        distances_arr.append(distance)\n",
    "    return np.mean(distances_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit avg_dist = avg_distance_traveled(trajectories.transpose([1,0,2]))\n",
    "#print(avg_dist)\n",
    "\n",
    "%timeit avg_dist1 = calc_avg_distance1(trajectories.transpose([1,0,2]))\n",
    "#print(avg_dist1)\n",
    "\n",
    "%timeit avg_dist2 = calc_avg_distance2(trajectories.transpose([1,0,2]))\n",
    "#print(avg_dist2)\n",
    "\n",
    "distances = np.array([np.sqrt(np.dot(disp, disp.T)) for disp in displacements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.train(params['num_training_steps'], config=config, plot=True)\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "model.build_graph()\n",
    "model.train(params['num_training_steps'], config=config, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
