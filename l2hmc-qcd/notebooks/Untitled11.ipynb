{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `numpy` inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#import numpy as np\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=3, linewidth=500, edgeitems=15, suppress=True)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('bright')\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "label_size = 9 \n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size \n",
    "\n",
    "mplstyle.use('fast')\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=False)\n",
    "\n",
    "import utils.file_io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters.plot_observables import grid_plot, get_obs_dict\n",
    "import utils.file_io as io\n",
    "\n",
    "import pandas as pd\n",
    "from plotters.plot_utils import load_pkl\n",
    "\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import scipy\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "label_size = 9\n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params.gauge_params import GAUGE_PARAMS\n",
    "from trainers.train_setup import train_setup\n",
    "from utils.attr_dict import AttrDict\n",
    "from models.gauge_model import GaugeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `GaugeModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.train_setup import train_setup\n",
    "from params.gauge_params import GAUGE_PARAMS\n",
    "\n",
    "_params = GAUGE_PARAMS.copy()\n",
    "params, hooks = train_setup(_params, log_file=None)\n",
    "params['zero_masks'] = True\n",
    "params['space_size'] = 4\n",
    "params['time_size'] = 4\n",
    "params['batch_size'] = 8\n",
    "for key, val in params.items():\n",
    "    print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['train_steps'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gauge_model import GaugeModel\n",
    "\n",
    "model = GaugeModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loggers.train_logger import TrainLogger\n",
    "from trainers.train_setup import create_config\n",
    "\n",
    "train_logger = TrainLogger(model, model.log_dir,\n",
    "                           logging_steps=model.logging_steps,\n",
    "                           summaries=params['summaries'])\n",
    "config, params = create_config(params)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.trainer import Trainer\n",
    "trainer = Trainer(sess, model, train_logger, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import NetWeights, NP_FLOAT\n",
    "\n",
    "samples_init = np.array(model.lattice.samples_array, dtype=NP_FLOAT)\n",
    "\n",
    "net_weights_init = NetWeights(1, 1, 1, 1, 1, 1)\n",
    "\n",
    "trainer.train(model.train_steps,\n",
    "              beta=model.beta_init,\n",
    "              samples=samples_init,\n",
    "              net_weights=net_weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_dump(obj, out_file, name=''):\n",
    "    io.log(f'Saving {name} to {out_file}')\n",
    "    with open(out_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.train_setup import get_net_weights\n",
    "\n",
    "wfile = os.path.join(model.log_dir, 'dynamics_weights.h5')\n",
    "model.dynamics.save_weights(wfile)\n",
    "\n",
    "weights_final, coeffs_final = get_net_weights(model, sess)\n",
    "xcoeffs = sess.run(list(coeffs_final['xnet'].values()))\n",
    "vcoeffs = sess.run(list(coeffs_final['vnet'].values()))\n",
    "weights_final['xnet']['GenericNet'].update({\n",
    "    'coeff_scale': xcoeffs[0],\n",
    "    'coeff_transformation': xcoeffs[1],\n",
    "})\n",
    "weights_final['vnet']['GenericNet'].update({\n",
    "    'coeff_scale': vcoeffs[0],\n",
    "    'coeff_transformation': vcoeffs[1],\n",
    "})\n",
    "pkl_dump(weights_final, os.path.join(model.log_dir, 'weights.pkl'), name='weights_final')\n",
    "#pkl_dump(model.params, os.path.join(os.getcwd(), 'params.pkl'), name='model.params')\n",
    "#io.save_dict(model.params, os.path.join(os.getcwd()), 'params')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Create `dynamics_np` to compare against `model.dynamics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runners.runner_np import create_dynamics, load_pkl, run_inference_np\n",
    "\n",
    "eps_np = sess.run(model.dynamics.eps)\n",
    "dynamics_np, lattice = create_dynamics(model.log_dir, eps=eps_np,\n",
    "                                       num_steps=model.num_steps,\n",
    "                                       batch_size=model.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create operations for calculating quantities of interest:   \n",
    " - `xf`: Proposed $x$, obtained from running `model.dyanmics.transition_kernel` with `forward=True`   \n",
    " - `vf`: Proposed $v$, obtained from running `model.dynamics.transition_kernel` with `forward=True`\n",
    " - `pxf`: $A(\\xi^{\\prime}|\\xi)$\n",
    " - `sumlogdetf`: Log determinant, accumulated over all leapfrog steps. Given by:\n",
    " \n",
    " \\begin{equation}\n",
    " \\log|\\mathcal{J}| = \\log\\left|\\frac{\\partial\\xi^{\\prime}}{\\partial \\xi^{T}}\\right| = d \\sum_{t\\leq N_{\\mathrm{LF}}} \\left[\\frac{\\varepsilon}{2}\\mathbb{1} \\cdot S_{v}(\\zeta^{t}_{1}) + \\varepsilon m^{t} \\cdot S_{x}(\\zeta^{t}_{2}) + \\varepsilon\\bar{m}^{t} \\cdot S_{x}(\\zeta^{t}_{3}) + \\frac{\\varepsilon}{2}\\mathbb{1}\\cdot S_{v}(\\zeta^{t}_{4})\\right]\n",
    " \\label{eq:sumlogdet}\n",
    " \\end{equation}   \n",
    " \n",
    "- `xf_`: $x^{\\prime\\prime}$, obtained by updating $x$ for a single leapfrog step.\n",
    "- `vf_`: $v^{\\prime\\prime}$, obtained by updating $v$ for a single leapfrog step.\n",
    "- `sld_`: Accumulated log determinant after a single leapfrog step. ($t = 1$ in Eq.\\ref{eq:sumlogdet})\n",
    "- `dudx_tf_`: $\\partial_{x}U(x, \\beta)$, evaluated at $\\beta = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import State, TF_FLOAT\n",
    "from seed_dict import seeds\n",
    "\n",
    "# ------------------------------\n",
    "# Run `model.dynamics` forward:\n",
    "# ------------------------------\n",
    "#vf_init = tf.random_normal(tf.shape(model.x), dtype=TF_FLOAT, seed=seeds['vf_init'], name='vf_init')\n",
    "vf_init_np = np.array(np.random.randn(*model.x.shape), dtype=NP_FLOAT)\n",
    "vf_init = tf.constant(vf_init_np)\n",
    "\n",
    "state_init_f = State(model.x, vf_init, model.beta)\n",
    "outf = model.dynamics.transition_kernel(*state_init_f,\n",
    "                                        model.net_weights,\n",
    "                                        model.train_phase,\n",
    "                                        forward=True, hmc=True)\n",
    "xf = outf['x_proposed']\n",
    "vf = outf['v_proposed']\n",
    "pxf = outf['accept_prob']\n",
    "pxf_hmc = outf['accept_prob_hmc']\n",
    "sumlogdetf = outf['sumlogdet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "# Create operations for getting the output from `model.dynamics._forward_lf`:\n",
    "xf_, vf_, sld_, _ = model.dynamics._forward_lf(model.x, vf_init,\n",
    "                                               model.beta, step,\n",
    "                                               model.net_weights,\n",
    "                                               training=model.train_phase)\n",
    "\n",
    "# Create operation for calculating the gradient of the potential\n",
    "dudx_tf_ = model.dynamics.grad_potential(model.x, model.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phase = False\n",
    "t = model.dynamics._get_time(step, tile=tf.shape(model.x)[0])\n",
    "Sv, Tv, Qv = model.dynamics.vnet([model.x, dudx_tf_, t], model.train_phase)\n",
    "\n",
    "mask, mask_inv = model.dynamics._get_mask(step)\n",
    "Sx, Tx, Qx = model.dynamics.xnet([vf_init, mask * model.x, t], model.train_phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Run `model.dynamics` forward and compare against results from running `dynamics_np` forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "beta_np = 5.\n",
    "train_phase = False\n",
    "net_weights = NetWeights(1, 1, 1, 1, 1, 1)\n",
    "#xf_init_np = np.zeros(model.x.shape, dtype=NP_FLOAT)\n",
    "xf_init_np = np.array(np.random.randn(*model.x.shape), dtype=NP_FLOAT)\n",
    "keys = ['xf', 'vf', 'vf_init', 'pxf', 'sumlogdetf']\n",
    "fops = [xf, vf, vf_init, pxf, sumlogdetf]\n",
    "_keys = ['xf_', 'vf_', 'sld_']\n",
    "_fops = [xf_, vf_, sld_]\n",
    "\n",
    "\n",
    "def forward_lf_tf(net_weights):\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.net_weights: net_weights,\n",
    "        model.train_phase: train_phase\n",
    "    }\n",
    "    \n",
    "    _fout = sess.run(_fops, feed_dict=feed_dict)\n",
    "    _fout_dict = dict(zip(_keys, _fout))\n",
    "    \n",
    "    return _fout_dict\n",
    "\n",
    "    \n",
    "def forward_lf_np(net_weights, vf_init_np):\n",
    "    \n",
    "    _fout_np = dynamics_np._forward_lf(xf_init_np, vf_init_np,\n",
    "                                       beta_np, step, net_weights)\n",
    "    _fout_dict_np = dict(zip(_keys, _fout_np))\n",
    "    return _fout_dict_np\n",
    "\n",
    "\n",
    "def dynamics_forward_tf(net_weights):\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.net_weights: net_weights,\n",
    "        model.train_phase: train_phase\n",
    "    }\n",
    "\n",
    "    fout = sess.run(fops, feed_dict=feed_dict)\n",
    "    fout_dict = dict(zip(keys, fout))\n",
    "    \n",
    "    return fout_dict\n",
    "\n",
    "\n",
    "def run_xnet():\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.net_weights: net_weights,\n",
    "        model.train_phase: train_phase,\n",
    "    }\n",
    "    \n",
    "    outputs = sess.run([Sx, Tx, Qx], feed_dict=feed_dict)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "\n",
    "def run_vnet():\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.train_phase: train_phase,\n",
    "    }\n",
    "    outputs = sess.run([Sv, Tv, Qv], feed_dict=feed_dict)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def run_xnet_np():\n",
    "    t = dynamics_np._get_time(step, tile=xf_init_np.shape[0])\n",
    "    mask, mask_inv = dynamics_np._get_mask(step)\n",
    "    outputs = dynamics_np.xnet([vf_init_np, mask * xf_init_np, t])\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def run_vnet_np():\n",
    "    t = dynamics_np._get_time(step, tile=xf_init_np.shape[0])\n",
    "    mask, mask_inv = dynamics_np._get_mask(step)\n",
    "    dU_dx = dynamics_np.grad_potential(xf_init_np, beta_np)\n",
    "    outputs = dynamics_np.vnet([xf_init_np, dU_dx, t])\n",
    "    return outputs\n",
    "    \n",
    "\n",
    "def dynamics_forward_np(net_weights, vf_init_np):\n",
    "    state_init_f_np = State(xf_init_np, vf_init_np, beta_np)\n",
    "    \n",
    "    xf, vf, pxf, sldf = dynamics_np.transition_kernel(*state_init_f_np,\n",
    "                                                      net_weights, forward=True)\n",
    "    fout_dict_np = {\n",
    "        'xf': xf,\n",
    "        'vf': vf,\n",
    "        'vf_init': vf_init_np,\n",
    "        'pxf': pxf,\n",
    "        'sumlogdetf': sldf,\n",
    "    }\n",
    "    \n",
    "    return fout_dict_np\n",
    "\n",
    "\n",
    "def calc_diff(x1, x2, name=''):\n",
    "    diff = np.sqrt(np.sum((x1 - x2)**2))\n",
    "    print(f'{name} diff = {diff}')\n",
    "    \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Check that $\\partial_x U(x)$ is the same for `dynamics_tf` and `dynamics_np`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrand_np = np.array(np.random.randn(*xf_init_np.shape), dtype=NP_FLOAT)\n",
    "dudx_np = dynamics_np.grad_potential(xrand_np, beta_np)\n",
    "\n",
    "dudx_tf = sess.run(dudx_tf_, feed_dict={model.x: xrand_np, model.beta: beta_np})\n",
    "\n",
    "diff = np.sqrt(np.sum((dudx_np - dudx_tf) ** 2))\n",
    "print(f'Gradients agree: {diff < 1e-3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sx_tf, Tx_tf, Qx_tf = run_xnet()\n",
    "Sx_np, Tx_np, Qx_np = run_xnet_np()\n",
    "print(f'Sx agrees: {np.allclose(Sx_tf, Sx_np)}')\n",
    "print(f'Tx agrees: {np.allclose(Tx_tf, Tx_np)}')\n",
    "print(f'Qx agrees: {np.allclose(Qx_tf, Qx_np)}')\n",
    "\n",
    "Sv_tf, Tv_tf, Qv_tf = run_vnet()\n",
    "Sv_np, Tv_np, Qv_np = run_vnet_np()\n",
    "print(f'Sv agrees: {np.allclose(Sv_tf, Sv_np)}')\n",
    "print(f'Tv agrees: {np.allclose(Tv_tf, Tv_np)}')\n",
    "print(f'Qv agrees: {np.allclose(Qv_tf, Qv_np)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = 80 * '-'\n",
    "net_weights_arr = [\n",
    "    NetWeights(0, 0, 0, 0, 0, 0),\n",
    "    #NetWeights(0, 0, 0, 0, 0, 1),\n",
    "    #NetWeights(0, 0, 0, 0, 1, 0),\n",
    "    #NetWeights(0, 0, 0, 1, 0, 0),\n",
    "    #NetWeights(0, 0, 1, 0, 0, 0),\n",
    "    #NetWeights(0, 1, 0, 0, 0, 0),\n",
    "    #NetWeights(1, 0, 0, 0, 0, 0),\n",
    "    NetWeights(1, 1, 1, 1, 1, 1),\n",
    "]\n",
    "\n",
    "diffs_dict = {\n",
    "    \n",
    "}\n",
    "for net_weights in net_weights_arr:\n",
    "    io.log(HEADER)\n",
    "    io.log(f'NetWeights: {net_weights}')\n",
    "    fout_tf = dynamics_forward_tf(net_weights)\n",
    "    diffs_dict[net_weights] = {}\n",
    "    _vf_np = fout_tf['vf_init']\n",
    "    np.allclose(_vf_np, vf_init_np)\n",
    "    fout_np = dynamics_forward_np(net_weights, vf_init_np)\n",
    "    for key in fout_tf.keys():\n",
    "        diffs_dict[key] = calc_diff(fout_tf[key], fout_np[key], name=key)\n",
    "    io.log(HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER1 = (len(f'NetWeights: {tuple(net_weights)}') + 5) * '-'\n",
    "\n",
    "_diffs_dict = {}\n",
    "for net_weights in net_weights_arr:\n",
    "    io.log(HEADER1)\n",
    "    io.log(f'NetWeights: {tuple(net_weights)}')\n",
    "    _diffs_dict[net_weights] = {}\n",
    "    _fout_tf = forward_lf_tf(net_weights)\n",
    "    #_vf_init = _fout_tf\n",
    "    _fout_np = forward_lf_np(net_weights, vf_init_np)\n",
    "    for key in _fout_tf.keys():\n",
    "        _diffs_dict[key] = calc_diff(_fout_tf[key], _fout_np[key], name=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:idp]",
   "language": "python",
   "name": "conda-env-idp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
