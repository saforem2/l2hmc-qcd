{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `numpy` inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:03.806428Z",
     "start_time": "2020-01-27T08:24:03.803941Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:07.071773Z",
     "start_time": "2020-01-27T08:24:04.833858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saforem2/opt/anaconda3/envs/tf12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/saforem2/opt/anaconda3/envs/tf12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/saforem2/opt/anaconda3/envs/tf12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/saforem2/opt/anaconda3/envs/tf12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/saforem2/opt/anaconda3/envs/tf12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/saforem2/opt/anaconda3/envs/tf12/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#import numpy as np\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(precision=3, linewidth=500, edgeitems=15, suppress=True)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('bright')\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.style as mplstyle\n",
    "\n",
    "label_size = 9 \n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size \n",
    "\n",
    "mplstyle.use('fast')\n",
    "\n",
    "#from matplotlib import rc\n",
    "#rc('text', usetex=False)\n",
    "\n",
    "import utils.file_io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:12.143762Z",
     "start_time": "2020-01-27T08:24:12.101737Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotters.plot_observables import grid_plot, get_obs_dict\n",
    "import utils.file_io as io\n",
    "\n",
    "import pandas as pd\n",
    "from plotters.plot_utils import load_pkl\n",
    "\n",
    "from plotters.plot_observables import get_run_dirs, get_title_str\n",
    "from lattice.lattice import u1_plaq_exact\n",
    "import scipy\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "label_size = 9\n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:17.108358Z",
     "start_time": "2020-01-27T08:24:12.835203Z"
    }
   },
   "outputs": [],
   "source": [
    "from params.gauge_params import GAUGE_PARAMS\n",
    "from trainers.train_setup import train_setup\n",
    "from utils.attr_dict import AttrDict\n",
    "from models.gauge_model import GaugeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `GaugeModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:18.508962Z",
     "start_time": "2020-01-27T08:24:18.446688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Starting training using L2HMC algorithm...\n",
      "Creating directory: /Users/saforem2/ANL/l2hmc-qcd/gauge_logs/2020_01_27/L8_b64_lf5_f32_0224\n",
      "space_size: 8\n",
      "time_size: 8\n",
      "link_type: U1\n",
      "dim: 2\n",
      "batch_size: 64\n",
      "rand: True\n",
      "num_steps: 5\n",
      "eps: 0.2\n",
      "fixed_beta: False\n",
      "beta_init: 2.0\n",
      "beta_final: 5.0\n",
      "lr_init: 0.001\n",
      "lr_decay_steps: 1000\n",
      "lr_decay_rate: 0.96\n",
      "warmup_lr: False\n",
      "train_steps: 100\n",
      "save_steps: 1000\n",
      "logging_steps: 2500\n",
      "print_steps: 1\n",
      "network_arch: generic\n",
      "num_hidden1: 50\n",
      "num_hidden2: 50\n",
      "use_bn: False\n",
      "dropout_prob: 0.0\n",
      "clip_value: 0.0\n",
      "summaries: True\n",
      "eps_fixed: False\n",
      "hmc: False\n",
      "use_nnehmc_loss: False\n",
      "use_gaussian_loss: False\n",
      "loss_scale: 1\n",
      "std_weight: 1.0\n",
      "aux_weight: 1.0\n",
      "charge_weight: 0.0\n",
      "metric: cos_diff\n",
      "x_scale_weight: 1\n",
      "x_translation_weight: 1\n",
      "x_transformation_weight: 1\n",
      "v_scale_weight: 1\n",
      "v_translation_weight: 1\n",
      "v_transformation_weight: 1\n",
      "log_dir: /Users/saforem2/ANL/l2hmc-qcd/gauge_logs/2020_01_27/L8_b64_lf5_f32_0224\n",
      "trace: False\n",
      "profiler: False\n",
      "gpu: False\n",
      "horovod: False\n",
      "comet: False\n",
      "restore: False\n",
      "theta: False\n",
      "num_intra_threads: 0\n",
      "float64: False\n",
      "using_hvd: False\n",
      "zero_masks: False\n"
     ]
    }
   ],
   "source": [
    "from trainers.train_setup import train_setup\n",
    "from params.gauge_params import GAUGE_PARAMS\n",
    "\n",
    "_params = GAUGE_PARAMS.copy()\n",
    "params, hooks = train_setup(_params, log_file=None)\n",
    "params['zero_masks'] = False\n",
    "params['space_size'] = 8\n",
    "params['time_size'] = 8\n",
    "params['batch_size'] = 64 \n",
    "params['train_steps'] = 100\n",
    "for key, val in params.items():\n",
    "    print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create `GaugeModel`\n",
    "2. Create `TrainLogger`\n",
    "3. Create `tf.ConfigProto()`\n",
    "4. Create `tf.Session`\n",
    "5. Create `Trainer`\n",
    "6. Run `Trainer` on `GaugeModel` to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:28.014073Z",
     "start_time": "2020-01-27T08:24:20.879078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "INFO: Building graph for `GaugeModel`...\n",
      "INFO: Creating lattice...\n",
      "INFO: Creating input placeholders...\n",
      "x: Tensor(\"GaugeModel/inputs/x:0\", shape=(64, 128), dtype=float32)\n",
      "\n",
      "beta: Tensor(\"GaugeModel/inputs/beta:0\", shape=(), dtype=float32)\n",
      "\n",
      "eps_ph: Tensor(\"GaugeModel/inputs/eps_ph:0\", shape=(), dtype=float32)\n",
      "\n",
      "global_step_ph: Tensor(\"GaugeModel/inputs/global_step_ph:0\", shape=(), dtype=int64)\n",
      "\n",
      "train_phase: Tensor(\"GaugeModel/inputs/is_training:0\", shape=(), dtype=bool)\n",
      "\n",
      "net_weights: NetWeights(x_scale=<tf.Tensor 'GaugeModel/inputs/x_scale_weight:0' shape=() dtype=float32>, x_translation=<tf.Tensor 'GaugeModel/inputs/x_translation_weight:0' shape=() dtype=float32>, x_transformation=<tf.Tensor 'GaugeModel/inputs/x_transformation_weight:0' shape=() dtype=float32>, v_scale=<tf.Tensor 'GaugeModel/inputs/v_scale_weight:0' shape=() dtype=float32>, v_translation=<tf.Tensor 'GaugeModel/inputs/v_translation_weight:0' shape=() dtype=float32>, v_transformation=<tf.Tensor 'GaugeModel/inputs/v_transformation_weight:0' shape=() dtype=float32>)\n",
      "\n",
      "INFO: Creating operations for calculating observables...\n",
      "INFO: Creating `Dynamics`...\n",
      "INFO: Calculating gradients for backpropagation...\n",
      "Collecting inference operations...\n",
      "INFO: Done building graph. Took: 7.070122003555298s\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.gauge_model import GaugeModel\n",
    "model = GaugeModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:32.387350Z",
     "start_time": "2020-01-27T08:24:29.273465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory: /Users/saforem2/ANL/l2hmc-qcd/gauge_logs/2020_01_27/L8_b64_lf5_f32_0224/checkpoints\n",
      "Creating directory: /Users/saforem2/ANL/l2hmc-qcd/gauge_logs/2020_01_27/L8_b64_lf5_f32_0224/training\n",
      "Creating directory: /Users/saforem2/ANL/l2hmc-qcd/gauge_logs/2020_01_27/L8_b64_lf5_f32_0224/summaries/train\n"
     ]
    }
   ],
   "source": [
    "from loggers.train_logger import TrainLogger\n",
    "from trainers.train_setup import create_config\n",
    "\n",
    "train_logger = TrainLogger(model, model.log_dir,\n",
    "                           logging_steps=model.logging_steps,\n",
    "                           summaries=params['summaries'])\n",
    "config, params = create_config(params)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:24:34.746997Z",
     "start_time": "2020-01-27T08:24:34.688655Z"
    }
   },
   "outputs": [],
   "source": [
    "from trainers.trainer import Trainer\n",
    "trainer = Trainer(sess, model, train_logger, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:25:05.677047Z",
     "start_time": "2020-01-27T08:24:36.724815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step: 0\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "    STEP      t/STEP     LOSS     % ACC      EPS        dX       BETA       LR      ACTION    dPLAQ   \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "    0/100      12.51    -110.8    0.8111     0.201    0.4991       2       0.001     63.25    0.6861   \n",
      "    1/100     0.1405     -98.1    0.6945     0.202    0.4354     2.012     0.001     43.64    0.3816   \n",
      "    2/100     0.1478    -90.23    0.5752     0.203    0.4104     2.024     0.001     35.92     0.263   \n",
      "    3/100     0.1482    -87.96    0.5417     0.204    0.4012     2.037     0.001     31.77    0.2002   \n",
      "    4/100     0.1698    -84.59    0.4779     0.205    0.3989     2.049     0.001     29.35    0.1643   \n",
      "    5/100     0.1667    -88.54    0.5987     0.206    0.3848     2.062     0.001     27.76    0.1415   \n",
      "    6/100     0.1555    -96.73    0.6861    0.2069    0.3837     2.075     0.001     26.16    0.1184   \n",
      "    7/100     0.1734    -95.16    0.6458    0.2079    0.3838     2.088     0.001     24.63    0.09649  \n",
      "    8/100     0.1421    -99.51    0.7556    0.2089    0.3803     2.101     0.001     24.15    0.09103  \n",
      "    9/100     0.1681    -91.23    0.6056    0.2099    0.3801     2.114     0.001     22.85    0.07276  \n",
      "   10/100     0.1411    -88.74    0.6136    0.2109    0.3729     2.128     0.001     21.82    0.05865  \n",
      "   11/100     0.1373    -98.21    0.7132    0.2119    0.3733     2.141     0.001     21.34    0.05303  \n",
      "   12/100     0.1669    -92.71    0.6302    0.2129     0.378     2.155     0.001     20.73    0.04564  \n",
      "   13/100     0.1663    -96.93    0.7054    0.2139    0.3678     2.169     0.001     20.27    0.04042  \n",
      "   14/100     0.1446    -94.31    0.6301    0.2149     0.374     2.183     0.001     19.25    0.02645  \n",
      "   15/100     0.1604    -99.89    0.7405    0.2158    0.3754     2.198     0.001     19.6     0.03391  \n",
      "   16/100     0.1357    -98.25    0.6549    0.2168     0.383     2.212     0.001     19.22    0.03007  \n",
      "   17/100     0.1429     -95.2    0.6867    0.2178    0.3689     2.227     0.001     18.91    0.02726  \n",
      "   18/100      0.155    -98.54    0.6902    0.2188    0.3791     2.242     0.001     19.13    0.03274  \n",
      "   19/100     0.1526     -99.2     0.715    0.2197    0.3826     2.257     0.001     18.72    0.02836  \n",
      "   20/100     0.1376    -102.9    0.7099    0.2207    0.3814     2.273     0.001     18.05    0.01989  \n",
      "   21/100     0.1646    -101.7    0.6599    0.2216    0.3787     2.288     0.001     17.73    0.01691  \n",
      "   22/100     0.1466    -98.76    0.6306    0.2226    0.3743     2.304     0.001     17.41    0.01399  \n",
      "   23/100     0.1514    -107.2    0.7483    0.2235    0.3892     2.32      0.001     17.53    0.01779  \n",
      "   24/100     0.1607    -103.9    0.6662    0.2244    0.3873     2.336     0.001     17.43    0.01825  \n",
      "   25/100     0.1634    -109.7     0.737    0.2253    0.3874     2.353     0.001     17.59    0.0229   \n",
      "   26/100     0.1362     -105      0.659    0.2262     0.39      2.37      0.001     17.46    0.02292  \n",
      "   27/100     0.1536    -107.1    0.7083    0.2271    0.3947     2.387     0.001     17.16    0.02014  \n",
      "   28/100      0.154    -102.3    0.6152     0.228    0.3893     2.404     0.001     17.03    0.02021  \n",
      "   29/100      0.146    -108.4    0.7363    0.2289    0.3842     2.421     0.001     16.49    0.01376  \n",
      "   30/100     0.1723    -105.9    0.6127    0.2298    0.3932     2.439     0.001     16.12    0.01009  \n",
      "   31/100     0.1418    -108.5    0.6901    0.2307    0.3931     2.457     0.001     16.21    0.01359  \n",
      "   32/100     0.1495    -108.3    0.6462    0.2316    0.3983     2.475     0.001     16.07    0.01337  \n",
      "   33/100     0.1596    -108.6    0.7031    0.2324    0.3921     2.494     0.001     16.04    0.01499  \n",
      "   34/100     0.1674    -106.4     0.636    0.2333     0.395     2.513     0.001     16.03    0.01678  \n",
      "   35/100     0.1502    -109.8    0.6756    0.2341    0.3979     2.532     0.001     15.91    0.01701  \n",
      "   36/100     0.1513    -102.6    0.5792     0.235    0.3938     2.551     0.001     15.6     0.01421  \n",
      "   37/100     0.1438    -112.4    0.6949    0.2358    0.3988     2.571     0.001     15.82    0.01967  \n",
      "   38/100     0.1583    -111.5    0.6909    0.2366    0.3982     2.591     0.001     15.53    0.01709  \n",
      "   39/100     0.1594    -110.7    0.6752    0.2374    0.4009     2.611     0.001     15.62    0.02056  \n",
      "   40/100     0.1506    -111.3    0.6339    0.2382    0.4054     2.632     0.001     15.25    0.0168   \n",
      "   41/100     0.1452    -111.3    0.6417     0.239    0.3964     2.653     0.001     15.1     0.01656  \n",
      "   42/100     0.1695    -108.5    0.6085    0.2398    0.3998     2.674     0.001     15.08    0.01824  \n",
      "   43/100     0.1487    -114.3    0.7049    0.2406    0.4054     2.695     0.001     15.1     0.02058  \n",
      "   44/100     0.1783    -108.1    0.6002    0.2414     0.405     2.717     0.001     14.79    0.01781  \n",
      "   45/100     0.1487    -117.4    0.7423    0.2422    0.4111     2.74      0.001     14.74    0.01906  \n",
      "   46/100     0.1854    -107.1    0.5648     0.243    0.4065     2.762     0.001     14.04    0.01021  \n",
      "   47/100     0.1723    -109.3    0.5911    0.2437    0.4044     2.786     0.001     14.19    0.0145   \n",
      "   48/100     0.1904    -106.8    0.5304    0.2444    0.4052     2.809     0.001     14.2     0.01668  \n",
      "   49/100     0.1696    -109.2    0.5383    0.2451    0.4068     2.833     0.001     14.04    0.01625  \n",
      "   50/100     0.1576    -111.6    0.5785    0.2458    0.4058     2.857     0.001     14.17    0.02031  \n",
      "   51/100     0.1802    -112.5    0.6171    0.2464    0.4097     2.882     0.001     13.97    0.01906  \n",
      "   52/100     0.1819     -111     0.6063    0.2471    0.4048     2.907     0.001     13.65    0.01611  \n",
      "   53/100     0.1894    -112.2    0.6015    0.2478    0.4109     2.933     0.001     12.98   0.007666  \n",
      "   54/100     0.1551     -107     0.4982    0.2484    0.4074     2.959     0.001     12.94   0.009141  \n",
      "   55/100     0.1844    -109.8    0.5715     0.249    0.4098     2.985     0.001     12.89    0.01033  \n",
      "   56/100     0.1743    -109.3    0.5344    0.2497    0.3991     3.012     0.001     12.69    0.0092   \n",
      "   57/100      0.196    -105.1    0.4605    0.2503    0.4075     3.04      0.001     12.86    0.01379  \n",
      "   58/100     0.1636     -109     0.5278    0.2509    0.4032     3.067     0.001     12.9     0.01646  \n",
      "   59/100     0.1847    -112.7    0.5624    0.2514    0.4104     3.096     0.001     12.78    0.0166   \n",
      "   60/100     0.1937    -108.6    0.5191     0.252    0.4048     3.125     0.001     12.69    0.01711  \n",
      "   61/100      0.165    -109.6     0.522    0.2526    0.4073     3.155     0.001     12.22    0.01169  \n",
      "   62/100      0.194    -105.4    0.4799    0.2531    0.4086     3.185     0.001     12.14    0.01247  \n",
      "   63/100     0.1712    -114.2    0.5849    0.2536    0.4137     3.215     0.001     12.1     0.01386  \n",
      "   64/100     0.1708    -109.3    0.5167    0.2541    0.4039     3.247     0.001      12      0.01423  \n",
      "   65/100      0.186    -103.1    0.4202    0.2546    0.4016     3.279     0.001     11.67    0.01106  \n",
      "   66/100     0.1787    -108.5    0.5322     0.255    0.3988     3.311     0.001     11.68    0.01311  \n",
      "   67/100     0.1702     -109     0.4646    0.2554    0.4097     3.344     0.001     11.5     0.01226  \n",
      "   68/100     0.1826    -109.9    0.4868    0.2558    0.4074     3.378     0.001     11.59    0.01557  \n",
      "   69/100     0.1843    -112.5    0.5955    0.2563    0.4094     3.413     0.001     11.69    0.0191   \n",
      "   70/100      0.16     -108.7    0.5136    0.2567    0.4078     3.448     0.001     11.41    0.0167   \n",
      "   71/100      0.161    -102.9    0.4327    0.2571    0.4055     3.484     0.001     11.15    0.01449  \n",
      "   72/100     0.1908    -106.7     0.492    0.2576    0.3939     3.521     0.001     11.04    0.01476  \n",
      "   73/100     0.1795    -107.9    0.5102     0.258     0.405     3.559     0.001     10.81    0.01299  \n",
      "   74/100     0.1567    -104.8    0.4688    0.2582    0.4011     3.597     0.001     10.77    0.01425  \n",
      "   75/100     0.1664    -105.1    0.4317    0.2584    0.4063     3.636     0.001     10.71    0.01523  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   76/100     0.1818    -107.5    0.4555    0.2586    0.4022     3.676     0.001     10.74    0.01755  \n",
      "   77/100     0.1511    -105.6    0.4857    0.2588    0.4009     3.717     0.001     10.61    0.01749  \n",
      "   78/100     0.1512    -105.6    0.4677    0.2585    0.4023     3.759     0.001     10.45    0.0168   \n",
      "   79/100     0.1615    -112.1    0.4855    0.2578    0.4046     3.802     0.001     10.29    0.01632  \n",
      "   80/100     0.1774    -103.2    0.4786    0.2572    0.3987     3.846     0.001     10.17    0.01625  \n",
      "   81/100     0.1564    -97.65     0.338    0.2565    0.4016     3.891     0.001     10.14    0.01758  \n",
      "   82/100     0.1638    -100.4    0.4507    0.2557    0.4063     3.937     0.001     10.21    0.02056  \n",
      "   83/100     0.1479    -90.55    0.3553    0.2545    0.3963     3.984     0.001     9.945    0.0183   \n",
      "   84/100     0.1793    -107.2    0.5037    0.2534    0.3973     4.032     0.001     9.944    0.02013  \n",
      "   85/100     0.1644    -99.85    0.4328    0.2525    0.3925     4.082     0.001     9.695    0.01807  \n",
      "   86/100     0.1534    -100.6    0.4223    0.2515    0.3879     4.132     0.001     9.533    0.01737  \n",
      "   87/100     0.1448    -99.94    0.3834    0.2506    0.3763     4.184     0.001     9.531    0.01917  \n",
      "   88/100     0.1741    -95.73    0.3836    0.2497    0.3795     4.237     0.001     9.411    0.01911  \n",
      "   89/100     0.1691    -101.8    0.4518    0.2488    0.3767     4.292     0.001     9.278    0.01885  \n",
      "   90/100     0.1538    -103.5    0.4718    0.2477    0.3727     4.348     0.001     9.144    0.01856  \n",
      "   91/100     0.1763    -89.28    0.3722    0.2467    0.3668     4.405     0.001     9.068    0.01917  \n",
      "   92/100     0.1615    -53.03    0.4112    0.2455    0.3676     4.464     0.001     8.88     0.01803  \n",
      "   93/100     0.1723    -92.66    0.3454    0.2444    0.3663     4.525     0.001     8.741    0.01764  \n",
      "   94/100     0.1606    -89.41    0.3134    0.2433     0.361     4.587     0.001     8.642    0.01787  \n",
      "   95/100     0.1631    -64.23    0.3566    0.2423    0.3556     4.651     0.001     8.626    0.01939  \n",
      "   96/100     0.1842    -96.59    0.4621    0.2414    0.3551     4.717     0.001     8.544    0.01988  \n",
      "   97/100     0.1599    -93.23     0.41     0.2405    0.3498     4.785     0.001     8.42     0.01969  \n",
      "   98/100     0.1803     -77.7    0.3265    0.2395    0.3523     4.854     0.001     8.257    0.01891  \n",
      "   99/100     0.1724    -81.72    0.2686    0.2387    0.3469     4.926     0.001     8.131    0.01869  \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "    STEP      t/STEP     LOSS     % ACC      EPS        dX       BETA       LR      ACTION    dPLAQ   \n",
      "-------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from config import NetWeights, NP_FLOAT\n",
    "\n",
    "samples_init = np.array(model.lattice.samples_array, dtype=NP_FLOAT)\n",
    "\n",
    "net_weights_init = NetWeights(1, 1, 1, 1, 1, 1)\n",
    "\n",
    "trainer.train(model.train_steps,\n",
    "              beta=model.beta_init,\n",
    "              samples=samples_init,\n",
    "              net_weights=net_weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Save weights from the trained model to `.pkl` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:25:18.831932Z",
     "start_time": "2020-01-27T08:25:18.778573Z"
    }
   },
   "outputs": [],
   "source": [
    "def pkl_dump(obj, out_file, name=''):\n",
    "    io.log(f'Saving {name} to {out_file}')\n",
    "    with open(out_file, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:25:26.925426Z",
     "start_time": "2020-01-27T08:25:24.659281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving weights_final to /Users/saforem2/ANL/l2hmc-qcd/gauge_logs/2020_01_27/L8_b64_lf5_f32_0224/weights.pkl\n"
     ]
    }
   ],
   "source": [
    "from trainers.train_setup import get_net_weights\n",
    "\n",
    "#wfile = os.path.join(model.log_dir, 'dynamics_weights.h5')\n",
    "#model.dynamics.save_weights(wfile)\n",
    "\n",
    "weights_final, coeffs_final = get_net_weights(model, sess)\n",
    "xcoeffs = sess.run(list(coeffs_final['xnet'].values()))\n",
    "vcoeffs = sess.run(list(coeffs_final['vnet'].values()))\n",
    "weights_final['xnet']['GenericNet'].update({\n",
    "    'coeff_scale': xcoeffs[0],\n",
    "    'coeff_transformation': xcoeffs[1],\n",
    "})\n",
    "weights_final['vnet']['GenericNet'].update({\n",
    "    'coeff_scale': vcoeffs[0],\n",
    "    'coeff_transformation': vcoeffs[1],\n",
    "})\n",
    "pkl_dump(weights_final, os.path.join(model.log_dir, 'weights.pkl'), name='weights_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:29:04.859715Z",
     "start_time": "2020-01-27T08:29:04.805960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving  to /Users/saforem2/ANL/l2hmc-qcd/gauge_logs/2020_01_27/L8_b64_lf5_f32_0224/dynamics_mask.pkl\n"
     ]
    }
   ],
   "source": [
    "masks_file = os.path.join(model.log_dir, 'dynamics_mask.pkl')\n",
    "m_ = sess.run(model.dynamics.masks)\n",
    "pkl_dump(m_, masks_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Create `dynamics_np` to compare against `model.dynamics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:31:07.169109Z",
     "start_time": "2020-01-27T08:31:06.735483Z"
    }
   },
   "outputs": [],
   "source": [
    "from runners.runner_np import create_dynamics, load_pkl, run_inference_np\n",
    "\n",
    "eps_np = sess.run(model.dynamics.eps)\n",
    "dynamics_np, lattice = create_dynamics(model.log_dir, eps=eps_np,\n",
    "                                       num_steps=model.num_steps,\n",
    "                                       batch_size=model.batch_size)\n",
    "with open(masks_file, 'rb') as f:\n",
    "    _m = pickle.load(f)\n",
    "    \n",
    "dynamics_np.masks = _m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create operations for calculating quantities of interest:   \n",
    " - `xf`: Proposed $x$, obtained from running `model.dyanmics.transition_kernel` with `forward=True`   \n",
    " - `vf`: Proposed $v$, obtained from running `model.dynamics.transition_kernel` with `forward=True`\n",
    " - `pxf`: $A(\\xi^{\\prime}|\\xi)$\n",
    " - `sumlogdetf`: Log determinant, accumulated over all leapfrog steps. Given by:\n",
    " \n",
    " \\begin{equation}\n",
    " \\log|\\mathcal{J}| = \\log\\left|\\frac{\\partial\\xi^{\\prime}}{\\partial \\xi^{T}}\\right| = d \\sum_{t\\leq N_{\\mathrm{LF}}} \\left[\\frac{\\varepsilon}{2}\\mathbb{1} \\cdot S_{v}(\\zeta^{t}_{1}) + \\varepsilon m^{t} \\cdot S_{x}(\\zeta^{t}_{2}) + \\varepsilon\\bar{m}^{t} \\cdot S_{x}(\\zeta^{t}_{3}) + \\frac{\\varepsilon}{2}\\mathbb{1}\\cdot S_{v}(\\zeta^{t}_{4})\\right]\n",
    " \\label{eq:sumlogdet}\n",
    " \\end{equation}   \n",
    " \n",
    "- `xf_`: $x^{\\prime\\prime}$, obtained by updating $x$ for a single leapfrog step.\n",
    "- `vf_`: $v^{\\prime\\prime}$, obtained by updating $v$ for a single leapfrog step.\n",
    "- `sld_`: Accumulated log determinant after a single leapfrog step. ($t = 1$ in Eq.\\ref{eq:sumlogdet})\n",
    "- `dudx_tf_`: $\\partial_{x}U(x, \\beta)$, evaluated at $\\beta = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:31:26.171718Z",
     "start_time": "2020-01-27T08:31:25.811789Z"
    }
   },
   "outputs": [],
   "source": [
    "from config import State, TF_FLOAT\n",
    "from seed_dict import seeds\n",
    "\n",
    "# ------------------------------\n",
    "# Run `model.dynamics` forward:\n",
    "# ------------------------------\n",
    "#vf_init = tf.random_normal(tf.shape(model.x), dtype=TF_FLOAT, seed=seeds['vf_init'], name='vf_init')\n",
    "vf_init_np = np.array(np.random.randn(*model.x.shape), dtype=NP_FLOAT)\n",
    "vf_init = tf.constant(vf_init_np)\n",
    "\n",
    "state_init_f = State(model.x, vf_init, model.beta)\n",
    "outf = model.dynamics.transition_kernel(*state_init_f,\n",
    "                                        model.net_weights,\n",
    "                                        model.train_phase,\n",
    "                                        forward=True, hmc=True)\n",
    "xf = outf['x_proposed']\n",
    "vf = outf['v_proposed']\n",
    "pxf = outf['accept_prob']\n",
    "pxf_hmc = outf['accept_prob_hmc']\n",
    "sumlogdetf = outf['sumlogdet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:31:28.254406Z",
     "start_time": "2020-01-27T08:31:27.874752Z"
    }
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "# Create operations for getting the output from `model.dynamics._forward_lf`:\n",
    "xf_, vf_, sld_, _ = model.dynamics._forward_lf(model.x, vf_init,\n",
    "                                               model.beta, step,\n",
    "                                               model.net_weights,\n",
    "                                               training=model.train_phase)\n",
    "\n",
    "# Create operation for calculating the gradient of the potential\n",
    "dudx_tf_ = model.dynamics.grad_potential(model.x, model.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:31:30.082818Z",
     "start_time": "2020-01-27T08:31:29.984052Z"
    }
   },
   "outputs": [],
   "source": [
    "train_phase = False\n",
    "t = model.dynamics._get_time(step, tile=tf.shape(model.x)[0])\n",
    "Sv, Tv, Qv = model.dynamics.vnet([model.x, dudx_tf_, t], model.train_phase)\n",
    "\n",
    "mask, mask_inv = model.dynamics._get_mask(step)\n",
    "Sx, Tx, Qx = model.dynamics.xnet([vf_init, mask * model.x, t], model.train_phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Run `model.dynamics` forward and compare against results from running `dynamics_np` forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:31:31.825427Z",
     "start_time": "2020-01-27T08:31:31.775009Z"
    }
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "beta_np = 5.\n",
    "train_phase = False\n",
    "net_weights = NetWeights(1, 1, 1, 1, 1, 1)\n",
    "#xf_init_np = np.zeros(model.x.shape, dtype=NP_FLOAT)\n",
    "xf_init_np = np.array(np.random.randn(*model.x.shape), dtype=NP_FLOAT)\n",
    "keys = ['xf', 'vf', 'vf_init', 'pxf', 'sumlogdetf']\n",
    "fops = [xf, vf, vf_init, pxf, sumlogdetf]\n",
    "_keys = ['xf_', 'vf_', 'sld_']\n",
    "_fops = [xf_, vf_, sld_]\n",
    "\n",
    "\n",
    "def forward_lf_tf(net_weights):\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.net_weights: net_weights,\n",
    "        model.train_phase: train_phase\n",
    "    }\n",
    "    \n",
    "    _fout = sess.run(_fops, feed_dict=feed_dict)\n",
    "    _fout_dict = dict(zip(_keys, _fout))\n",
    "    \n",
    "    return _fout_dict\n",
    "\n",
    "    \n",
    "def forward_lf_np(net_weights, vf_init_np):\n",
    "    \n",
    "    _fout_np = dynamics_np._forward_lf(xf_init_np, vf_init_np,\n",
    "                                       beta_np, step, net_weights)\n",
    "    _fout_dict_np = dict(zip(_keys, _fout_np))\n",
    "    return _fout_dict_np\n",
    "\n",
    "\n",
    "def dynamics_forward_tf(net_weights):\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.net_weights: net_weights,\n",
    "        model.train_phase: train_phase\n",
    "    }\n",
    "\n",
    "    fout = sess.run(fops, feed_dict=feed_dict)\n",
    "    fout_dict = dict(zip(keys, fout))\n",
    "    \n",
    "    return fout_dict\n",
    "\n",
    "\n",
    "def run_xnet():\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.net_weights: net_weights,\n",
    "        model.train_phase: train_phase,\n",
    "    }\n",
    "    \n",
    "    outputs = sess.run([Sx, Tx, Qx], feed_dict=feed_dict)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "\n",
    "def run_vnet():\n",
    "    feed_dict = {\n",
    "        model.x: xf_init_np,\n",
    "        model.beta: beta_np,\n",
    "        model.train_phase: train_phase,\n",
    "    }\n",
    "    outputs = sess.run([Sv, Tv, Qv], feed_dict=feed_dict)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def run_xnet_np():\n",
    "    t = dynamics_np._get_time(step, tile=xf_init_np.shape[0])\n",
    "    mask, mask_inv = dynamics_np._get_mask(step)\n",
    "    outputs = dynamics_np.xnet([vf_init_np, mask * xf_init_np, t])\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def run_vnet_np():\n",
    "    t = dynamics_np._get_time(step, tile=xf_init_np.shape[0])\n",
    "    mask, mask_inv = dynamics_np._get_mask(step)\n",
    "    dU_dx = dynamics_np.grad_potential(xf_init_np, beta_np)\n",
    "    outputs = dynamics_np.vnet([xf_init_np, dU_dx, t])\n",
    "    return outputs\n",
    "    \n",
    "\n",
    "def dynamics_forward_np(net_weights, vf_init_np):\n",
    "    state_init_f_np = State(xf_init_np, vf_init_np, beta_np)\n",
    "    \n",
    "    xf, vf, pxf, sldf = dynamics_np.transition_kernel(*state_init_f_np,\n",
    "                                                      net_weights, forward=True)\n",
    "    fout_dict_np = {\n",
    "        'xf': xf,\n",
    "        'vf': vf,\n",
    "        'vf_init': vf_init_np,\n",
    "        'pxf': pxf,\n",
    "        'sumlogdetf': sldf,\n",
    "    }\n",
    "    \n",
    "    return fout_dict_np\n",
    "\n",
    "\n",
    "def calc_diff(x1, x2, name=''):\n",
    "    diff = np.sqrt(np.sum((x1 - x2)**2))\n",
    "    print(f'{name} diff = {diff}')\n",
    "    \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Check that $\\partial_x U(x)$ is the same for `dynamics_tf` and `dynamics_np`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:31:34.398372Z",
     "start_time": "2020-01-27T08:31:33.738852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients agree: True\n"
     ]
    }
   ],
   "source": [
    "xrand_np = np.array(np.random.randn(*xf_init_np.shape), dtype=NP_FLOAT)\n",
    "dudx_np = dynamics_np.grad_potential(xrand_np, beta_np)\n",
    "\n",
    "dudx_tf = sess.run(dudx_tf_, feed_dict={model.x: xrand_np, model.beta: beta_np})\n",
    "\n",
    "diff = np.sqrt(np.sum((dudx_np - dudx_tf) ** 2))\n",
    "print(f'Gradients agree: {diff < 1e-3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:31:36.660017Z",
     "start_time": "2020-01-27T08:31:36.158444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sx agrees: True\n",
      "Tx agrees: True\n",
      "Qx agrees: True\n",
      "Sv agrees: False\n",
      "Tv agrees: False\n",
      "Qv agrees: False\n"
     ]
    }
   ],
   "source": [
    "Sx_tf, Tx_tf, Qx_tf = run_xnet()\n",
    "Sx_np, Tx_np, Qx_np = run_xnet_np()\n",
    "print(f'Sx agrees: {np.allclose(Sx_tf, Sx_np)}')\n",
    "print(f'Tx agrees: {np.allclose(Tx_tf, Tx_np)}')\n",
    "print(f'Qx agrees: {np.allclose(Qx_tf, Qx_np)}')\n",
    "\n",
    "Sv_tf, Tv_tf, Qv_tf = run_vnet()\n",
    "Sv_np, Tv_np, Qv_np = run_vnet_np()\n",
    "print(f'Sv agrees: {np.allclose(Sv_tf, Sv_np)}')\n",
    "print(f'Tv agrees: {np.allclose(Tv_tf, Tv_np)}')\n",
    "print(f'Qv agrees: {np.allclose(Qv_tf, Qv_np)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T15:20:00.263661Z",
     "start_time": "2020-01-27T15:20:00.048767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "NetWeights: NetWeights(x_scale=0, x_translation=0, x_transformation=0, v_scale=0, v_translation=0, v_transformation=0)\n",
      "xf diff = 1.29953223222401e-05\n",
      "vf diff = 3.780630140681751e-05\n",
      "vf_init diff = 0.0\n",
      "pxf diff = 0.0\n",
      "sumlogdetf diff = 0.0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "NetWeights: NetWeights(x_scale=1, x_translation=1, x_transformation=1, v_scale=1, v_translation=1, v_transformation=1)\n",
      "xf diff = 1.858777250163257e-05\n",
      "vf diff = 5.8459081628825516e-05\n",
      "vf_init diff = 0.0\n",
      "pxf diff = 1.3292044968693517e-05\n",
      "sumlogdetf diff = 3.592385382944485e-06\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "HEADER = 80 * '-'\n",
    "net_weights_arr = [\n",
    "    NetWeights(0, 0, 0, 0, 0, 0),\n",
    "    #NetWeights(0, 0, 0, 0, 0, 1),\n",
    "    #NetWeights(0, 0, 0, 0, 1, 0),\n",
    "    #NetWeights(0, 0, 0, 1, 0, 0),\n",
    "    #NetWeights(0, 0, 1, 0, 0, 0),\n",
    "    #NetWeights(0, 1, 0, 0, 0, 0),\n",
    "    #NetWeights(1, 0, 0, 0, 0, 0),\n",
    "    NetWeights(1, 1, 1, 1, 1, 1),\n",
    "]\n",
    "\n",
    "diffs_dict = {\n",
    "    \n",
    "}\n",
    "for net_weights in net_weights_arr:\n",
    "    io.log(HEADER)\n",
    "    io.log(f'NetWeights: {net_weights}')\n",
    "    fout_tf = dynamics_forward_tf(net_weights)\n",
    "    diffs_dict[net_weights] = {}\n",
    "    _vf_np = fout_tf['vf_init']\n",
    "    np.allclose(_vf_np, vf_init_np)\n",
    "    fout_np = dynamics_forward_np(net_weights, vf_init_np)\n",
    "    for key in fout_tf.keys():\n",
    "        diffs_dict[key] = calc_diff(fout_tf[key], fout_np[key], name=key)\n",
    "    io.log(HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:32:04.825412Z",
     "start_time": "2020-01-27T08:32:04.111618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "NetWeights: (0, 0, 0, 0, 0, 0)\n",
      "xf_ diff = 1.0772878340503667e-06\n",
      "vf_ diff = 4.042994987685233e-06\n",
      "sld_ diff = 0.0\n",
      "-----------------------------------\n",
      "NetWeights: (1, 1, 1, 1, 1, 1)\n",
      "xf_ diff = 1.898151026580308e-06\n",
      "vf_ diff = 5.409741788753308e-06\n",
      "sld_ diff = 4.5733153797300474e-07\n"
     ]
    }
   ],
   "source": [
    "HEADER1 = (len(f'NetWeights: {tuple(net_weights)}') + 5) * '-'\n",
    "\n",
    "_diffs_dict = {}\n",
    "for net_weights in net_weights_arr:\n",
    "    io.log(HEADER1)\n",
    "    io.log(f'NetWeights: {tuple(net_weights)}')\n",
    "    _diffs_dict[net_weights] = {}\n",
    "    _fout_tf = forward_lf_tf(net_weights)\n",
    "    #_vf_init = _fout_tf\n",
    "    _fout_np = forward_lf_np(net_weights, vf_init_np)\n",
    "    for key in _fout_tf.keys():\n",
    "        _diffs_dict[key] = calc_diff(_fout_tf[key], _fout_np[key], name=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
